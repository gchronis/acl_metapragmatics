{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import csv\n",
    "import textwrap\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import pickle\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch\n",
    "#from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "2024-11-20 08:36:27.863171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gabriellachronis/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gabriellachronis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import preprocess_for_context_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize BERT model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device : \", device)\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the word we want to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\"coca\", \"acl\"]\n",
    "word = \"model\"\n",
    "k_means_n = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data for the word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5062</th>\n",
       "      <td>5062</td>\n",
       "      <td>156200</td>\n",
       "      <td>The fit of each of three nonrecursive models (...</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>coca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11931</th>\n",
       "      <td>11931</td>\n",
       "      <td>159103</td>\n",
       "      <td>The general linear model applied was : # Due t...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>coca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13938</th>\n",
       "      <td>13938</td>\n",
       "      <td>136866</td>\n",
       "      <td>Role model o My mom . \"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>coca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9932</th>\n",
       "      <td>9932</td>\n",
       "      <td>158417</td>\n",
       "      <td>Albert , Sci-Fi Club alum from 2006 , felt tha...</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>coca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>9345</td>\n",
       "      <td>158048</td>\n",
       "      <td>Chronic exposure to high-intensity light ( 2,0...</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>coca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131383</th>\n",
       "      <td>131383</td>\n",
       "      <td>18443059</td>\n",
       "      <td>A radically new approach is needed to address ...</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684915</th>\n",
       "      <td>684915</td>\n",
       "      <td>221816590</td>\n",
       "      <td>In many cases, the model struggles to distingu...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694830</th>\n",
       "      <td>694830</td>\n",
       "      <td>222133423</td>\n",
       "      <td>A.4.1 Word Embedding Dimension To decide what ...</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372177</th>\n",
       "      <td>372177</td>\n",
       "      <td>15142037</td>\n",
       "      <td>For language model scoring, we use the SRILM t...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234419</th>\n",
       "      <td>234419</td>\n",
       "      <td>6734095</td>\n",
       "      <td>How is the topic number affect the language mo...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  corpus_id  \\\n",
       "5062          5062     156200   \n",
       "11931        11931     159103   \n",
       "13938        13938     136866   \n",
       "9932          9932     158417   \n",
       "9345          9345     158048   \n",
       "...            ...        ...   \n",
       "131383      131383   18443059   \n",
       "684915      684915  221816590   \n",
       "694830      694830  222133423   \n",
       "372177      372177   15142037   \n",
       "234419      234419    6734095   \n",
       "\n",
       "                                                 sentence  start_idx  end_idx  \\\n",
       "5062    The fit of each of three nonrecursive models (...         24       25   \n",
       "11931   The general linear model applied was : # Due t...          3        4   \n",
       "13938                             Role model o My mom . \"          1        2   \n",
       "9932    Albert , Sci-Fi Club alum from 2006 , felt tha...         29       30   \n",
       "9345    Chronic exposure to high-intensity light ( 2,0...         49       50   \n",
       "...                                                   ...        ...      ...   \n",
       "131383  A radically new approach is needed to address ...         24       25   \n",
       "684915  In many cases, the model struggles to distingu...          5        6   \n",
       "694830  A.4.1 Word Embedding Dimension To decide what ...         32       33   \n",
       "372177  For language model scoring, we use the SRILM t...         21       22   \n",
       "234419  How is the topic number affect the language mo...          8        9   \n",
       "\n",
       "       source  \n",
       "5062     coca  \n",
       "11931    coca  \n",
       "13938    coca  \n",
       "9932     coca  \n",
       "9345     coca  \n",
       "...       ...  \n",
       "131383    acl  \n",
       "684915    acl  \n",
       "694830    acl  \n",
       "372177    acl  \n",
       "234419    acl  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for source in sources:\n",
    "    df = pd.read_csv('./collected_tokens/{}/{}.csv'.format(source,word))\n",
    "    df['source'] = source\n",
    "\n",
    "    # get senteces that are less than 150 in length\n",
    "    df[\n",
    "        df[\"sentence\"].apply(lambda x: len(x) > 100)\n",
    "    ]\n",
    "\n",
    "    # get senteces that are less than 150 in length\n",
    "    df[\"sentence\"] = df[\"sentence\"].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii', 'ignore'))\n",
    "\n",
    "    ####### REAL ######\n",
    "    # Take at most 200 sentences.\n",
    "    sample_df = df.sample(1000, random_state=42) # use a fixed seed for reproducibility\n",
    "    \n",
    "    ##### DEBUG########\n",
    "    # Take at most 2 sentences.\n",
    "    #sample_df = df.sample(200)\n",
    "    \n",
    "    dfs.append(sample_df)\n",
    "    \n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting embeddings for 2000 sentences \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "filename = 'viz_data/{}.pkl'.format(word)\n",
    "\n",
    "if not path.exists(filename):\n",
    "    # get the vectors\n",
    "    data = preprocess_for_context_atlas.neighbors(word, sample_df)\n",
    "    # save data\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "else:\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess returns a dict with three array-containing keys. sentence, pos, and data. Later we can add to this preprocessing if we want to add more metadata. For now, we separate them out. would perhaps be better to put them all in a single df and use that to build our plot. TODO if you go down that road but unnecessary now. That would involve making a DF from the labels and one from the data and joining them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [label['sentence'] for label in data['labels'] ]\n",
    "pos = [label['pos'] for label in data['labels'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are the layers. We select layer 7 (0 indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get clusters labels for this layer\n",
    "\n",
    "cluster_ids = data['clusters'][layer]\n",
    "cluster_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "points = data['data'][layer]\n",
    "points = np.array(points)\n",
    "umap_x = points[:,0]\n",
    "umap_y = points[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = {\"umap_x\": umap_x,\n",
    "             \"umap_y\": umap_y,\n",
    "             \"pos\": pos,\n",
    "             \"cluster\": cluster_ids,\n",
    "             \"sents\": sents,\n",
    "            \"wrapped_sents\": list(map((lambda x: x.replace('\\n', '<br>')),sents)),\n",
    "             \"source\": df['source']\n",
    "}\n",
    "df = pd.DataFrame.from_records(plot_dict)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.write_html(\"visualizations/{}_{}_{}.html\".format(corpus, word, layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment in doing a dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to change plot data using dropdowns\n",
    "#\n",
    "# This example shows how to manually add traces\n",
    "# to the plot and configure the dropdown to only\n",
    "# show the specific traces you allow.\n",
    "\n",
    "fig = go.Figure()\n",
    "#plt.figure(figsize=(16,16))\n",
    "\n",
    "fig = px.scatter(\n",
    "                #color = df['pos'],\n",
    "                 width=1000, height=1000\n",
    "                )\n",
    "\n",
    "# \"\"\"\n",
    "# create color list based on POS\n",
    "# \"\"\"\n",
    "# #create dict with unique color values\n",
    "pos = [label['pos'] for label in data['labels'] ]\n",
    "color_dict={}\n",
    "x=0\n",
    "for p in pos:\n",
    "    if p not in color_dict:\n",
    "        color_dict[p]=x\n",
    "        x += 1    \n",
    "#create color list\n",
    "color_list=[]\n",
    "for p in pos:\n",
    "    color_list.append(color_dict[p])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "create color list based on data source\n",
    "\"\"\"\n",
    "source_dict = {}\n",
    "for p in sources:\n",
    "    if p not in source_dict:\n",
    "        source_dict[p]=x\n",
    "        x += 1\n",
    "#create color list\n",
    "source_list=[]\n",
    "for p in df['source']:\n",
    "    source_list.append(source_dict[p])\n",
    "\n",
    "# create a column of formatted text\n",
    "df[\"wrapped_sents\"] = df[\"sents\"].str.wrap(50)\n",
    "df[\"wrapped_sents\"] = df[\"wrapped_sents\"].apply(lambda x: x.replace('\\n', '<br>'))\n",
    "\n",
    "\"\"\"\n",
    "create traces for different layers\n",
    "\"\"\"\n",
    "for layer in range(12):\n",
    "    points = data['data'][layer]\n",
    "    clusters = data['clusters'][layer]\n",
    "    points = np.array(points)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                    size=4,\n",
    "                    color= source_list,   # pos # cluster_list # use color_list to set color to an array/list of desired values\n",
    "                    colorscale='Viridis',   # choose a colorscale\n",
    "                    #opacity=0.8\n",
    "                ),\n",
    "\n",
    "            x = points[:,0],\n",
    "            y = points[:,1],\n",
    "            hovertext=df[\"wrapped_sents\"],\n",
    "            \n",
    "            name = layer\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_yaxes(\n",
    "    scaleanchor=\"x\",\n",
    "    scaleratio=1,\n",
    "  )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "create dropdown menu to show one set of points at a time\n",
    "\"\"\"\n",
    "    \n",
    "fig.update_layout(\n",
    "    updatemenus=[go.layout.Updatemenu(\n",
    "        active=0,\n",
    "        buttons=list(\n",
    "            [dict(label = 'All',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [True, True, True, True, True, True, True, True, True, True, True, True]},\n",
    "                          {'title': 'All',\n",
    "                           'showlegend':True}]),\n",
    "\n",
    "\n",
    "             \n",
    "             dict(label = 'Layer 0',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [True, False, False, False, False, False, False, False, False, False, False, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 0',\n",
    "                           'showlegend':True}]),\n",
    "             dict(label = 'Layer 1',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [False, True, False, False, False, False, False, False, False, False, False, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 1',\n",
    "                           'showlegend':True}]),\n",
    "             dict(label = 'Layer 2',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [False, False, True, False, False, False, False, False, False, False, False, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 2',\n",
    "                           'showlegend':True}]),\n",
    "             dict(label = 'Layer 3',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [False, False, False, True, False, False, False, False, False, False, False, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 3',\n",
    "                           'showlegend':True}]),\n",
    "             dict(label = 'Layer 4',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [False, False, False, False, True, False, False, False, False, False, False, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 4',\n",
    "                           'showlegend':True}]),\n",
    "             dict(label = 'Layer 6',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [True, False, False, False, False, False, True, False, False, False, False, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 6',\n",
    "                           'showlegend':True}]),\n",
    "             dict(label = 'Layer 7',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [False, False, False, False, False, False, False, True, False, False, False, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 7',\n",
    "                           'showlegend':True}]),\n",
    "              dict(label = 'Layer 8',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [False, False, False, False, False, False, False, False, True, False, False, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 8',\n",
    "                           'showlegend':True}]),\n",
    "             dict(label = 'Layer 9',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [False, False, False, False, False, False, False, False, False, True, False, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 9',\n",
    "                           'showlegend':True}]),\n",
    "             dict(label = 'Layer 10',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [False, False, False, False, False, False, False, False, False, False, True, False]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 10',\n",
    "                           'showlegend':True}]),\n",
    "             dict(label = 'Layer 11',\n",
    "                  method = 'update',\n",
    "                  args = [{'visible': [False, False, False, False, False, False, False, False, False, False, False, True]}, # the index of True aligns with the indices of plot traces\n",
    "                          {'title': 'Layer 11',\n",
    "                           'showlegend':True}]),\n",
    "\n",
    "            ])\n",
    "        )\n",
    "    ])\n",
    "\n",
    "fig.update_layout(hoverlabel={\n",
    "    \"align\": \"right\",\n",
    "    \"bgcolor\": \"white\"\n",
    "})\n",
    "fig.update_layout(hoverlabel_font={\n",
    "    \"size\": 9,\n",
    "    \"color\": \"black\"\n",
    "})\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"visualizations/{}_{}_full.html\".format(corpus, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
