{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3860dc48-6d6e-4f53-b42d-fd1ef9f6ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "821be68c-ccb5-459c-ad72-91921aec6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('true.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "401abea6-a613-472f-976d-bd076d1f2610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/data_gabriella_chronis/workspace/acl_metapragmatics/data/logic_words\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "840f1587-ec62-4d3a-9933-f6eeb6d39036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16703040</td>\n",
       "      <td>Error Analysis We inspected 50 email pairs each of true positives, false positives, false negatives, and true negatives from our RB experiments 8 .</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16703040</td>\n",
       "      <td>Error Analysis We inspected 50 email pairs each of true positives, false positives, false negatives, and true negatives from our RB experiments 8 .</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2491460</td>\n",
       "      <td>Since dręczyć 'to torment' is in acc dictionary and since Janek 'John' has subst class and acc case -the boolean operator returns 'true'.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2491460</td>\n",
       "      <td>Because all of these conditions are fulfilled, the operator returns 'true', and we may assume that the last token takes the role of Proto-Agent.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>690455</td>\n",
       "      <td>The true value for the ME based processing is realized in ME_LS, where the probabilities have been logarithmically scaled be summing.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  corpus_id  \\\n",
       "0           0   16703040   \n",
       "1           1   16703040   \n",
       "2           2    2491460   \n",
       "3           3    2491460   \n",
       "4           4     690455   \n",
       "\n",
       "                                                                                                                                              sentence  \\\n",
       "0  Error Analysis We inspected 50 email pairs each of true positives, false positives, false negatives, and true negatives from our RB experiments 8 .   \n",
       "1  Error Analysis We inspected 50 email pairs each of true positives, false positives, false negatives, and true negatives from our RB experiments 8 .   \n",
       "2            Since dręczyć 'to torment' is in acc dictionary and since Janek 'John' has subst class and acc case -the boolean operator returns 'true'.   \n",
       "3     Because all of these conditions are fulfilled, the operator returns 'true', and we may assume that the last token takes the role of Proto-Agent.   \n",
       "4                The true value for the ME based processing is realized in ME_LS, where the probabilities have been logarithmically scaled be summing.   \n",
       "\n",
       "   start_idx  end_idx  \n",
       "0          9       10  \n",
       "1         19       20  \n",
       "2         27       28  \n",
       "3         12       13  \n",
       "4          1        2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67ad8839-1ae5-4bbd-8a26-397a7c5aad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40595"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "730a900f-3644-4ab1-8bcd-81f464ab60c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33556</th>\n",
       "      <td>33556</td>\n",
       "      <td>235097435</td>\n",
       "      <td>Nevertheless, the two tasks differ in one key aspect: whether the combination 2 of the segmented morpheme sequence stays true to the initial orthography of the word.</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26575</th>\n",
       "      <td>26575</td>\n",
       "      <td>208139384</td>\n",
       "      <td>2018) use: (1) mean absolute error (MAE); and (2) mean absolute percentage error (MAPE), calculated as 100 n n i=1 ŷi −y i y i , where n is the number of examples and ŷi (y i ) the predicted (true) value.</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30718</th>\n",
       "      <td>30718</td>\n",
       "      <td>3126524</td>\n",
       "      <td>We use the simple approach of having a single binary feature per sense (e.g., role) that is set true whenever any of the associated collocation words for that sense are encountered (i.e., per-class-binary).</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>5298</td>\n",
       "      <td>44109570</td>\n",
       "      <td>Although these word embeddings do not distinguish one semantic relation from another, we expect that true hypernyms will constitute a significant proportion of the predicted candidate hypernyms.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21466</th>\n",
       "      <td>21466</td>\n",
       "      <td>6677927</td>\n",
       "      <td>Also, some facts are only true for a certain time period, like being the president of a country.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>3178</td>\n",
       "      <td>247594019</td>\n",
       "      <td>We can also define the outcome Y of a test example x i as the predicted probability of (pseudo) true label given by the trained model f (⋅): Y i (0) ∶= P f (L ′ = l ′ i | X = x i ) ∈ (0, 1). (</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>4440</td>\n",
       "      <td>427084</td>\n",
       "      <td>In sum, the dialog system never knows the true state of the product nor the user's true actions, yet must still instruct the user to successfully restore the product to a working state.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30968</th>\n",
       "      <td>30968</td>\n",
       "      <td>9228771</td>\n",
       "      <td>Results We were interested in whether our working definition of cognation (translations and LCSR ≥ 0.58) reflects true etymological relatedness.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>3541</td>\n",
       "      <td>199000861</td>\n",
       "      <td>In the open-world setting, it's quite possible that the answer entity t true (for a tail query) or h true (for a head query) does not exist in the KB (in E).</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11627</th>\n",
       "      <td>11627</td>\n",
       "      <td>16223112</td>\n",
       "      <td>Note that, as discussed in Section 1, the list will contain true and false cognates.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17691</th>\n",
       "      <td>17691</td>\n",
       "      <td>18712337</td>\n",
       "      <td>It is also unclear whether human examinees guess the text characters according to the true probability distribution.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37056</th>\n",
       "      <td>37056</td>\n",
       "      <td>202235043</td>\n",
       "      <td>The γ • Y (k) term is in effect a class-specific bias offset given the matched document, and the γ • y k variation directly balances the signal from the true token-level label and the prediction.</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15600</th>\n",
       "      <td>15600</td>\n",
       "      <td>18111831</td>\n",
       "      <td>Therefore we label model bill sentences in M * that match a bill sentence with a score greater than 0.85 as true matches (S * ) 2 .</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39324</th>\n",
       "      <td>39324</td>\n",
       "      <td>199424813</td>\n",
       "      <td>Hamming loss was the chosen metric for evaluation (Zhang and Zhou, 2014) , which computes the distance between predicted and true values.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7969</th>\n",
       "      <td>7969</td>\n",
       "      <td>247595094</td>\n",
       "      <td>While training, this distribution is penalised for being different from the 'true' distribution (i.e. a probability of 1 for the true next token, 0 for all other tokens) using cross entropy loss.</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>4716</td>\n",
       "      <td>9623634</td>\n",
       "      <td>After the conversion, w1 will depend on w2 with a DEP label, and the same is true for w4 and w5; w2 will depend on w5 with label rel and w5 on a dummy word with label ROOT; w3 is ignored since it is not part of any entity.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38947</th>\n",
       "      <td>38947</td>\n",
       "      <td>227231142</td>\n",
       "      <td>This could not be more true for endangered language archives.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39750</th>\n",
       "      <td>39750</td>\n",
       "      <td>48374376</td>\n",
       "      <td>Checking whether R ω a (x) is true requires global evaluation of the string to see if any position is labeled b. This is due to the existential quantifier ∃, which makes (17) strictly FO.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18986</th>\n",
       "      <td>18986</td>\n",
       "      <td>237513923</td>\n",
       "      <td>We then have one of the authors and an additional expert annotator manually label all of the errors as true or false positives.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26673</th>\n",
       "      <td>26673</td>\n",
       "      <td>558258</td>\n",
       "      <td>They characterized three regimes: one where EM was successful in recovering the true clusters (given lots of data), another where EM failed but the global optimum was successful, and the last where both failed (without much data).</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14518</th>\n",
       "      <td>14518</td>\n",
       "      <td>6342059</td>\n",
       "      <td>Because LDA needs to know the number of topics a priori, we set the number of topics to be equal to the true number of factoids.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21620</th>\n",
       "      <td>21620</td>\n",
       "      <td>71148539</td>\n",
       "      <td>In order to create meaningful edges using training data as the only resource, we utilize the type co-occurrence matrix: if two type t 1 and t 2 both appear to be the true types of a particular entity mention, we will add an edge between them.</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32547</th>\n",
       "      <td>32547</td>\n",
       "      <td>199379857</td>\n",
       "      <td>This is true for many diseases in the i2b2 dataset.</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33362</th>\n",
       "      <td>33362</td>\n",
       "      <td>243865621</td>\n",
       "      <td>Mean reciprocal rank is the average of the inverse of the mean rank assigned to the true triple over all candidate triples.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36992</th>\n",
       "      <td>36992</td>\n",
       "      <td>1526921</td>\n",
       "      <td>However, by separating predicates from entities, we can have two different entities which chase is true of, where one co-occurs with a dog-entity ARG1 and catentity ARG2, while the other co-occurs with a catentity ARG1 and a mouse-entity ARG2.</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15624</th>\n",
       "      <td>15624</td>\n",
       "      <td>2551840</td>\n",
       "      <td>We exclude the years of the true examples from the dataset's year range, and then randomly choose years for the negative examples.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10155</th>\n",
       "      <td>10155</td>\n",
       "      <td>11551180</td>\n",
       "      <td>Thus, we tend to overestimate true word order freedom.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13583</th>\n",
       "      <td>13583</td>\n",
       "      <td>28126691</td>\n",
       "      <td>If the ability is greater than the difficulty, the student is likely to succeed, or if the inverse is true, the student is more likely to fail.</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9220</th>\n",
       "      <td>9220</td>\n",
       "      <td>241583486</td>\n",
       "      <td>However, this is not true of all hypernyms: it is possible that BERT's use of generic hypernyms like \"thing\" stems from a memorization of frequent constructions like \"my favorite thing\" in the training data.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31064</th>\n",
       "      <td>31064</td>\n",
       "      <td>7596434</td>\n",
       "      <td>If we take sufficient number of random words as nearby words, the sense distribution comes close to the true distribution, and then we expect the statistically true sense distribution should find out the true sense of the target word, according to the distributional hypotheses (Harris, 1954) .</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27848</th>\n",
       "      <td>27848</td>\n",
       "      <td>104744</td>\n",
       "      <td>The prosodic pseudo-punctuation symbol would replace the true preceding sibling's category in the model, thus possibly resulting in poorer overall performance (note however that the parser also includes a higher-order backoff distribution in which the next category is predicted using the preceding two sibling's categories, so the true sibling's category would still have some predictive value).</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31940</th>\n",
       "      <td>31940</td>\n",
       "      <td>250390598</td>\n",
       "      <td>When the other two distance scores correctly reflect the ground true similarity, like in the second example in Table 4 , the one with no overlap could be large, which spoils the overall prediction.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40209</th>\n",
       "      <td>40209</td>\n",
       "      <td>227209515</td>\n",
       "      <td>As the true label in the AL setting is unknown, Zhang et al. (</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>4271</td>\n",
       "      <td>204885369</td>\n",
       "      <td>While it is of course true that were the AVG or GNN method able to perfectly capture the word order of the UD corpora, the rate of projectivity and Spearman's ρ would match exactly, but it is intriguing that short of perfection, Spearman's ρ and projectivity are not necessarily correlated.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33400</th>\n",
       "      <td>33400</td>\n",
       "      <td>222091022</td>\n",
       "      <td>We apply Pareto to select maximum input sequences of 64 tokens for true/false questions and 180 for text and diagram MC.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19666</th>\n",
       "      <td>19666</td>\n",
       "      <td>221187043</td>\n",
       "      <td>In consequence, the negation F1 is zero for the left sentence with the distorted facts and maximum for the sentence that sticks true to the facts.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32216</th>\n",
       "      <td>32216</td>\n",
       "      <td>7177714</td>\n",
       "      <td>Firstly, variations of the same token share the key words and present in similar patterns, for instance, it's true, this is true and true are all considered as variations of that's true, since they contain the same key word true with similar patterns.</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35627</th>\n",
       "      <td>35627</td>\n",
       "      <td>248084905</td>\n",
       "      <td>Both the Hoeffding and Bernstein bounds are very loose, overestimating the true error in 100% of samples, by margins that are about an order of magnitude greater than the average error in Figure 4 .</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>5245</td>\n",
       "      <td>174799458</td>\n",
       "      <td>Ultimately, we consolidated the above finegrained labels into the following coarse-grained labels, which we used for subtask B: * FACTUAL -TRUE: Contains answers with proven true, non-contradictory statements.</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14764</th>\n",
       "      <td>14764</td>\n",
       "      <td>16763028</td>\n",
       "      <td>DCU [baseline] Depending on the drink, some images of galaxias galaxies become true works of art.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>2378</td>\n",
       "      <td>236478233</td>\n",
       "      <td>We can calculate how often this is true for the DeepHit model by calculating the concordance index of the predicted event times and the inverse of the censoring indicator.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>9291</td>\n",
       "      <td>13908311</td>\n",
       "      <td>They introduce three data sets of true and lying texts containing 100 true and 100 false statements for each dataset.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33663</th>\n",
       "      <td>33663</td>\n",
       "      <td>6323862</td>\n",
       "      <td>of them were (true) paraphrases.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40565</th>\n",
       "      <td>40565</td>\n",
       "      <td>233365334</td>\n",
       "      <td>If this is true, then we should find similar results in languages that are typologically related to Hindi.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34209</th>\n",
       "      <td>34209</td>\n",
       "      <td>28148522</td>\n",
       "      <td>salad, the semantic approaches allow us to say that it was a mass or count semantic representation of apple only after inspecting the kind of thing that apple is true of in the sentences.</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>8051</td>\n",
       "      <td>202544040</td>\n",
       "      <td>We treat such basic projections in trivalent semantics, where natural language sentences are represented using propositions that denote 1 (true), 0 (false) or (presupposition failure).</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>633</td>\n",
       "      <td>5187134</td>\n",
       "      <td>○(T alm ): When the text is true, the hypothesis is almost true. •</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32499</th>\n",
       "      <td>32499</td>\n",
       "      <td>53082197</td>\n",
       "      <td>For example, (Bill Clinton, presi-dentOf, USA) was true only from 1993 to 2001.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19643</th>\n",
       "      <td>19643</td>\n",
       "      <td>1076380</td>\n",
       "      <td>Finally, a Boolean feature (e.g., cues id ea ) is set to true if any word from the list is in the citing context.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>326</td>\n",
       "      <td>131773759</td>\n",
       "      <td>2019 ) and compute the true positive rate (TPR) race gap and the TPR gender gap-i.e., the differences in the TPRs between races and between genders, respectively-for each occupation.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>4210</td>\n",
       "      <td>521137</td>\n",
       "      <td>This is especially true in the case of presentational relations.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30040</th>\n",
       "      <td>30040</td>\n",
       "      <td>222290454</td>\n",
       "      <td>We treat each integer as a bucket and use the normalized counts in each bucket as the true distribution for that scalar attribute of the object.</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29746</th>\n",
       "      <td>29746</td>\n",
       "      <td>225041060</td>\n",
       "      <td>We predict the probability for every text fragment in a page and count the number of fragments whose true superior counterparts appears in the top k candidates.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9745</th>\n",
       "      <td>9745</td>\n",
       "      <td>250390627</td>\n",
       "      <td>Note that when the author has baseline information, it is the author's choice to decide whether or not to disclose the true information to the public.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32448</th>\n",
       "      <td>32448</td>\n",
       "      <td>202774805</td>\n",
       "      <td>As discussed in Section 4.2, the true posterior we can obtain is in the form of the unordered set.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25582</th>\n",
       "      <td>25582</td>\n",
       "      <td>25940328</td>\n",
       "      <td>2011) , who use a neural network to predict whether an n-gram is a true n-gram or a \"corrupted\" version.</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>16186</td>\n",
       "      <td>233209971</td>\n",
       "      <td>Intra-rater agreement For quality control, annotation files contained a total of 69 randomly sampled duplicate pairs, in addition to the 1,360 true pairs.</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37622</th>\n",
       "      <td>37622</td>\n",
       "      <td>235658689</td>\n",
       "      <td>Then we compute, in a similar fashion as a normal F1, the precision and recall using the soft definitions of the true positive, false positive, and false negative.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29526</th>\n",
       "      <td>29526</td>\n",
       "      <td>5816453</td>\n",
       "      <td>Future work must therefore gather a large corpus of true narratives, like fairy tales and children's stories, whose simple plot structures should provide better learning material, both for models predicting script events, and for related tasks like automatic storytelling (McIntyre and Lapata, 2009) .</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26417</th>\n",
       "      <td>26417</td>\n",
       "      <td>248085885</td>\n",
       "      <td>in a tweet tuesday night, trump said he \" would love to send ambassador [ sundland ], a really good man and great american, to testify, but unfortunately he would be testifying before a totally compromised kangaroo court, where republican ' s rights have been taken away, and true facts are not allowed out for the public to see. \"</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18692</th>\n",
       "      <td>18692</td>\n",
       "      <td>237485621</td>\n",
       "      <td>-Consistency: highly consistent • (\"relax\", HASSUBEVENT, \"vegetable\") -Grammar: incorrect -Truthfulness: never true -Consistency: not consistent at all • (\"drink coffee\", HASSUBEVENT, \"water may get into your nose\") -Grammar: correct -Truthfulness: never true -Consistency: a little consistent (Our interpretation: Drinking coffee doesn't cause water to get into your nose, but coffee and water are both drinkable liquids, so we think this statement is a little consistent.)</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>19991</td>\n",
       "      <td>6489978</td>\n",
       "      <td>The correct answer is true, so it shows the method works well for the decision.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37233</th>\n",
       "      <td>37233</td>\n",
       "      <td>213719646</td>\n",
       "      <td>The second way of modifying surprisal theory would be to posit that the relevant probability distribution of words given contexts does not take into account full information from the context, or is distorted in some way relative to the true distribution of words given contexts.</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12666</th>\n",
       "      <td>12666</td>\n",
       "      <td>13051685</td>\n",
       "      <td>In order to understand better the true precision and recall of the automatic classification as compared to the handannotated data-set it would, of course, be highly beneficial to have a larger sample of hand-annotated data.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>3298</td>\n",
       "      <td>16470003</td>\n",
       "      <td>In this case, given the imbalance between positive and negative pairs, we maximize weighted accuracy (that is, we count each true negative as (|pos| + |neg|)/2|neg|, and each true positive as (|pos| + |neg|)/2|pos|, where |class| is the cardinality of the relevant class in the tuning data).</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18414</th>\n",
       "      <td>18414</td>\n",
       "      <td>14222290</td>\n",
       "      <td>That is, (true pos + inv pos) divided by (true pos + inv pos + f alse pos).</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38949</th>\n",
       "      <td>38949</td>\n",
       "      <td>227231142</td>\n",
       "      <td>Anthropologists interested in material culture now have a very simple entry point into the data; the same is true for ethnozoologist/ornithologists and their kin.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32877</th>\n",
       "      <td>32877</td>\n",
       "      <td>237364106</td>\n",
       "      <td>For EL, we use (i) mention-level F1 score (EL m ), and (ii) cluster-level hard F1 score (EL h ) that counts a true positive only if both the coreference cluster (in terms of all its mention spans) and the entity link are correctly predicted.</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40428</th>\n",
       "      <td>40428</td>\n",
       "      <td>226283839</td>\n",
       "      <td>We can formalize it as: T P C j = I y i =C j * I C j =y i (4) where: I X = 1 if X is true 0 if X is false We propose a continuous generalization as the confidence true positive: cT P C j = M (x i , C j ) * I C j =y i (5) As shown in Equation 5 , we're simply replacing the binary I y i =C j from Equation 4 by the continuous M (x i , C j ).</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>7093</td>\n",
       "      <td>2613012</td>\n",
       "      <td>Computing the true translation probability would require the same operation to be repeated in every cell during decoding, which is very time consuming.</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15333</th>\n",
       "      <td>15333</td>\n",
       "      <td>226262218</td>\n",
       "      <td>In contrast, our model reduces the difference in scores for a human entity's true sensitive attributes and the alternatives (shown in Table 5 ) significantly for FB15K and FB3M. For Wikidata, we still see a notable gap between these scores (for example of 0.49 for gender), suggesting some information about these attributes remains in the embeddings.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>5721</td>\n",
       "      <td>9665780</td>\n",
       "      <td>When margin = 2 the ratio true positive/true negative is maximal.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39792</th>\n",
       "      <td>39792</td>\n",
       "      <td>8211364</td>\n",
       "      <td>Recall, as defined in (8), is the number of true positives divided by the number of true positives plus false negatives.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14917</th>\n",
       "      <td>14917</td>\n",
       "      <td>13936472</td>\n",
       "      <td>The same is true for the implementation described in Eisner (1997a) , although a proposal is given there for a method that might improve the situation.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35187</th>\n",
       "      <td>35187</td>\n",
       "      <td>9922498</td>\n",
       "      <td>To see that this is true, execute the following algorithm.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9548</th>\n",
       "      <td>9548</td>\n",
       "      <td>86111</td>\n",
       "      <td>Because we train both our model and the standard phrase table on the same dataset, we use leaving-one-out in the classifier training to avoid Feature Type Configurations Czech German Polish, Romanian Source Indicator f, l, l+t, t f, l, l+t, t l, t Source Internal f, f+a, f+p, l, l+t, t, a+p f, f+a, f+p, l, l+t, t, a+p l, l+a, l+p, t, a+p Source Context f (-3,3), l (-3,3), t (-5,5) f (-3,3), l (-3,3), t (-5,5) l (-3,3), t (-5,5) For target-side context features, we simply use the true (gold) target context.</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724</th>\n",
       "      <td>7724</td>\n",
       "      <td>5410772</td>\n",
       "      <td>For FTC, it will be the probability of observing the difference (referred to as the evidence, E) between the offender's and the suspect's samples if they had come from the same author (H p ) (i.e. if the prosecution hypothesis is true) relative to the probability of observing the same evidence (E) if they had been produced by different authors (H d ) (i.e. if the defence hypothesis is true).</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22835</th>\n",
       "      <td>22835</td>\n",
       "      <td>233296446</td>\n",
       "      <td>Following such schema, models were instead required to produce a continuous score representing how likely the premise is true given the hypothesis.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>4133</td>\n",
       "      <td>712473</td>\n",
       "      <td>QA and IR It is true that, intrinsically, IR engines and QA systems differ in design, objectives and processes.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>14277</td>\n",
       "      <td>248780123</td>\n",
       "      <td>B.2 Zero-shot TPE Classification We build the previous premise-hypothesis construction in § 4.4 based on the assumption of availability of TPE, which is frequently not true.</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30204</th>\n",
       "      <td>30204</td>\n",
       "      <td>233405184</td>\n",
       "      <td>operator: RUN &lt;/s&gt; generated answer:true, NAF.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>4222</td>\n",
       "      <td>17487884</td>\n",
       "      <td>R's answer circumvents this problem, by conveying the extent to which the questioned proposition (on the strict interpretation) is true.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30018</th>\n",
       "      <td>30018</td>\n",
       "      <td>51890955</td>\n",
       "      <td>We contrast using random negatives with carefully selected hard negatives that challenge the model to distinguish between true translation pairs versus non-translation pairs that exhibit some degree of semantic similarity.</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>10078</td>\n",
       "      <td>18458434</td>\n",
       "      <td>For example, 'sharp' and 'clear' are conceptually related to camera picture qualities, but they are not true synonyms from a linguistic perspective.</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>11092</td>\n",
       "      <td>31006069</td>\n",
       "      <td>This is especially true in overcoming language barriers of today's global communication besides supporting underresourced language.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11118</th>\n",
       "      <td>11118</td>\n",
       "      <td>226283642</td>\n",
       "      <td>Then, the model with attention focuses mainly on the repeated part and marks the misleading statement as \"true\".</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32581</th>\n",
       "      <td>32581</td>\n",
       "      <td>53080215</td>\n",
       "      <td>As in most cases of multiview learning, these three properties are only approximately true for our problem. (</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>4018</td>\n",
       "      <td>6745820</td>\n",
       "      <td>Next, we show the predicted and true distributions over attachment direction and distance.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15195</th>\n",
       "      <td>15195</td>\n",
       "      <td>248780356</td>\n",
       "      <td>If true, the experiments' performance is printed on the shell.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29023</th>\n",
       "      <td>29023</td>\n",
       "      <td>1211840</td>\n",
       "      <td>To describe our algorithm, we exploit an abstract data structure called a lazy list (aka generator, stream, pipe, or iterator), which supports three oper-ations: next(list): pops the front item from a list peek(list): returns the score of the front item empty(list): returns true if the list is empty A cube is a lazy list (of edges).</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>3957</td>\n",
       "      <td>2687019</td>\n",
       "      <td>However, as we do not have access to negative facts, the model would simply learn to predict all facts to be true.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35388</th>\n",
       "      <td>35388</td>\n",
       "      <td>18679018</td>\n",
       "      <td>The only difference is that we need to use words from previous sentences while we don't have true previous sentences but their best lists.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348</th>\n",
       "      <td>12348</td>\n",
       "      <td>1681159</td>\n",
       "      <td>This shows the true potential of the machine learning approach and the features chosen for the classification (see relatedness measures, Section 5.4).</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14598</th>\n",
       "      <td>14598</td>\n",
       "      <td>12665845</td>\n",
       "      <td>Therefore, at training time, we replace the label y ji for the i-th segment of the j-th document (system output) by y ji − Q (true) j , where Q (true) j is the true overall quality of the j-th document.</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20209</th>\n",
       "      <td>20209</td>\n",
       "      <td>53577360</td>\n",
       "      <td>To this end, the model can use the presence of \"exit\" to classify true-belief from non-true-belief tasks.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21130</th>\n",
       "      <td>21130</td>\n",
       "      <td>119069467</td>\n",
       "      <td>To create a negative sentence given a gold response, we pick a random phrase in the true response and replace it with a random phrase in another random true response.</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17930</th>\n",
       "      <td>17930</td>\n",
       "      <td>12505676</td>\n",
       "      <td>In our example, the premise to goal argument is the shortest, as it threads a path through the 6 nodes in the Argument Graph; the exclusive reasoning by cases argument is the longest, requiring 9 nodes (3 for the case where node 4 is false, 5 for the case where node 4 is true, and 1 for stating the conclusion); the non-exclusive reasoning by cases argument requires 8 nodes (3 for each case, 1 for node 6, which introduces the cases, and 1 for the conclusion); and the reductio ad absurdum argument requires 7 nodes (the 6 nodes in the Argument Graph plus 1 node for stating the conclusion).</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37828</th>\n",
       "      <td>37828</td>\n",
       "      <td>11987101</td>\n",
       "      <td>However, this is not exactly true.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>203591833</td>\n",
       "      <td>Model training We use negative log likelihood of the true labels as a loss function.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19906</th>\n",
       "      <td>19906</td>\n",
       "      <td>9016539</td>\n",
       "      <td>A true positive is a DNI which has been linked to the correct entity as given by the gold data.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34510</th>\n",
       "      <td>34510</td>\n",
       "      <td>600719</td>\n",
       "      <td>On the other hand, if we know both readings are true, then we can safely assert the ambiguous expression (2).</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17143</th>\n",
       "      <td>17143</td>\n",
       "      <td>10230907</td>\n",
       "      <td>Assertion (9) states that the signal \"AWID\" is true at the point of evaluation, and must remain true for next clock cycle before the single \"AWVALID\" will be true, while assertion (10) states that the signal \"AWID\" is true, and may remain true for up to 3 further clock cycles, directly after which the single \"AWVALID\" will be true.</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14344</th>\n",
       "      <td>14344</td>\n",
       "      <td>245218415</td>\n",
       "      <td>Although current systems achieve near-human F1 scores on this static evaluation, it is questionable whether this can faithfully reflect models' true performance in real-world applications.</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18714</th>\n",
       "      <td>18714</td>\n",
       "      <td>15548934</td>\n",
       "      <td>A preliminary manual analysis of the resulting list of relevant terms (true positives) revealed that a clear majority of the resulting terms were related to substance abuse -only one term was obviously problematic (years).</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38485</th>\n",
       "      <td>38485</td>\n",
       "      <td>52142083</td>\n",
       "      <td>Following the tenets of the TPACK Framework (Koehler &amp; Mishra, 2009) , which urges the researchers to consider the complex interplay of the three primary forms of knowledge: Content (C), Pedagogy (P), and Technology (T) and their intersections in the language classroom context, the researchers drew implications from these intersections: PCK or Pedagogical Content Knowledge, which refers to the knowledge of pedagogy that is applicable to the teaching of specific content that a teacher intends to teach; TCK or Technological Content Knowledge, which refers to the knowledge of the relationship between technology and content; TPK or Technological Pedagogical Knowledge, which refers to the components and capabilities of various technologies as they used in teaching and learning; and finally the TPACK or Technological Pedagogical Content Knowledge, which is the intersection of the three components characteristic of true technology integration in the classroom.</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32740</th>\n",
       "      <td>32740</td>\n",
       "      <td>202763196</td>\n",
       "      <td>It ranks all the entities in the graph for their likelihood to be the missing entity and the rank assigned to the true missing entity is considered.</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9236</th>\n",
       "      <td>9236</td>\n",
       "      <td>16456504</td>\n",
       "      <td>The true class for datum x i is denoted with xi .</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35568</th>\n",
       "      <td>35568</td>\n",
       "      <td>11996398</td>\n",
       "      <td>is true, then only the full scopings are returned. (</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16054</th>\n",
       "      <td>16054</td>\n",
       "      <td>204874503</td>\n",
       "      <td>The baseline model already corrects most typos, and while there are examples of phrases where the baseline model generates an incorrect word or inflection and the error-augmented model a correct one, the converse is true in other cases.</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1295</td>\n",
       "      <td>107331975</td>\n",
       "      <td>We listed payment in an attempt to see if Frey and Goette's theory would hold true (see above).</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26301</th>\n",
       "      <td>26301</td>\n",
       "      <td>12585424</td>\n",
       "      <td>In particular, we vary the ratio of positive (true relations) and negative (the class Other) examples in the ACE 2005 dataset and see how the system performance responds to this variation.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36925</th>\n",
       "      <td>36925</td>\n",
       "      <td>219302968</td>\n",
       "      <td>Operands are set-of-support phrases which have a true interpretation in the model.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32441</th>\n",
       "      <td>32441</td>\n",
       "      <td>202789710</td>\n",
       "      <td>Each item has at least 8 annotations indicating the extent to which the speaker of the sentences are committed to the truth of the embedded clause (+3/speaker is certain that it is true, 0/speaker is not certain about its truth, −3/speaker is certain that it is false).</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40140</th>\n",
       "      <td>40140</td>\n",
       "      <td>235097679</td>\n",
       "      <td>However, since the algorithm developed in this study is a binary classier, scores 1 and 2 were considered true (task preformed) and 0 was considered false.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>557</td>\n",
       "      <td>52808826</td>\n",
       "      <td>However, training on true case texts proved beneficial when translating from English to French, even when scoring in a case insensitive manner.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30132</th>\n",
       "      <td>30132</td>\n",
       "      <td>247447100</td>\n",
       "      <td>WMT'17 Edinburgh en-cs.l2r(1-4) ≤ 2 0 en-cs.r2l(1-4) ≤ 1 0 cs-en.l2r(1-4) ≤ 2 0 cs-en.r2l(1-4) 0 0 en-de.l2r(1-4) index c t , W ∈ R |C|×d , b ∈ R |C| Result: Whether c t is unargmaxable 1 unargmaxable = true 2 patience = 2500 3 x = w ⊤ c t 4 while patience do 5 c i = argmax(Wx + b) 6 if c i = c t then 7 unargmaxable = false 8 break 9 else 10 w = (w ct − w c i ) ⊤ 11 b = b ct − b c i 12 w ′ = w ∥w∥ 2 13 d = w ′ ⊤ x 14 x = x − 2(d + b ∥w∥ 2 )w ′ 15 patience = patience -1 16 end 17 end ≤ 1 0 en-de.r2l(1-4) ≤ 2 0 de-en.l2r(1-4) ≤ 2 0 de-en.r2l(1-4) 0 0 en-ru.l2r(1-4) 0 0 ru-en.l2r(1-4) 0 0 ru-en.r2l(1-4) 0 0 en-tr.l2r(1-4) ≤ 5 0 en-tr.r2l(1-4) ≤ 4 0 lv-en.l2r(1-4) 0 0 lv-en.r2l(1-4) ≤ 1 0 tr-en.l2r(1) 2 0 tr-en.l2r(2) 8 0 tr-en.l2r(3) 6 0 tr-en.l2r(4) 2 0 tr-en.r2l(1) 4 0 tr-en.r2l(2) 0 0 tr-en.r2l(3) 6 0 tr-en.r2l(4) 4 0 en-zh.l2r(1) 3 0 en-zh.l2r(2) 3 0 en-zh.l2r(3) 14 0 en-zh.l2r(4) 1 0 en-zh.r2l(1) 2 0 en-zh.r2l(2) 0 0 en-zh.r2l(3) 7 0 en-zh.r2l(4) 7 0 zh-en.l2r(1) 8 0 zh-en.l2r(2) 3 0 zh-en.l2r(3) 366 0 zh-en.r2l(1-3) ≤ 3 0 Table 8 : Unargmaxable token search results for Edinburgh WMT'17 submission (ensemble) models.</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8555</th>\n",
       "      <td>8555</td>\n",
       "      <td>51874206</td>\n",
       "      <td>It is true that movie dialogs promote stereotypes that may affect characters' expression of code-choice, however accommodative effects can still be expected to play out largely independent of such stereotypes.</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>1787</td>\n",
       "      <td>1039864</td>\n",
       "      <td>Let y denote a possible world, the p(y) is defined as follows (Richardson and Domingos, 2006) : p(y) = 1 Z exp   ∑ (ϕ i ,w i )∈M w i ∑ c∈C n ϕ i f ϕ i c (y)   , where each c is a binding of free variable in ϕ i to constraints; f ϕ i c (y) is a binary feature function that returns 1 if the true value is obtained in the ground formula we get by replacing the free variables in ϕ i with the constants in c under the given possible world y, and 0 otherwise; C n ϕ i is all possible bindings of variables to constants, and Z is a normalization constant.</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>11426</td>\n",
       "      <td>13174124</td>\n",
       "      <td>The symbols h a , l a , and d a are used to denote the head node, label, and dependent node, respectively, of an arc a (that is, a = (h a , l a , d a )); IN-SPAN(i) is true if i is contained in a span in S C ; END-SPAN(i) is true if i is the last word in a span in S C ; s(i) denotes the span containing i (with a dummy span for all words that are not contained in any span); r(s) denotes the designated root of span s (if any); #CC records the number of connected components in the current span up to and including the last word that was pushed onto the stack; NONE and ROOT are true if we allow no outgoing arcs from spans and if we allow outgoing arcs only from the span root, respectively.</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35418</th>\n",
       "      <td>35418</td>\n",
       "      <td>30167514</td>\n",
       "      <td>Accordingly, Einstein's formula М(х-x 0 ) 2 = 2....(1) was applicable as well as the Einstein-Fokker-Plank equation, which holds true for Markov's processes.</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>5228</td>\n",
       "      <td>218581979</td>\n",
       "      <td>In the process of search, we optimized for macro-average F 1 score, i.e., averaging over the classes, since our dataset is not balanced, which is true for both tasks.</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>7695</td>\n",
       "      <td>789848</td>\n",
       "      <td>One issue with our evaluation is that it assumes all tokens are true instances of the multiword unit in question; we carried out a manual inspection of multiword tokens identified by string match in our development sets (5000 sentences set aside from each of the abstract and blog corpora), and excluded from the evaluation a small set of idiomatic expressions (e.g. on it, do in) whose literal, non-MWE usage is too common for the expression to be used reliably for evaluation; otherwise, we were satisfied that the vast majority of multiword tokens were true matches.</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31495</th>\n",
       "      <td>31495</td>\n",
       "      <td>244051004</td>\n",
       "      <td>2002) and a number of examples presenting true and false MWEs.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15042</th>\n",
       "      <td>15042</td>\n",
       "      <td>1876856</td>\n",
       "      <td>The Chernoff bound says that for any δ &gt; 0, for the sum of n bernouilli variables with prob p and Now we bound each group separately, using the binomial Chernoff bound where n = mµ &gt; mp (which is true since p &lt; µ ) This bound decreases with p, so we can replace this for all strings in S k with the upper bound for the probability, and we can replace m with m 0 .</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39653</th>\n",
       "      <td>39653</td>\n",
       "      <td>10616494</td>\n",
       "      <td>Conflict and Cooperation The machines response and the true category is best seen as a set of multinomial probabilities (with a unit vector with the value 1 at the index of the system's extracted category or the true category respectively.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8472</th>\n",
       "      <td>8472</td>\n",
       "      <td>9975083</td>\n",
       "      <td>2013) and defines 11 groups of features to capture how likely each candidate answer is the true answer for the question from different aspects, which includes answer type coercion, candidate answer occurrence count, name count, average overlapping token count, stopword count, overlapping concept count, token and concept proximity, etc.</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>7177</td>\n",
       "      <td>1034340</td>\n",
       "      <td>If there exists a mapping from RMRS-D into RMRS-B such that: • for each index i, each anchor a, each label l and each relation r such that l:a:r(i) is in RMRS-D then for the corresponding label l', anchor a' and index i' it is true that l':a':r(i') is in RMRS-B; • for each anchor a, each index i and argument ARG such that a:ARG(i) is in RMRS-D then for the corresponding anchor a' and index i' it is true that a':ARG(i') is in RMRS-B; • for each handle h and each label l such that h =q l is in RMRS-D then for the corresponding handle h' and label l' it is true that h' =q l' is in RMRS-B; and • if l':a':i' is the hook of RMRS-B and for at least one of its elements there is a mapping from a corresponding element in RMRS-D, then there are mappings for all elements and original triple l:a:i is the hook of RMRS-D. then we say that RMRS-D is substructure of RMRS-B. The last condition is very strong and is subject to further refinement.</td>\n",
       "      <td>154</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24305</th>\n",
       "      <td>24305</td>\n",
       "      <td>233209981</td>\n",
       "      <td>Among our results, there are many examples where the model detected spans in not annotated posts, for example: • \"uhhh Hillary Clinton is a serial killer and thief\": [] (true annotation), [26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 44, 45, 46, 47, 48] (our annotation, \"uhhh Hillary Clinton is a serial killer and thief\"); • \"This goes way beyond just being an asshole skipper, dude must have some serious mental issues\": [] (true annotation), [35, 36, 37, 38, 39, 40, 41] (our annotation, \"This goes way beyond just being an asshole skipper, dude must have some serious mental issues\").</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>6330</td>\n",
       "      <td>14474596</td>\n",
       "      <td>Second, we argue that the true domain of lexical rules is not, in fact, the lexical item, but rather the referent of the lexical item.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21820</th>\n",
       "      <td>21820</td>\n",
       "      <td>174800717</td>\n",
       "      <td>This was in general true, although we observed a different pattern to the previous experiment.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37280</th>\n",
       "      <td>37280</td>\n",
       "      <td>245433917</td>\n",
       "      <td>The same is true for the scenario of merging MCI and mAD patients (i.e., the 2-class identification task).</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31868</th>\n",
       "      <td>31868</td>\n",
       "      <td>15726857</td>\n",
       "      <td>The future experiments will continue with new thesauri parsing: Russian, Spanish, Italian, but the true challenge shall be oriented towards Chinese / Japanese thesauri, aiming to establish a thorough lexical-semantics comparison and a language-independent, portable DEP technology based on SCD configurations.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33752</th>\n",
       "      <td>33752</td>\n",
       "      <td>7898970</td>\n",
       "      <td>A manual sampling of VPEs in the Brown Corpus showed this to be true.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31484</th>\n",
       "      <td>31484</td>\n",
       "      <td>18070886</td>\n",
       "      <td>The path in the decision tree where both Locative and Deictic are true may be accounting for utterances in which an identity expression is used, rather than a true deictic.</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10189</th>\n",
       "      <td>10189</td>\n",
       "      <td>218974040</td>\n",
       "      <td>We generate all the paths by the following: for each category c, each true candidate x and each connector o we gen- So basically, if the connector is not used by category c or if x is not a true instance of c, then the combinations of x and connector c can be followed by any arbitrary words.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19682</th>\n",
       "      <td>19682</td>\n",
       "      <td>59599691</td>\n",
       "      <td>An outcome which holds true for both data sets and two different ensemble model configurations (MarkerE and MarkerEB).</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17036</th>\n",
       "      <td>17036</td>\n",
       "      <td>15956331</td>\n",
       "      <td>Since we noticed that the number of \"false\" pairs is much larger than the number of \"true\" ones in the training data of every iteration, we defined another parameter (currently 6) that limits the factor of \"false\" pairs allowed in the training data with respect to the \"true\" pairs.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>26272</td>\n",
       "      <td>36965648</td>\n",
       "      <td>In a similar manner, the converse is true for the weights into the target unit representing the example (2).</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>13296</td>\n",
       "      <td>17506596</td>\n",
       "      <td>The converse is true for the remainder of the lexicon: the words will all the same frequency as in the smaller samples, but their ranks will have increased in proportion to their distance above the Figure 12 .</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26514</th>\n",
       "      <td>26514</td>\n",
       "      <td>231592352</td>\n",
       "      <td>Comparison with model that explicitly uses the true hierarchy We compare performance of our joint approach HIDDEN jnt against a state-of-the-art hierarchical multi-label classifier, HiLAP (Mao et al.,</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>4683</td>\n",
       "      <td>235127261</td>\n",
       "      <td>Building on continued Moses development of Moses in the academic community and combined with other open source projects, Moses for Localization can serve as a crucial building block in a true end-to-end open source machine translation solution for the localization industry.</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13831</th>\n",
       "      <td>13831</td>\n",
       "      <td>13614607</td>\n",
       "      <td>For sentences it will return the probability that the sentence is true.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18821</th>\n",
       "      <td>18821</td>\n",
       "      <td>7904050</td>\n",
       "      <td>2  Slang: As with profanity, it is intuitively true that true news articles tend to avoid slang.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28902</th>\n",
       "      <td>28902</td>\n",
       "      <td>2638760</td>\n",
       "      <td>However, the true probability cannot be known ahead of time and certainly not in a new domain.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38520</th>\n",
       "      <td>38520</td>\n",
       "      <td>52141013</td>\n",
       "      <td>First, belief propositions of the form B w x ϕ are defined by doxastic accessibility: 8 (6) a. B w x ϕ → ∀w .wR dox x w : w ∈ W ϕ b. ¬B w x ϕ → ∃w .wR dox x w : w ∈ W ϕ c. B w x ¬ϕ → ∀w .wR dox x w : w ∈ W ϕ Thus, \"x believes ϕ to be true at w\" (B w x ϕ) means that at all worlds compatible with x's beliefs at w, ϕ is true ; \"x does not believe ϕ to be true at w\" (¬B w x ϕ) means that at least at one world compatible with x's beliefs at w, ϕ is false, and \"x believes ϕ to be false at w\" (B w x ¬ϕ) means that at no worlds compatible with x's beliefs at w at which ϕ is true (ϕ is false at all worlds compatible with x's beliefs at w).</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16467</th>\n",
       "      <td>16467</td>\n",
       "      <td>11058419</td>\n",
       "      <td>The best results are obtained when combining all models, which remains true when considering mean results up to at least 8 rephrasings.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23473</th>\n",
       "      <td>23473</td>\n",
       "      <td>13391714</td>\n",
       "      <td>We use SVN repository version 2444, giving the options --modal true --nn true --roles verbnet to Boxer and making some minor modifications to its code to better match our annotation scheme for adjectives, adverbs, semantic roles and modals.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181</th>\n",
       "      <td>29181</td>\n",
       "      <td>382187</td>\n",
       "      <td>Precision is defined as the number of true instances divided by number of true positives and false negatives.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18126</th>\n",
       "      <td>18126</td>\n",
       "      <td>17493348</td>\n",
       "      <td>This is especially true since gestures usually take an extra effort from a user.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>2867</td>\n",
       "      <td>21731209</td>\n",
       "      <td>Qualitative analysis shows that L2W's continuation is often a straightforward continuation of the original text while the true continuation is more surprising and contains complex references to earlier parts of the book.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22186</th>\n",
       "      <td>22186</td>\n",
       "      <td>14792663</td>\n",
       "      <td>We then use cosine similarity over these vector space models as features: Title Features: LIEL also contains a number of features that make use of the Wikipedia title of the entity links in t (remember t = entity mention tuples and not a Wikipedia title) : • NIL FREQUENCY: Computes the frequency of entities that link to N IL • EXACT MATCH FREQUENCY: returns 1 if the surface form of m is a redirect for e; • MATCH ALL: returns true if m matches exactly the title of e; • MATCH ACRONYM: returns true if m is an acronym for a redirect of e; • LINK PRIOR: the prior link probability P (e|m), computed from anchor-title pairs in KB (described in Section 2.3).</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>34521</td>\n",
       "      <td>600719</td>\n",
       "      <td>However, if only one of R1 and R2 is true, then there is a model where Q is false, namely where R1 is true and C1 is false, and C2 is true but R2 is false, or vice versa.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8196</th>\n",
       "      <td>8196</td>\n",
       "      <td>7708706</td>\n",
       "      <td>Given a word w and two opposing styles (topics) p and n, we place w on the PN dimension according to the β of our trained model as follows: PN w = β pw − β nw β pw + β nw The normalization is important because otherwise more-common words would tend to have higher PN's, when in fact the opposite is true (rare words tend to be more stylistically prominent).</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31813</th>\n",
       "      <td>31813</td>\n",
       "      <td>15134057</td>\n",
       "      <td>° b) another approach however consists in regarding the data base as a set of fomaulas and the process of answering a query as a deduction° A query wil] be said to be true with respect to the ~ita ]mse if and only if it can I~ &lt;]educed frc~n ]to (Naturally as in the case of the first approach, this meth(x] app].ies (~qual]y well to closed sentences ( i°e yes-no questions) as well as to open sentences ( i.e W[I-questions)° ],'or an application of this im~thod as wo].l as for disc:ussion of its advantages (cf [PASERO~ 73])° ].'o~. reasons which w~ sha]l not spell out here we have chosen the ~ode] the(met]ca] approach (].e the first approach ) in OPERA° Needless to say it: is not Loo difficult and in fact, sclnetimes necessary~ as we shall see below, to c&lt;mlpl6]nent the pure se~nantic evaluation with deductivo capacities.. 2-Sh:MANTICS VIA TRANS~TION IN'IY) LOGIC Even if it is clear in nmst respects how to obtain predicate logic: translaticms for a large w~riety of natura] language sentences, cf [WAR[~FM &amp; PEREIRA, 82] we repeat here :[or the sake of clarity the essentials of the translation process in OPERA.</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31457</th>\n",
       "      <td>31457</td>\n",
       "      <td>10505260</td>\n",
       "      <td>It lower bounds the true distances of original data (Lin et al.,</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>18180</td>\n",
       "      <td>214802016</td>\n",
       "      <td>These results show that, though setting a threshold is a common heuristic to balance true and false acceptance rates (Larson et al.,</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30373</th>\n",
       "      <td>30373</td>\n",
       "      <td>7523960</td>\n",
       "      <td>As long as an upward path takes at least one step, making it to a scheme containing two or more alternating suffixes, our search strategy accepts the terminal scheme of the path as likely modeling a portion of a true inflection class.</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18609</th>\n",
       "      <td>18609</td>\n",
       "      <td>222379592</td>\n",
       "      <td>However, these sequences are unlikely to have any semantic correlation with the true label.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13287</th>\n",
       "      <td>13287</td>\n",
       "      <td>5220041</td>\n",
       "      <td>The fundamental assumption, in our \"unsupervised\" technique for WSD in this paper, is that the similarity of contextual features of the target with the pre-defined features of its sense in the lexical knowledge base provides a quantitative cue for identifying the true sense of the target.</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39441</th>\n",
       "      <td>39441</td>\n",
       "      <td>6574418</td>\n",
       "      <td>This allows the phrase to be selected or adjoined to again by anything that selects or adjoins to X. This model accounts for optionality and true transparency: the modified element remains the head ( Since this grammar is designed to model unordered modifiers, illicit orders are also derivable (Figure 6 ).</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12665</th>\n",
       "      <td>12665</td>\n",
       "      <td>247939929</td>\n",
       "      <td>Misclassifications occur when the inferred label y i of an input x i does not correspond to the actual true label ŷi and thus ŷi = y i holds.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32767</th>\n",
       "      <td>32767</td>\n",
       "      <td>18932500</td>\n",
       "      <td>This is especially true of phonotactics: reduplication and metathesis, which have higher complexity, are not phonotactic patterns as they involve alternations.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>2746</td>\n",
       "      <td>6386563</td>\n",
       "      <td>Moreover, let the boolean function L(a i , u i ) to be true if the anchor text a i points to url u i .</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40262</th>\n",
       "      <td>40262</td>\n",
       "      <td>10350260</td>\n",
       "      <td>This conjecture seems to be true for natural languages (the contrary would mean the possibility of unlimited extraction from extracted groups).</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33325</th>\n",
       "      <td>33325</td>\n",
       "      <td>237581611</td>\n",
       "      <td>Questions we ask to search engines are often done in the comfort of our own homes, making them likely to reflect true stereotypes that are out there in the real world (Stephens-Davidowitz, 2018 • 'Why is [TGT] so [ATTR] ?' • '</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>2643</td>\n",
       "      <td>16531053</td>\n",
       "      <td>This is true of automatic summarization systems too, which consider the position of a sentence in a document and how it relates to its surrounding sentences (Kupiec, Pedersen, and Chen 1995; Barzilay and Elhadad 1997; Marcu 2000; Teufel and Moens 2002) .</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>859</td>\n",
       "      <td>7207849</td>\n",
       "      <td>In part this is true: most words translate to a word which is identical in its form and they happen to appear largely in the same order.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>5002</td>\n",
       "      <td>227230600</td>\n",
       "      <td>However, this kind of pattern is not always true and an opposite case is shown in Figure 2 (b) .</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30805</th>\n",
       "      <td>30805</td>\n",
       "      <td>231643046</td>\n",
       "      <td>Though it is true that the improvement was relatively small (between 1 % and 3 %), we must remember that in these cases the method was applied to a percentage of the synsets in Word-Net.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32853</th>\n",
       "      <td>32853</td>\n",
       "      <td>62853828</td>\n",
       "      <td>But the same is not true for grammatical relations, and we get both OBJ(eat,banana, ) and OBJ(eat,apple, ).</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18206</th>\n",
       "      <td>18206</td>\n",
       "      <td>6819967</td>\n",
       "      <td>In future work, it would be useful to build a ternary classifier which labels Agree/Disagree/Neutral, thus reflecting the true distribution of these dialogue acts in the data.</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33495</th>\n",
       "      <td>33495</td>\n",
       "      <td>543</td>\n",
       "      <td>In general a probabilistic algorithm will make an estimate, 15, of this probability: 15(A= llV=v, Nl=nl, P=p, N2=n2) For brevity this estimate will be referred to from here on as: p(l[v, nl,p, n2) The decision can then be made using the test: ~(llv, nl,p, n2 ) &gt;= 0.5 If this is true the attachment is made to the noun, !</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>16923208</td>\n",
       "      <td>The stability of evaluation results Question A can be rephrased in the following way: How much does the observed precision value for an acceptance region A differ from the true average precision π A ?</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30084</th>\n",
       "      <td>30084</td>\n",
       "      <td>220045140</td>\n",
       "      <td>While the work presented here targets possession relations, we believe that a similar approach could be used to to determine for how long any semantic relation holds true.</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>4167</td>\n",
       "      <td>232222259</td>\n",
       "      <td>This certainly rings true for NLP as well.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15653</th>\n",
       "      <td>15653</td>\n",
       "      <td>16097412</td>\n",
       "      <td>In addition, we will produce a corpus of annotated (true and false) instances that can later be used as training data.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14957</th>\n",
       "      <td>14957</td>\n",
       "      <td>3888499</td>\n",
       "      <td>We aim to predict a quality class ĉ for each article, such that ĉ is as close as possible to the true latent quality class c of the article.</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28349</th>\n",
       "      <td>28349</td>\n",
       "      <td>231602963</td>\n",
       "      <td>While the classification accuracy is important, it is more important that given a sample is misclassified, the predicted label is close to the true label.</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24433</th>\n",
       "      <td>24433</td>\n",
       "      <td>233189596</td>\n",
       "      <td>First, while encountering a scientific claim, we need to identify the true fact related to the claim from the knowledge base (in most cases the source journal article).</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21896</th>\n",
       "      <td>21896</td>\n",
       "      <td>221818956</td>\n",
       "      <td>To further capture causal and temporal dependencies between sentences in a reasonable story, they employ multi-task learning which combines a discriminative objective to distinguish true and fake stories during fine-tuning.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29319</th>\n",
       "      <td>29319</td>\n",
       "      <td>13163488</td>\n",
       "      <td>The value being true means that the model has estimated Shift actions to all the target nodes (from i = 1 to i = |T |) in the parsing process, then the parser stops the analysis and outputs the subtrees in T, because no further action is possible.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8963</th>\n",
       "      <td>8963</td>\n",
       "      <td>237055475</td>\n",
       "      <td>This SMT model is of very high quality thanks to the amount of training data (especially true for English-French: with more than 8 Million parallel translation units as released in COPPA corpus 3 ).</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>637</td>\n",
       "      <td>5187134</td>\n",
       "      <td>The input text and the hypothesis were considered as a problem of binary classification ('true' or 'false').</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38585</th>\n",
       "      <td>38585</td>\n",
       "      <td>221097958</td>\n",
       "      <td>If no ps exist, the conclusion is vacuously true; otherwise, we may choose some q to which every p is related, and the conclusion is certainly true.</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1514</td>\n",
       "      <td>226284017</td>\n",
       "      <td>The imbalanced dataset results in an excessive number of true negatives rather than true positives.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39075</th>\n",
       "      <td>39075</td>\n",
       "      <td>201740458</td>\n",
       "      <td>The ambiguity of source morphology is the true ambiguity rate of the language (according to the morphological analyser), i.e. how many potential interpretation each word has.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9097</th>\n",
       "      <td>9097</td>\n",
       "      <td>248780508</td>\n",
       "      <td>Although it is true that creating a language repository alone cannot revert language endangerment or decay, there are several ways in which documentation data can be integrated into revitalisation projects.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>5903</td>\n",
       "      <td>9013266</td>\n",
       "      <td>For instance, the sentence \"Ana y Juan hablan espafiol y franc6s\" (Ann and John speak Spanish and French), which translates roughly into speak({Ann,John], {Spanish,French]), introduces a distributive plural and must therefore evaluate to true (false) if the following formulas are all true (false): speak(Ann,Spanish) speak(John,Spanish) speak(Ann,French) speak(John,French) On the other hand, the sentence \"A y B son paralelas\" (A and B are parallel), which translates into parallel({A,B]), introduces a collective plural and must evaluate to either true or false as a result of testing the whole set {A,B} for the property of being parallel.</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22922</th>\n",
       "      <td>22922</td>\n",
       "      <td>218487098</td>\n",
       "      <td>We analyze wrongly predicted spans by their true category.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31007</th>\n",
       "      <td>31007</td>\n",
       "      <td>6161073</td>\n",
       "      <td>Levin takes a useful approach in reducing the size of true state space by simply tracking when a particular state variable has a value rather than including the specific value in the state.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22750</th>\n",
       "      <td>22750</td>\n",
       "      <td>233189603</td>\n",
       "      <td>We conclude that if we do not see alignment improvement on the QC-HQ setting (as is true of ATOMIC-PIQA), then extraction does not indicate the best knowledge gap coverage.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29711</th>\n",
       "      <td>29711</td>\n",
       "      <td>201666088</td>\n",
       "      <td>The partial annotation of coreference data for mention detection means that not labeled spans may be true mentions of entities.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36111</th>\n",
       "      <td>36111</td>\n",
       "      <td>18860723</td>\n",
       "      <td>Second, the reported improvement cover corrections of vocabulary deficiencies, not only true transcription mistakes due to weaknesses of the language model.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30261</th>\n",
       "      <td>30261</td>\n",
       "      <td>239017038</td>\n",
       "      <td>We straightforwardly use pairs of contexts and their true re-sponses from DOMAINREDDIT as positive training instances.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>7575</td>\n",
       "      <td>8333909</td>\n",
       "      <td>Under some circumstances, such an error-correction capability might induce comprehenders to adopt grammatical analyses that are inconsistent with the true input.</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32322</th>\n",
       "      <td>32322</td>\n",
       "      <td>18733074</td>\n",
       "      <td>On CDCP, where the number of true links is 272, the linear baseline with strict inference predicts 796 links with a precision of only 16%, while the strict structured RNN only predicts 52 links, with 33% precision; the example in Figure 5 illustrates this.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25957</th>\n",
       "      <td>25957</td>\n",
       "      <td>237213618</td>\n",
       "      <td>For example, the fact (Liu Cang, sibling, Liu Yan) is true, but is not included by KG, resulting in the inferred answer being judged as wrong.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13426</th>\n",
       "      <td>13426</td>\n",
       "      <td>9707387</td>\n",
       "      <td>The text describes some situation or setting, and the query in the simplest case asks whether a particular statement is true of the situation described in the text.</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32839</th>\n",
       "      <td>32839</td>\n",
       "      <td>220046708</td>\n",
       "      <td>The ELBO on the marginal likelihood of the finance documents is as follows: where q φ (z|D) is an approximation to the true posterior p θ (z|D).</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32346</th>\n",
       "      <td>32346</td>\n",
       "      <td>5753846</td>\n",
       "      <td>The true error rate is almost invariably higher than the apparent error rate.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21295</th>\n",
       "      <td>21295</td>\n",
       "      <td>201657818</td>\n",
       "      <td>One reason is that STRESS decreases word overlap rate and injects negation words by appending distractor phrases, i.e. \"true is true\" and \"false is not true\".</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2701</td>\n",
       "      <td>1200082</td>\n",
       "      <td>However, such skip normally reflects the true searching intent because novel relevant feedbacks always have more attractions after all.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30556</th>\n",
       "      <td>30556</td>\n",
       "      <td>6795973</td>\n",
       "      <td>Since the task, which involved identifying, on average, 3.33 true positives among 2596 candidates, was more challenging, the recall values are lower than in Figure 1 .</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12184</th>\n",
       "      <td>12184</td>\n",
       "      <td>16075189</td>\n",
       "      <td>2014 ) report κ = 0.4), so discarding candidates without a clear majority decision can be seen as discarding those for which the true label is not well defined.</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8271</th>\n",
       "      <td>8271</td>\n",
       "      <td>21701770</td>\n",
       "      <td>Human-judged Synonyms: The prediction is judged as true by the expert (but is not present in the glossary). *</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38855</th>\n",
       "      <td>38855</td>\n",
       "      <td>15030503</td>\n",
       "      <td>The lower fee paid to external translators is based on the premise that postediting saves them some typing and part of the time they need to consult dictionaries and reference works, which is generally true.</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12388</th>\n",
       "      <td>12388</td>\n",
       "      <td>202784449</td>\n",
       "      <td>de i,j and d e i,j denote the true distribution and predicted distribution of entity categorical labels, respectively.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>1157</td>\n",
       "      <td>9080688</td>\n",
       "      <td>We can then see from Table 3 that b-LID outperforms every other system by a large margin: 7 it is excellent at distinguishing between true entailments, and while it misses some good identity replacements, is not handicapped in this respect relative to the other systems, which are also unable to model them.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22789</th>\n",
       "      <td>22789</td>\n",
       "      <td>18340881</td>\n",
       "      <td>Although the fact stay-in(Snowden, Hong Kong) is true, it is harmful to include \"Snowden will stay in Hong Kong\" in the training for travel-to(person, location).</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15115</th>\n",
       "      <td>15115</td>\n",
       "      <td>234345309</td>\n",
       "      <td>But, this statement is not true in the case of the children with ASD.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>7773</td>\n",
       "      <td>28572853</td>\n",
       "      <td>The same is true for another type of relational annotation, discourse analysis, and a future version of the corpus should therefore include a running text section from a source, where this is not a copyright problem.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19849</th>\n",
       "      <td>19849</td>\n",
       "      <td>235097421</td>\n",
       "      <td>Unsupervised Baseline: Text Classification as Natural Language Inference Natural language inference (NLI) is the task of determining if a hypothesis is true (entailment), false (contradiction), or undetermined (neutral) given a premise 8 (Table 3 ).</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25255</th>\n",
       "      <td>25255</td>\n",
       "      <td>10539461</td>\n",
       "      <td>In the logic formalisms, \"negation is the only significant monadic functor,\" whose behavior is described by the Law of Contradiction that asserts that no proposition can be both true and not true.</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>2357</td>\n",
       "      <td>426998</td>\n",
       "      <td>Our experimentation also shows that the CRF model is much complementary to the ME model in trigger identification with a high precision of 83.7 units and a low recall of 43.3 units, and the new constraint helps bring back 1.9% of true trigger mentions.</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27167</th>\n",
       "      <td>27167</td>\n",
       "      <td>18289778</td>\n",
       "      <td>Compatibility and Backward Dependency Match As mentioned in Section 2, the independency assumption of phrase tokenization is not always true.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21921</th>\n",
       "      <td>21921</td>\n",
       "      <td>226226713</td>\n",
       "      <td>One limitation of any analysis of social bias on TVTROPES is that the website may not be representative of the true distribution of tropes within media.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18017</th>\n",
       "      <td>18017</td>\n",
       "      <td>1583135</td>\n",
       "      <td>By varying the relative size of an animal and the number of cells in the matrix (or number of digits) imaged next to it, it was demonstrated that size and number of parts had independent effects on time to verify properties of the image (see Kosslyn, in press; 1974) property appropriate for, the image, the subject was to respond \"true\" as quickly as possible (after consulting an image), otherwise he was to respond \"false.\"</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>3416</td>\n",
       "      <td>16210778</td>\n",
       "      <td>They do not receive any formal training and do not have access to true annotations except a few examples if provided by the requester.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18920</th>\n",
       "      <td>18920</td>\n",
       "      <td>746333</td>\n",
       "      <td>Furthermore, it is unable to cope with noisy dimensions (this is especially true in the case of the text data) and highly non-ellipsoid clusters. (</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35735</th>\n",
       "      <td>35735</td>\n",
       "      <td>2262192</td>\n",
       "      <td>Suggested fixes to the representations Of the 74 true positives, the judges felt that 17 of the bad representations should be fixed by splitting the predicate into multiple senses.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17088</th>\n",
       "      <td>17088</td>\n",
       "      <td>248157591</td>\n",
       "      <td>This logical relationship can either be Entailment (premise is true implies the hypothesis is absolutely true), Contradiction (premise is true implies the hypothesis is absolutely false), and Neutral (one cannot determine if the hypothesis is true or false based on the premise) (Dagan et al.,</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>3897</td>\n",
       "      <td>222140820</td>\n",
       "      <td>This also holds true for Rotowire tableto-text generation, where our models surpass previously reported metrics for content selection, planning and ordering, highlighting the strength of stepwise modeling.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22313</th>\n",
       "      <td>22313</td>\n",
       "      <td>2845210</td>\n",
       "      <td>Special thanks go to Prof. Jianmin Yao at Soochow University and Suzhou Scientific Service Center of China for his advices and suggestions that help this paper finally come true.</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>4530</td>\n",
       "      <td>237503252</td>\n",
       "      <td>In this way, empirical evaluations can test more accurately the true linguistic capabilities of the models.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19061</th>\n",
       "      <td>19061</td>\n",
       "      <td>14647620</td>\n",
       "      <td>We also observe that although the top-ranked output of the CRF model is not always correct, the true abbreviation very often appears in the top few outputs of the CRF.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15551</th>\n",
       "      <td>15551</td>\n",
       "      <td>6630458</td>\n",
       "      <td>A constraint is true if when all the propositions in the right hand side of the constraint are true, the left han(l prop(.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2072</td>\n",
       "      <td>226262339</td>\n",
       "      <td>Crowdsourced Evaluators Crowdworkers on Mechanical Turk are presented with the 500 test set claims and instructed to use a search bar to decide if the claim is true, false, or in the middle.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855</th>\n",
       "      <td>12855</td>\n",
       "      <td>227231118</td>\n",
       "      <td>By definition, precision is the number of true positives divided by the number of all non-null results retrieved by the system, recall is the number of true positive samples divided by the total number of positives, and F1 is the harmonic mean of precision and recall.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31114</th>\n",
       "      <td>31114</td>\n",
       "      <td>2401184</td>\n",
       "      <td>Conversely, the falsity of any of them is sufficient to make (1) true: (1) would be true if nobody got anything, we didn't get, an offer wasn't gotten or the offer wasn't for more than $40.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32749</th>\n",
       "      <td>32749</td>\n",
       "      <td>201103945</td>\n",
       "      <td>This is especially true if we consider languages other than English, ever since the influ-ential CoNLL shared tasks on dependency parsing in 2006 (Buchholz and Marsi, 2006) and 2007 (Nivre et al.,</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21501</th>\n",
       "      <td>21501</td>\n",
       "      <td>229924289</td>\n",
       "      <td>The overall model, shown in Figure 3 , takes a corrupted event sequence x = {e i } as input, and outputs the true event sequence y = {e j }.</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29995</td>\n",
       "      <td>5846516</td>\n",
       "      <td>For our context model, we address this problem using distant supervision: we treat all contexts of an entity that can have type t as contexts of type t even though this assumption will in general be only true for a subset of these contexts.</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13051</th>\n",
       "      <td>13051</td>\n",
       "      <td>10464407</td>\n",
       "      <td>Oenerally speaking, the converse of this is also true,and only a Poisson process would produce exponential decay.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36031</th>\n",
       "      <td>36031</td>\n",
       "      <td>3856149</td>\n",
       "      <td>This view may turn out to be true but it is impossible to discuss it.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28313</th>\n",
       "      <td>28313</td>\n",
       "      <td>233189520</td>\n",
       "      <td>Calculating the upper bound essentially comes down to associating each word in the dataset to the largest possible number N given m: N = i m i (5) To demonstrate that, no matter what the vectors were the compression would work, we show the upper bounds compared to the size of the original dataset of 50-dimensional GloVe embeddings and the true CRT-compressed dataset of those embeddings on Table 4 .</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29997</td>\n",
       "      <td>5846516</td>\n",
       "      <td>Assumptions that result in errors: The performance of all models suffers from a number of assumptions we made in our training / evaluation setup that are only approximately true.</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40162</th>\n",
       "      <td>40162</td>\n",
       "      <td>1840980</td>\n",
       "      <td>Evaluation Evaluation was to be carried out according to the following F-scores:  Strict F-score: a predicted mention is considered a true positive if: 1.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30231</th>\n",
       "      <td>30231</td>\n",
       "      <td>6694415</td>\n",
       "      <td>We introduce a unary predicate called holds over string constants to capture the probability of a string constant being true given the setup is true (∀x ∈ setup, holds(x) = true) and the KB rules hold.</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37921</th>\n",
       "      <td>37921</td>\n",
       "      <td>184483092</td>\n",
       "      <td>The absence of true labels for both the dev and the test set prevents us from conducting an error analysis.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>2057</td>\n",
       "      <td>15227710</td>\n",
       "      <td>For each relation type, P is the ratio of the true relation instances in all the relation instances being identified, R is the ratio of the true relation instances being identified in all the true relation instances in the corpus, and F1 is the harmonic mean of P and R. The overall performance P/R/F1 is then calculated using the micro-average measure over all major class types.</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25384</th>\n",
       "      <td>25384</td>\n",
       "      <td>14095018</td>\n",
       "      <td>During training the class that corresponds to the column with the greatest sum is compared to the true class and if it is correct no change is made.</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35607</th>\n",
       "      <td>35607</td>\n",
       "      <td>15637201</td>\n",
       "      <td>The maximum likelihood estimate for τ is x n , however for small values of x this estimate has a high variance and can significantly overestimate the true value.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19809</th>\n",
       "      <td>19809</td>\n",
       "      <td>16617195</td>\n",
       "      <td>For example, 62% of the true responses are produced only by 1 or 2 of the 18 SF systems.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37650</th>\n",
       "      <td>37650</td>\n",
       "      <td>13579675</td>\n",
       "      <td>The expected value is determined using the unconditional distribution, on the assumption that if the null hypothesis is true then this distribution will correlate with the conditional distribution.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24246</th>\n",
       "      <td>24246</td>\n",
       "      <td>250390646</td>\n",
       "      <td>We tested EFEX on the EFCAMDAT test set and we obtained significant results when comparing the true labels with the predicted ones in terms of PCC (see Table 8 ).</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35458</th>\n",
       "      <td>35458</td>\n",
       "      <td>5304321</td>\n",
       "      <td>This holds true for all estimation methods tried.</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>2877</td>\n",
       "      <td>765547</td>\n",
       "      <td>If we knew which derivation in each forest was the \"true\" derivation, then we could straightforwardly collect rule counts off those derivations.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25320</th>\n",
       "      <td>25320</td>\n",
       "      <td>774866</td>\n",
       "      <td>moll 'wet', morat 'purple', mutu 'mutual', notori 'notorious', ocult 'hidden', opac 'opaque', paradoxal 'paradoxical', peculiar 'peculiar', perillós 'dangerous', pertinent 'pertinent', pessimista 'pessimistic', plàcid 'placid', precoç 'precocious', predilecte 'favorite', primari 'primary', primitiu 'primitive', propens 'prone', pròsper 'prosperous', prudent 'prudent', punxegut 'sharp-pointed', quadrat 'square', reaccionari 'reactionary', recent 'recent', recíproc 'reciprocal', remarcable 'remarkable', responsable 'responsible', rígid 'rigid', roent 'burning', sant 'saint', semicircular 'semicircular', seriós 'serious', significatiu 'significant', silenciós 'silent', similar 'similar', simplista 'simplistic', subaltern 'subordinate', sublim 'sublime', subsidiari 'subsidiary', subterrani 'underground', superflu 'superfluous', tenaç 'tenacious', terrible 'terrible', típic 'typical', titular 'titular, official', tort 'bent', total 'total', tou 'soft', triangular 'triangular', vague 'vague', ver 'true', viciós 'vicious', vigorós 'vigorous', viril 'virile', vulgar 'vulgar'.</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>2212</td>\n",
       "      <td>5715019</td>\n",
       "      <td>Even with semi-supervised approaches, which use a large unlabeled corpus, manual construction of a small set of seeds known as true instances of the target entity or relation is susceptible to arbitrary human decisions.</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>2163</td>\n",
       "      <td>9203411</td>\n",
       "      <td>Our variational approximation takes the following form: Q(T, L, Z r , A p , τ , π) = δ r (Z r , L) n k=1 q k (T k ) np i=1 r i (A p i ) δ s (τ )δ d (π) We use a mean field approach to update each of the RHS factors in turn to minimize the KL-divergence between the current variational posterior and the true model posterior.</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35920</th>\n",
       "      <td>35920</td>\n",
       "      <td>14621757</td>\n",
       "      <td>We represent an infon as a term of the form Sit : P, which means that p is true in the situation Sit.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19890</th>\n",
       "      <td>19890</td>\n",
       "      <td>344550</td>\n",
       "      <td>Trigger type consistency is motivated by one observation: documents in the ACE 2005 Chinese corpus are mostly news articles, each of which describes one theme, and most of the true triggers are compatible with this document theme.</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>6022</td>\n",
       "      <td>2731424</td>\n",
       "      <td>This is because our focus is on evaluating pairwise approach versus the graph partitioning approach and also comparing them to some state-of-the-art approaches which also use true mentions.</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15706</th>\n",
       "      <td>15706</td>\n",
       "      <td>14446047</td>\n",
       "      <td>Condition 2 is true as the Kullback-Leibler Divergence is never smaller than 0 and the same is true for the Euclidean norm.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20600</th>\n",
       "      <td>20600</td>\n",
       "      <td>7206421</td>\n",
       "      <td>However, formulas with high scores in PRA are not always true.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7122</th>\n",
       "      <td>7122</td>\n",
       "      <td>244119739</td>\n",
       "      <td>These shortcomings are mainly are a result of commonly used automatic evaluation methods (like BLEU) using only surface-level similarity; they do not strictly measure , Semantic Equivalence (SE), which is the true goal.</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14950</th>\n",
       "      <td>14950</td>\n",
       "      <td>14974322</td>\n",
       "      <td>Statistical-based collocation extraction approaches suffer from (1) low precision rate because high co-occurrence bi-grams may be syntactically unrelated and are thus not true collocations; (2) low recall rate because some true collocations with low occurrences cannot be identified successfully by statistical-based models.</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25726</th>\n",
       "      <td>25726</td>\n",
       "      <td>729163</td>\n",
       "      <td>Most importantly, it is not clear what should be the 'true' senses of a word.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32709</th>\n",
       "      <td>32709</td>\n",
       "      <td>249625490</td>\n",
       "      <td>Denoising Techniques Noisy training examples can be thought of as the result of perturbing the true, underlying labels by some source of noise.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36387</th>\n",
       "      <td>36387</td>\n",
       "      <td>6048999</td>\n",
       "      <td>Precision is the percentage of boundaries identified by an algorithm that are indeed true boundaries; recall is the percentage of true boundaries that are identified by the algorithm.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12304</th>\n",
       "      <td>12304</td>\n",
       "      <td>195750836</td>\n",
       "      <td>We observe that in most regions of the brain, the predicted and true activity agree on the activity sign, thereby providing evidence that deep learning representations can capture useful information about language processing consistent with the brain recording.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17952</th>\n",
       "      <td>17952</td>\n",
       "      <td>3896503</td>\n",
       "      <td>As stated, the EBC rule makes a true prediction about u-ambiguous defnps which occur in sentences following the focus: they are c¢)-referential with the focus, and hence disambiguated as non-generic.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>6297</td>\n",
       "      <td>17161699</td>\n",
       "      <td>The truth conditions state that a IRS K is true in a model M if there is a proper imbedding from K Into M. Proper embedding is defined as a f~mction f from the set of discourse referents of K in to M s.t. (</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33023</th>\n",
       "      <td>33023</td>\n",
       "      <td>243865381</td>\n",
       "      <td>Hierarchical-F1 is a commonly used measure for hierarchical classification tasks that compares the true path from the true parent to the root with the predicted path (Kiritchenko et al.,</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16053</th>\n",
       "      <td>16053</td>\n",
       "      <td>248962366</td>\n",
       "      <td>This will ensure that the sentiment state of the generated output by the VA is consistent with the true output.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>4963</td>\n",
       "      <td>14552960</td>\n",
       "      <td>Results from each category were compiled in 2 x 2 contingency tables like Table 3 , where tp stands for \"true positive\" and fn for \"false negative\".</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>1901</td>\n",
       "      <td>16377016</td>\n",
       "      <td>Each node includes three different components: (1) A precondition that must be true before the subtask is executed; (2) A description of the node that includes its label and identifier; and (3) Links to nodes that will be executed at the subsequent turn.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2016</td>\n",
       "      <td>10714273</td>\n",
       "      <td>Cameras had more relevant than not relevant tweets, while the opposite was true for mobile devices and game consoles.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27012</th>\n",
       "      <td>27012</td>\n",
       "      <td>6980436</td>\n",
       "      <td>a default rule: P is assumed to be true if Q is true or assumed to be true and there is no definite evidence to the contrary.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34447</th>\n",
       "      <td>34447</td>\n",
       "      <td>9163485</td>\n",
       "      <td>$uch conclusions may be true, and this is why the values in Tab.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>6892</td>\n",
       "      <td>220057351</td>\n",
       "      <td>PRMSE with reference to true scores The simulations in the previous sections demonstrate that the values of metrics usually used to evaluate automated scoring systems are directly dependent on the quality of human ratings used to evaluate the system.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>9935</td>\n",
       "      <td>248118589</td>\n",
       "      <td>Jacovi and Goldberg (2020) define faithfulness as \"how accurately [explanations] reflects the true reasoning process of the model.\"</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14899</th>\n",
       "      <td>14899</td>\n",
       "      <td>231986109</td>\n",
       "      <td>When using only 10% data, the error is larger and ENIGMA has lower correlation with the true reward.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18502</th>\n",
       "      <td>18502</td>\n",
       "      <td>11574815</td>\n",
       "      <td>As we can see, for news stories text order by itself is a poor predictor of chronological order (only 3.71% correlation with the true order).</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>8374</td>\n",
       "      <td>202782321</td>\n",
       "      <td>We consider two assumptions in this work as the same has been done in the baseline, -(a) every sarcastic text has at least one sarcasm target as this holds true by the definition of sarcasm, and, (b) the notion of sarcasm target is applicable for sarcastic texts only.</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023</th>\n",
       "      <td>10023</td>\n",
       "      <td>237451171</td>\n",
       "      <td>The L2-Error is the L2-Norm of the difference between the predicted user distribution and the true user goal.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37110</th>\n",
       "      <td>37110</td>\n",
       "      <td>2468783</td>\n",
       "      <td>Therefore, a good measure of relational similarity, sim r , should obey the following equation: sim r (A : B, C : D) = sim r (B : A, D : C) ( 8 ) In steps 5 and 6 of the LRA algorithm (Section 5.5), we ensure that the matrix X is symmetrical, so that equation ( 8 ) is necessarily true for LRA.</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>4927</td>\n",
       "      <td>11131833</td>\n",
       "      <td>Evaluation by hand identified 232 true collocations in the set A test set.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>3090</td>\n",
       "      <td>44113199</td>\n",
       "      <td>When the condition is true, then the result would apply.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12729</th>\n",
       "      <td>12729</td>\n",
       "      <td>218973702</td>\n",
       "      <td>We regarded the anchor texts as mentions and the entities that anchor texts referred to were considered as the true entities.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30081</th>\n",
       "      <td>30081</td>\n",
       "      <td>220045140</td>\n",
       "      <td>Possession Duration How long do possession relations hold true for?</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30387</th>\n",
       "      <td>30387</td>\n",
       "      <td>5371028</td>\n",
       "      <td>If we suppose that the number of languages is finite, let us denote it n, counting the number of \"true analogies\" in a set of sentences in a given language, say L 1 , is tantamount to counting the cases described by the following formula (ii).</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22469</th>\n",
       "      <td>22469</td>\n",
       "      <td>235303672</td>\n",
       "      <td>This method relies on the assumption that the two embedding spaces are structurally similar, which does not necessarily hold true in general.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27148</th>\n",
       "      <td>27148</td>\n",
       "      <td>1130969</td>\n",
       "      <td>Given the cover, the overall plural predication holds just in case the basic property denoted by the predicate is true (collectively)of each of the sets (or CELLS) in the cover.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>1790</td>\n",
       "      <td>7628635</td>\n",
       "      <td>Most of these candidates are in fact English phrasal verbs that happened to be missing from Wiktionary; some are present in Wiktionary but were removed from the reference sets during filtering, and the remainder are in fact not phrasal verbs (true precision errors).</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27679</th>\n",
       "      <td>27679</td>\n",
       "      <td>5369521</td>\n",
       "      <td>This is true both in resource acquisition, such as automated bilingual lexicon generation (Kolak et al.,</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28042</th>\n",
       "      <td>28042</td>\n",
       "      <td>219302427</td>\n",
       "      <td>For example, definition clause (7) means that, for a pair of the variables X and Y, p(f(X, Y)) is true if the instances satisfy the constraint {r(X), s(Y)}.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33610</th>\n",
       "      <td>33610</td>\n",
       "      <td>12928004</td>\n",
       "      <td>A definite clause has either the form P:-QI,\"',Qn\" to be read as \"P is true if Q 1 ..... Qn are true\", or the form P. to be read as \"P is true\".</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39240</th>\n",
       "      <td>39240</td>\n",
       "      <td>199022725</td>\n",
       "      <td>This includes complete utterances or phrases (e.g. to je res \"that's true\", no no \"well well\"), sentence elements, such as predicates (boš videl \"you-will see\"), predicate arguments (glava družine \"head of the family\") and adjuncts (pol ure \"half an hour\"), as well as modifiers (bolj ali manj \"more or less\"), multi-word conjunctions (zaradi tega ker \"given the fact that\"), and connectives (tako da \"so that\").</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20556</th>\n",
       "      <td>20556</td>\n",
       "      <td>19226723</td>\n",
       "      <td>Our method employs embedding techniques, and also integrates context-aware true label dis- Although Universal Schemas does not adopted the source consistency assumption, but it's conducted in document-level, and is context-agnostic in our sentence-level setting.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>32559</td>\n",
       "      <td>52971170</td>\n",
       "      <td>W t is another set of parameters in addition to W. Objective Function We use the max-margin loss function to learn the parameters of the model: L(θ) = m ∑ i=1 k ∑ j̸ =i max ( 0, γ + d(y i , ŷg i ) − d(y j , ŷg i ) ) , (5) Where y i is the true label; ŷg i is the prediction, which is either ŷlinear i or ŷnn i .</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>917</td>\n",
       "      <td>6019603</td>\n",
       "      <td>Thus, the distinction between stem and variant can not be done clearly by the algorithm (the same holds true for independant and independent).</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>3347</td>\n",
       "      <td>1193152</td>\n",
       "      <td>More formally: α(N i,j ) = P (w 0,i , N i,j , w j,n ) β(N i,j ) = P (w i,j |N ) FOM(N i,j ) = α(N i,j ) β(N i,j ) With bottom-up parsing, the true inside probability is accumulated and β(N i,j ) does not need to be estimated, improving the FOMs ability to represent the true inside/outside distribution.</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27371</th>\n",
       "      <td>27371</td>\n",
       "      <td>33743229</td>\n",
       "      <td>The sentence is judged true in scenario Σ 30a -a scenario that makes the transparent NP, opaque VP reading true--but false in scenario Σ 30b -a scenario where the opaque NP, transparent VP reading is true.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>3639</td>\n",
       "      <td>13341920</td>\n",
       "      <td>Figure 3 illustrates a simulation demonstrating that the approximation is a close match for small a and n but underestimates the true value for high a To resample a sequence of trigrams we start by removing their counts from the current restaurant configuration (resulting in z − ).</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13796</th>\n",
       "      <td>13796</td>\n",
       "      <td>15047929</td>\n",
       "      <td>The extensional models of logic are recast as \"semantic\" functors from the lexical category to C. We associate to any semantic functor an RDF interpretation and show that a statement is true in the semantic functor if and only if the corresponding RDF graph is true in the RDF interpretation.</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18975</th>\n",
       "      <td>18975</td>\n",
       "      <td>51918720</td>\n",
       "      <td>However, we should be cautious of using backchannels too liberally if they are not a result of true understanding, since they could break down trust between robot and human.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28571</th>\n",
       "      <td>28571</td>\n",
       "      <td>4408231</td>\n",
       "      <td>For example, assigned relation variable (Z(i, r)) is true if z i = r and false otherwise.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37606</th>\n",
       "      <td>37606</td>\n",
       "      <td>17387910</td>\n",
       "      <td>7 The length filter eliminated 48.6% of the 9,000,000 possible pairs in the cross-product, keeping 95.7% of the true pairs.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21598</th>\n",
       "      <td>21598</td>\n",
       "      <td>202538985</td>\n",
       "      <td>We believe the problem comes from the nature of variational family itself and hence we propose our Copula-VAE which makes use of the dependency modeling ability of copula model to guide the variational posterior to match the true posterior.</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13202</th>\n",
       "      <td>13202</td>\n",
       "      <td>215800828</td>\n",
       "      <td>False responses are hypothesized to be less fluent than true responses because fabricating a story takes more mental effort than recalling an actual event.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31310</th>\n",
       "      <td>31310</td>\n",
       "      <td>18718806</td>\n",
       "      <td>If true, this merely attests to the relative independence of task-based and human-annotated knowledge sources.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32506</th>\n",
       "      <td>32506</td>\n",
       "      <td>3201076</td>\n",
       "      <td>a(C i,j ) matches the true outside score if the onebest category assignments on the outside words (arg max c k log P tag (c k |x)) can comprise a wellformed tree with C i,j , which is generally not true.</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28918</th>\n",
       "      <td>28918</td>\n",
       "      <td>243865273</td>\n",
       "      <td>The message is clear: the ordinal model is always more likely to detect a true effect of any size than the corresponding linear model is (all of the solid lines of a given color are always above their dashed counterpart).</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>1084</td>\n",
       "      <td>16936514</td>\n",
       "      <td>However, this assumes that each error indicates a unique level, which is not always true.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>9357</td>\n",
       "      <td>31080548</td>\n",
       "      <td>Temporally, the original blank positions are labeled true, and the shifted ones are labeled as false.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17749</th>\n",
       "      <td>17749</td>\n",
       "      <td>11825156</td>\n",
       "      <td>To allow a \"partial credit\" for these cases, we introduce \"weighted\" version of these measures, where a predicted label is given 0.5 credit if the true label is its direct child or parent, and 0.25 credit if the true label is a sibling.</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36741</th>\n",
       "      <td>36741</td>\n",
       "      <td>134248</td>\n",
       "      <td>Next, the tranformations from L1 will be applied if X is true, since S' is the initial-state label for L1.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13634</th>\n",
       "      <td>13634</td>\n",
       "      <td>5620421</td>\n",
       "      <td>The constants true and false play their usual role, c-struct and f-struct give us 'labels' for our two domains, while the elements of Cat and Atom enable us to talk about syntactic categories and atomic f-structure information respectively.</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33517</th>\n",
       "      <td>33517</td>\n",
       "      <td>235422654</td>\n",
       "      <td>Second, normalized κ x approximates the true correlation between two experiments' item-level mean scores.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16522</th>\n",
       "      <td>16522</td>\n",
       "      <td>248118588</td>\n",
       "      <td>Same is true for majority of EQUATE data.</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38148</th>\n",
       "      <td>38148</td>\n",
       "      <td>1270797</td>\n",
       "      <td>However, this generalization holds true only in Mandarin and perhaps in some other varieties of the Chinese language but certainly not in all varieties of the language.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18803</th>\n",
       "      <td>18803</td>\n",
       "      <td>2333978</td>\n",
       "      <td>We call this threshold the confidence threshold and denote it by ρ, whilst the prefixed true score to identify a good translation is called acceptance threshold and is denoted by τ .</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20831</th>\n",
       "      <td>20831</td>\n",
       "      <td>236460013</td>\n",
       "      <td>Markov Logic Network (MLN) (Pearl, 1988) can model such uncertainty by assigning each causal rule a causal strength, which measures the probability that this rule holds true.</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>15174</td>\n",
       "      <td>44084674</td>\n",
       "      <td>In our model, we removed the dependency on both the true cast list and the script, which makes it easier to apply our model to other movies and TV shows.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>3003</td>\n",
       "      <td>2922398</td>\n",
       "      <td>Algorithm 4.1: CALCULATE-T(U, Tj) procedure FAST-UPDATE(n k ) diff ← 0, m(n k ) ← *1, U ← φ for n2 ← 1 to |Tj| do change(n2) ← true n1 ← n k while n1 ̸ = nil do 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : for n2 ← 1 to |Tj| do // actually iterate only on n2 with l(pa( n1 ) ) = l(n2) nchange(n2) ← false for n2 ← 1 to |Tj| do // actually iterate only on n2 with l(n1) = l(n2) if change(n2) then pre ← C r (n1, n2), U ← U ∪ (n1, n2) update C(n1, n2) and C r (n1, n2) using (A) of Algorithm 3.1 diff + = (C r (n1, n2) − pre) if pa(n2) ̸ = nil then nchange(pa(n2)) ← true n1 ← pa(n1), change ← nchange for (n1, n2) ∈ U do //restore DP cells C(n1, n2) ← C ′ (n1, n2), C r (n1, n2) ← C r ′ (n1, n2) m(n k ) ← no-mark return (diff ) main m(nv) ← * 0, k ← WMOLT-KERNEL(U, Tj) C ′ (n1, n2) ← C(n1, n2), C r ′ (n1, n2) ← C r (n1, n2) for n k ← 1 to |U | do (n k ̸ = nv) diff ← FAST-UPDATE(n k ), t(n k ) ← k + diff Given a sentence represented by tree U and the node for the target predicate n v , the argument recognition requires the calculation of: However, if we exploit the fact that U @{n v = *0, n k = *1} is different from U @{n v = *0} at one node, we can greatly speed up the above calculation.</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12036</th>\n",
       "      <td>12036</td>\n",
       "      <td>210044174</td>\n",
       "      <td>Fact checking requires the apt evidence against which sentences can be predicted to be true or false.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>6046</td>\n",
       "      <td>58302</td>\n",
       "      <td>This is not true in the cooperation of bigrams and trigrams with acquired constraints (BTC), in this case the synergy is not enough to get a better joint result.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19548</th>\n",
       "      <td>19548</td>\n",
       "      <td>44063972</td>\n",
       "      <td>The gradient of L G can be formulated as below: θ D L G = s j ∈B i E s j ∼p G (s j ) r θ G log p G (s j ) = 1 |T | s j ∈T r θ G log p G (s j ) (7) Cleaning Noisy Dataset with Generator After our adversarial learning process, we obtain one generator for one relation type; These generators possess the capability of generating true positive samples for the corresponding relation type.</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32687</th>\n",
       "      <td>32687</td>\n",
       "      <td>202776155</td>\n",
       "      <td>They are used to help to judge whether the answer found by the vanilla model is true.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2071</td>\n",
       "      <td>226262339</td>\n",
       "      <td>For example, questions such as What evidence is there that [claim] is true?</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7119</th>\n",
       "      <td>7119</td>\n",
       "      <td>3223514</td>\n",
       "      <td>Finally, we use a simple 3-gram casing model trained on the true-case workshop distributed language model data, and apply the SRILM disambig tool to restore true-case for our final submissions.</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>5110</td>\n",
       "      <td>202540591</td>\n",
       "      <td>As we have manually corrected the label mistakes in the testing set, we are able to report the number of true mistakes among the potential mistakes discovered in the test set.</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19475</th>\n",
       "      <td>19475</td>\n",
       "      <td>2315102</td>\n",
       "      <td>Conversely, not Permit P to be true was labeled as Require P to be false.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34649</th>\n",
       "      <td>34649</td>\n",
       "      <td>67239762</td>\n",
       "      <td>If the author of the domain model has provided this reasonable and perfectly true fact about motherhood, (6) can proceed to yield: (PAT I ENT-WI TH-D I ABET IC-MOTHER X) as in the preceding example.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>1236</td>\n",
       "      <td>53235202</td>\n",
       "      <td>However, if our hypothesis holds true, visible differences in the baseline improvements measured with \"TER/BLEU (pe)\" and \"TER/BLEU (ref)\" should indicate system's ability to model the post-editing style of the training data.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22519</th>\n",
       "      <td>22519</td>\n",
       "      <td>250390926</td>\n",
       "      <td>Rephrase) Evaluation Metrics For these three sub-tasks, standard evaluation metrics including accuracy and F1 score are used to evaluate the participating system, calculated as follows: accuracy = T P + T N T P + F P + T N + F N (1) recall = T P T P + F N (3) F1 = 2 • precision • recall precision + recall (4) where T P, F P, T N, F N represent true positive, false positive, true negative, and false negative, respectively.</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34763</th>\n",
       "      <td>34763</td>\n",
       "      <td>11878680</td>\n",
       "      <td>Within $waggart's world view, adulterers rn~t be sinners simply because the bible says so, and whatever the bible says is true.</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14741</th>\n",
       "      <td>14741</td>\n",
       "      <td>3876179</td>\n",
       "      <td>We refer to dimensions by their first descriptor (Section 3); 1 (-1) indicates that the first (second) descriptor is true, and 0 that the value is unknown.</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22029</th>\n",
       "      <td>22029</td>\n",
       "      <td>102350590</td>\n",
       "      <td>The country's history has been turbulent and true is true.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30644</th>\n",
       "      <td>30644</td>\n",
       "      <td>15619421</td>\n",
       "      <td>In that case, it is no longer true that (10) 3m is the only generated sentence, which is a contradiction.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33543</th>\n",
       "      <td>33543</td>\n",
       "      <td>1437</td>\n",
       "      <td>We collected only nouns under the assumption that most, if not all, true category members would be nouns3 1 Of course, this may depend on the target categories.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12435</th>\n",
       "      <td>12435</td>\n",
       "      <td>227230832</td>\n",
       "      <td>PCNN+INTRA+INTER (Ye and Ling, 2019) propose to emphasize true labeled sentences and bags.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912</th>\n",
       "      <td>15912</td>\n",
       "      <td>227231594</td>\n",
       "      <td>This does not assume that analytic treatment of linguistic context can resolve any 'true' or 'correct' meaning of a contested concept, but simply that usage reflects meaning as held by the community or ideology that produces the text.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26554</th>\n",
       "      <td>26554</td>\n",
       "      <td>1455285</td>\n",
       "      <td>2  From the definition of G it directly follows that w ∈ L(G) implies the existence of a truth assignment that satisfies C. A satisfying truth assignment can be read directly off of any derivation tree for w. If T i (respectively, F i ) is a child of S in the derivation tree, then v k is true (respectively, false).</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23902</th>\n",
       "      <td>23902</td>\n",
       "      <td>234763107</td>\n",
       "      <td>Beam search is an approximation that is tractable, but it also frequently fails to find the true mode of the distribution (Stahlberg and Byrne, 2019) .</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>19993</td>\n",
       "      <td>6489978</td>\n",
       "      <td>They contain 26 and 23 multiple-choice questions each of which has four sentential statements, thus 104 and 92 predicates can be used for true/false validation as development and test data, respectively.</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15065</th>\n",
       "      <td>15065</td>\n",
       "      <td>99196</td>\n",
       "      <td>-the algorithm's task is to return a set of descriptors that encompasses the majority of points with rain=true values.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13757</th>\n",
       "      <td>13757</td>\n",
       "      <td>3892641</td>\n",
       "      <td>Reasonable people can disagree about how best to categorize a situation, as no metaphor is ever objectively right or true, just potentially apt in a particular context.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22462</th>\n",
       "      <td>22462</td>\n",
       "      <td>248780478</td>\n",
       "      <td>First compute the forward derivative: ∇F(X) = ∂F (X) ∂e(X) = ∂F j (X) ∂e(x i ) i∈1..N,j∈1..T (1) and the saliency of word x i is defined as: S(x i ) = ∂F true (X) ∂e(x i ) (2) where, F j (•) is the output w.r.t.</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9002</th>\n",
       "      <td>9002</td>\n",
       "      <td>10551763</td>\n",
       "      <td>The two criteria used would select the most difficult cases for the algorithm, that is, cases whose true alignment is expected to be most informative.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20173</th>\n",
       "      <td>20173</td>\n",
       "      <td>40503511</td>\n",
       "      <td>While this may typically be true, extending the system to be able to prefer the opposite with certain types of questions would potentially help with these errors.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39439</th>\n",
       "      <td>39439</td>\n",
       "      <td>6574418</td>\n",
       "      <td>This allows the derivation to keep track of both the true head of the phrase and the place in the Cinque hierarchy of the modifier, preventing inverted modifier orders in the absence of Move.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30227</th>\n",
       "      <td>30227</td>\n",
       "      <td>6694415</td>\n",
       "      <td>We are interested in computing Pr[result() = true].</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>6194</td>\n",
       "      <td>1881596</td>\n",
       "      <td>Moreover, if one of the premises is tagged by contributors as true but irrelevant, then the inference is blocked.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27807</th>\n",
       "      <td>27807</td>\n",
       "      <td>2380594</td>\n",
       "      <td>If either case is true, then CFLex reports that the anaphor and candidate might be coreferent.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2559</td>\n",
       "      <td>10570679</td>\n",
       "      <td>We measure the Top-1 accuracy (i.e., whether the true comparable is the closest in the test set), and the Mean Reciprocal Rank of the true comparable, and report the average performance over the two retrieval directions.</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22453</th>\n",
       "      <td>22453</td>\n",
       "      <td>247233685</td>\n",
       "      <td>Following previous work in this direction such as Jacovi and Goldberg (2020), we advocate to carefully consider the explanations obtained from interpretation methods as they may not always reflect the true reasoning process behind model predictions.</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24308</th>\n",
       "      <td>24308</td>\n",
       "      <td>218974041</td>\n",
       "      <td>In particular, this is true for basic problems such as POS-tagging, sentence parsing and entity recognition, as well as for more complex problems such as question answering (QA).</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>3978</td>\n",
       "      <td>1290272</td>\n",
       "      <td>In our case, the true negative number is 100 times larger than the true positive number.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29225</th>\n",
       "      <td>29225</td>\n",
       "      <td>219182005</td>\n",
       "      <td>CDP [does] not suppose cooperation with party [of] mister Sladek and it isn't true, that chairman [of] Christian democrats mister Benda enforced in telephonic discussion with Petr Pithart ing.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>2096</td>\n",
       "      <td>174797774</td>\n",
       "      <td>w m }, annotated with N highlights, we define the weight β n g ∈ [0, 1] for an n-gram g as: β n g = m−(n−1) i=1 i+n−1 j=i NumH(w j ) N n w i:i+n−1 ==g m−(n−1) i=1 [1] w i:i+n−1 ==g where, [x] y is an indicator function which returns x if y is true and 0, otherwise.</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11362</th>\n",
       "      <td>11362</td>\n",
       "      <td>815755</td>\n",
       "      <td>5 When using a static oracle for training in Algorithm 2, the function o(t; c, T ) returns true if o s (T ) = t 1 , . . . ,</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21662</th>\n",
       "      <td>21662</td>\n",
       "      <td>8965491</td>\n",
       "      <td>Regression model evaluation We select 10K English-Chinese sentence pairs with both hand alignment and automatic HMM alignment, and extract 106K phrase pairs with true phrase translation quality scores as computed according to formula 8.</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>3637</td>\n",
       "      <td>14922772</td>\n",
       "      <td>We filter out false negatives that were observed true (entity, type) pairs in our complete data set.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39946</th>\n",
       "      <td>39946</td>\n",
       "      <td>7009464</td>\n",
       "      <td>19 This simple technique has reasonable accuracy (0.752: see Table 5 ) but this is due largely to the high number of true negatives produced.</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26340</th>\n",
       "      <td>26340</td>\n",
       "      <td>234482939</td>\n",
       "      <td>Intuitively, the true fraction of decaying instances can be captured by the difference of these left tails, and we formally quantify this below.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27408</th>\n",
       "      <td>27408</td>\n",
       "      <td>51940055</td>\n",
       "      <td>Traditional approach fails to capture the true posterior distribution of z due to its oversimplified assumption when using the mean-field approaches.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16498</th>\n",
       "      <td>16498</td>\n",
       "      <td>220512955</td>\n",
       "      <td>Perceived weakness of must is accounted for on this analysis because must φ -unlike bare φ -allows for the possibility that ¬φ is true in worlds compatible with the known propositions (but incompatible with the assumed ones).</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31189</th>\n",
       "      <td>31189</td>\n",
       "      <td>2772094</td>\n",
       "      <td>12* Factive verb in context {true, false} One/two word(s) around w is a factive (Hooper, 1975) .</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36029</th>\n",
       "      <td>36029</td>\n",
       "      <td>912349</td>\n",
       "      <td>Though inversion transduction grammars remain inadequate as full-fledged translation models, bilingual parsing with simple inversion transduction grammars turns out to be very useful for parallel corpus analysis when the true grammar is not fully known.</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9603</th>\n",
       "      <td>9603</td>\n",
       "      <td>10969391</td>\n",
       "      <td>Action schemas (acs1 and acs2) use the reassignment operator R to make loaded true after performing the Load action and to make both loaded and alive false after performing the F ire action, but only if loaded was true when the action was initiated.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14147</th>\n",
       "      <td>14147</td>\n",
       "      <td>10707097</td>\n",
       "      <td>For instance, the first utterance, u 1 : \"turn right a little\", shows the true user utterance.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22908</th>\n",
       "      <td>22908</td>\n",
       "      <td>226222033</td>\n",
       "      <td>This is especially true for the elaboration and list relations.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31478</th>\n",
       "      <td>31478</td>\n",
       "      <td>18070886</td>\n",
       "      <td>One possibility is that this is caused by our having defined the Deictic feature as true whenever there is an actual deictic expression (variable D in Table 1 ; e.g. those squares) or an identity expression (variable ID; e.g. the same one we saw).</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960</th>\n",
       "      <td>5960</td>\n",
       "      <td>218974002</td>\n",
       "      <td>The choice of language clues (i.e., features) that can be used to classify news as true or false vary considerably.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30685</th>\n",
       "      <td>30685</td>\n",
       "      <td>204867474</td>\n",
       "      <td>Phylogenetic methods are designed to recover the \"true\" evolutionary tree as often as possible.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24146</th>\n",
       "      <td>24146</td>\n",
       "      <td>1494188</td>\n",
       "      <td>Our ) UNARY A B u w l B u pg(A → B | A)p lef t (w l | A, eA) B u B B wr p right (wr | A, eA) BINARY A A 1 w l A 1 p lef t (w l | A, eA) A 1 B C 1 B C 1 pg(A → B C | A)pinv(I=false | B, C) A 1 B C 1 C 1 B pg(A → B C | A)pinv(I=true | B, C) C 1 C 2 fm C 2 p mid (fm | A, eA) C 2 C C fr p right (fr | A, eA) DT[3,3] NN[3,4] VP[0,3] VB[2,2] VP[2,3] VBN[2,3] NN[3,3] VP[2,3] MD[1,2] 明天 将 公布 名!</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>3190</td>\n",
       "      <td>5679981</td>\n",
       "      <td>By construction, correct edges (i, j), that appear both in the true parse tree y and the predicted parse tree ŷ, are not affecting the update, as the terms in the two sums of Eq. (</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39616</th>\n",
       "      <td>39616</td>\n",
       "      <td>96442562</td>\n",
       "      <td>For every R i 2 S, R i (x 1 , ..., x k ) is an atomic formula in L S , which is interpreted as true in a model M when x 1 , ..., x k are evaluated to d 1 , ..., d k 2 D and (d 1 , ..., d k ) 2 R i in M .</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>10657</td>\n",
       "      <td>6190877</td>\n",
       "      <td>This is true even for a language as seemingly dissimilar to English as Japanese .</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34303</th>\n",
       "      <td>34303</td>\n",
       "      <td>14692027</td>\n",
       "      <td>Since, by the definition of o\" , any predicate indexed by the empty set will be true of the typical element of the empty set, \"arrlve#(~(# ))\" will be true, and the sentence will be satisfied.</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>7490</td>\n",
       "      <td>201710452</td>\n",
       "      <td>With the multitoken approach none of the tokens would have the gazetteer feature equal to true, while with the single token approach both salami, pizza, mozzarella and sandwiches would have the presence set to true.</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8617</th>\n",
       "      <td>8617</td>\n",
       "      <td>8558112</td>\n",
       "      <td>If a specific linguistic cue was more often used during deception than in a true story, d becomes a negative sign.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26893</th>\n",
       "      <td>26893</td>\n",
       "      <td>237256842</td>\n",
       "      <td>The analogy is made between computerised information and books; if it is not an infringement of copyright to pick up someone else's book and read it, the same should be true of unauthorised browsing through computer files.</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6831</th>\n",
       "      <td>6831</td>\n",
       "      <td>18877507</td>\n",
       "      <td>A major reason for this problem was that the true attributes did not exist in our dictionary.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29646</th>\n",
       "      <td>29646</td>\n",
       "      <td>247762111</td>\n",
       "      <td>In other words, the negative samples chosen by the backbone model X for the AF algorithm will be difficult to distinguish from the human-annotated true samples using the same model X. These negative samples, however, could be relatively easier to identify using another model Y. The seq2seq models T5 and Unified QA perform significantly better than RoBERTa and ELECTRA as can be seen in Table 8 .</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12853</th>\n",
       "      <td>12853</td>\n",
       "      <td>235795697</td>\n",
       "      <td>2015) , previous dialogue states are half predicted dialogue states and half true labels.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16805</th>\n",
       "      <td>16805</td>\n",
       "      <td>8066686</td>\n",
       "      <td>L DGA gives thus a true cut across the Chomsky hierarchy, which we judge to be possibly relevant for formal linguistics.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40086</th>\n",
       "      <td>40086</td>\n",
       "      <td>2211971</td>\n",
       "      <td>Similarly, the feature word hp1 of has the value 1 (true) if the given window contains the head word followed by \"of\"; otherwise, it has the value 0 (false).</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24877</th>\n",
       "      <td>24877</td>\n",
       "      <td>2408543</td>\n",
       "      <td>For example, if we have in the gazetteer the compound name yAsr ErfAt 'Yasser Arafat' and the input text is yAsr BarakAt then PM-GAZ for the token yAsr will be set to true.</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14077</th>\n",
       "      <td>14077</td>\n",
       "      <td>1692763</td>\n",
       "      <td>Of the 52 occurrences in the test corpus BIO-ART, the system produces 3 true positives, 8 false positives and 49 false negatives.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11540</th>\n",
       "      <td>11540</td>\n",
       "      <td>8015669</td>\n",
       "      <td>Variable x i is true, and therefore phrase i will be included, if any of its dependents x j ∈ D i are true.</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6535</th>\n",
       "      <td>6535</td>\n",
       "      <td>1140080</td>\n",
       "      <td>Each node in the tree is marked with an elementary formula which can be true or false.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30131</th>\n",
       "      <td>30131</td>\n",
       "      <td>247447100</td>\n",
       "      <td>This is especially true for recommender systems, where adversarial attacks can create fake users such that a target item is removed from a target user's top-k list (Christakopoulou and Banerjee, 2019) .</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40076</th>\n",
       "      <td>40076</td>\n",
       "      <td>235097296</td>\n",
       "      <td>x n , y n ), the (empirical) training loss for a parameter θ is defined as: 1 n n i=1 ( x i , θ ; y i ) and the goal in training (empirical risk minimization) is to minimize this loss over a parameter space Θ. Let θ be a true minimizer of 1 n n i=1 ( x i , θ ; y i ), i.e., θ ∈ argmin θ∈Θ 1 n n i=1 ( x i , θ ; y i ).</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>5271</td>\n",
       "      <td>14917259</td>\n",
       "      <td>The so-called true tree principle (e.g. Schubert 1987:87-90) makes it impossible for different parts of a constituent C1 to be split apart by another constituent C2 which is not a part of C1.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14778</th>\n",
       "      <td>14778</td>\n",
       "      <td>225067907</td>\n",
       "      <td>Third, they perform multi-class classification (i.e., they assume only one intent to be true for a user query) and have no notion of state (e.g., current webpage).</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19165</th>\n",
       "      <td>19165</td>\n",
       "      <td>17100741</td>\n",
       "      <td>Let us assume that we have a rule ¢, R2 = ¢ ^ X ~ \"~¢. When ¢ and X are both true ¢ and ~g, are both true.</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2011</td>\n",
       "      <td>2265838</td>\n",
       "      <td>Instances are known tuples of entities that make a relation or category true, such as film(Titanic) or directed by(Titanic, James Cameron).</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25237</th>\n",
       "      <td>25237</td>\n",
       "      <td>3899390</td>\n",
       "      <td>This type of model constraint allows the model to find solutions which correspond to true syntactic parts of speech (which follow such a sparse, Zipfian distribution), unlike the uniformly-sized clusters found by standard maximum likelihood estimation using EM.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15881</th>\n",
       "      <td>15881</td>\n",
       "      <td>204762959</td>\n",
       "      <td>Usage Implications The consequences of declaring a claim to be true or false can be serious.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37927</th>\n",
       "      <td>37927</td>\n",
       "      <td>214612871</td>\n",
       "      <td>In reality, this is true only if we are very sure about the right sense used in a particular sentence.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26123</th>\n",
       "      <td>26123</td>\n",
       "      <td>648382</td>\n",
       "      <td>Writer Perspective The writer perspective tells the reader what the writer wants him to believe (to be true) and explicates what this implies for the status of the targets involved, i.e. whether they are benefactors etc.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>8522</td>\n",
       "      <td>46932607</td>\n",
       "      <td>Length Mismatch: For this adversarial set, we append the tautology \"and true is true\" five times to the end of the premise sentence for every example in the MultiNLI development set.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25099</th>\n",
       "      <td>25099</td>\n",
       "      <td>201683127</td>\n",
       "      <td>This is particularly true with informal forms of 'everyday' language, which proliferate in most online spaces (Eisenstein, O'Connor, Smith, &amp; Xing, 2014) .</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28215</th>\n",
       "      <td>28215</td>\n",
       "      <td>2133607</td>\n",
       "      <td>In our implementation, the function returns true if M −1 m=0 max h∈ Ω:|h|=l−m α(h,X)−max h ∈ Ω α(h , X) &lt; D end =M, (18) where D end and M are predetermined thresholds.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37208</th>\n",
       "      <td>37208</td>\n",
       "      <td>15852664</td>\n",
       "      <td>Second, the system is to learn the language well enough to determine whether or not a new sentence is true of the accompanying picture.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>236881122</td>\n",
       "      <td>The three metrics are defined as follows: P @k = 1 k k l∈r k (ŷ) y l (3) R@k = 1 n k l∈r k (ŷ) y l (4) F 1@k = 2 • P @k • R@k P @k + R@k (5) where k is the number of labels to be used for comparison, n is the number of true labels of the respective document, y ∈ {0, 1} L is the vector of the true labels, ŷ ∈ R L is the vector of predicted labels and r k (ŷ) is a function that selects the index of the kth largest value in the prediction labels.</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32837</th>\n",
       "      <td>32837</td>\n",
       "      <td>220046708</td>\n",
       "      <td>More specifically, we assume a latent variable z for generating the representation of finance document, whose true posterior distribution p(z|D) is usually too complicated to have an analytical form.</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22546</th>\n",
       "      <td>22546</td>\n",
       "      <td>219573632</td>\n",
       "      <td>For the book seller's example, we assume that one book can have only one true author list; so if we knew one list was true, then any different list of the same book would be false.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24176</th>\n",
       "      <td>24176</td>\n",
       "      <td>218973843</td>\n",
       "      <td>It is valuable to note the algorithm also selects word pairs which can technically be considered true cognates (long/luengo -meaning long), but are not used as such in current speech: largo is more frequently used than luengo.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31971</th>\n",
       "      <td>31971</td>\n",
       "      <td>245838383</td>\n",
       "      <td>8 The same is true for a sentence with many clauses.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7901</th>\n",
       "      <td>7901</td>\n",
       "      <td>6741119</td>\n",
       "      <td>By the same token, \"the interpretation of a question is the minimal explanation of why the question would be true\" based on a set of lexical knowledge bases.</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11587</th>\n",
       "      <td>11587</td>\n",
       "      <td>250390781</td>\n",
       "      <td>In addition, an advantage of the template-based framework is that it can generate T/F questions while determining whether their answers are true or false.</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27852</th>\n",
       "      <td>27852</td>\n",
       "      <td>7255624</td>\n",
       "      <td>Because answer typing is only intended to be a component of a full QA system, we rely on other components to help establish the true correctness of a candidate answer.</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>3774</td>\n",
       "      <td>235097447</td>\n",
       "      <td>2019) uses an unrealistic candidate generation setting where the true positive candidate is within the candidate set and/or entities are limited to those in the dataset rather than those in the knowledge-base.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>12090</td>\n",
       "      <td>52011877</td>\n",
       "      <td>Results on the Test Set Figure 2 depicts the average number of CS (i.e., true positives) retrieved per the top K = 10, 20, 50 predictions.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32618</th>\n",
       "      <td>32618</td>\n",
       "      <td>1451416</td>\n",
       "      <td>Active(N) is true iff a node or an element of a node gets an A-Marker.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33305</th>\n",
       "      <td>33305</td>\n",
       "      <td>218517046</td>\n",
       "      <td>The more likely r is to be true, the more likely it is to be generated.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20978</th>\n",
       "      <td>20978</td>\n",
       "      <td>209091351</td>\n",
       "      <td>This means that for any given recognized entity, it is only counted as a true positive if both the span and the label match exactly with the gold standard annotation.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31639</th>\n",
       "      <td>31639</td>\n",
       "      <td>149449424</td>\n",
       "      <td>Morphological analyzers provide multiple analyses of a word, only one of which is true in context.</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31488</th>\n",
       "      <td>31488</td>\n",
       "      <td>244064508</td>\n",
       "      <td>6  Annotators were provided detailed guidelines, which included an operational definition of MWEs (as presented in 3.1) and several examples showing true and false MWEs.</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31627</th>\n",
       "      <td>31627</td>\n",
       "      <td>27757235</td>\n",
       "      <td>First, what one writes in a comment is more important than simply how much one writes; this is true across both subjective and objective outcomes, though length had virtually no predictive ability for improving forecaster accuracy.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23228</th>\n",
       "      <td>23228</td>\n",
       "      <td>34211552</td>\n",
       "      <td>2003 ) created a labeled corpus of elicited narratives marked as lie or true, then applied machine learning techniques (logistic regression) to rank the contribution of these linguistic categories.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40225</th>\n",
       "      <td>40225</td>\n",
       "      <td>17964067</td>\n",
       "      <td>If an instance is classified as true by more than one classifier, we consider only the classification with the highest confidence.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10867</th>\n",
       "      <td>10867</td>\n",
       "      <td>218486900</td>\n",
       "      <td>If the number of slots is huge, each individual inflection is rare, and it is hard for any unsupervised paradigm completion system to distinguish true inflections (e.g., rise → rises) from false candidates (e.g., rise → arise).</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29334</th>\n",
       "      <td>29334</td>\n",
       "      <td>14195143</td>\n",
       "      <td>When ~ is close to 1, there will be few ~rds in common between two meanings, on the average~ and hence the distance between them will be close to I. When c~ is close to zero, on the other hand, the reverse is true, and distances will tend toward zero.</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22500</th>\n",
       "      <td>22500</td>\n",
       "      <td>233033554</td>\n",
       "      <td>2018) , typically represent the head entity, relation, and tail entity in each triplet in the knowledge graph as vectors and aim to rank true triplets higher than corresponding corrupted triplets.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21862</th>\n",
       "      <td>21862</td>\n",
       "      <td>106402715</td>\n",
       "      <td>the true distance or norm.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22826</th>\n",
       "      <td>22826</td>\n",
       "      <td>235358901</td>\n",
       "      <td>i go with my parents are more relevant and coherent than the response generated by baselines, and it also similar with the true response 1 (oh, that sounds great!),</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38716</th>\n",
       "      <td>38716</td>\n",
       "      <td>236486083</td>\n",
       "      <td>See Table 1 for a summary of the criterion for each type of fragment to be true.</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37714</th>\n",
       "      <td>37714</td>\n",
       "      <td>29904330</td>\n",
       "      <td>And this is true not only for individual wordsenses, but also for larger units such as topics: the product of LDA and similar topic characterization engines is similar.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12747</th>\n",
       "      <td>12747</td>\n",
       "      <td>237277900</td>\n",
       "      <td>2011) based on mutual information, even with the expectation these may only somewhat correlate with true human judgments (Lau et al.,</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21129</th>\n",
       "      <td>21129</td>\n",
       "      <td>119069467</td>\n",
       "      <td>To create a negative sentence given a gold response, we pick a random phrase in the true response and replace it with a random phrase in another random true response.</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39756</th>\n",
       "      <td>39756</td>\n",
       "      <td>15822567</td>\n",
       "      <td>Note that by simply checking if rheme is contained in the alternatives set is not sufficient; this would return true or false as an answer to a question that expects a person.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>26045</td>\n",
       "      <td>245118159</td>\n",
       "      <td>In his opinion the principles of natural science, such as those of causality and the law of conservation of energy, are unconditionally true because the mind thinks in Newtonian terms.</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>5050</td>\n",
       "      <td>243865344</td>\n",
       "      <td>It makes a true-false determination for each of the inferred aspect terms based on the corresponding contextual.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>2652</td>\n",
       "      <td>10048734</td>\n",
       "      <td>When the relation classifier is trained using the true entity labels, the performance is much worse than using the predicted entity labels.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>9478</td>\n",
       "      <td>748227</td>\n",
       "      <td>2012) , we evaluate the imputed sentence completions by examining their distinguishability from the true sentence endings.</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11576</th>\n",
       "      <td>11576</td>\n",
       "      <td>5881871</td>\n",
       "      <td>We select the maximum likelihood frame as the system's hypothesized meaning for the test utterance, and examine both how often the maximum likelihood estimate exactly matches the true frame (frame accuracy), and how many of the role fillers within the estimated frame match the role fillers of the true frame (role accuracy).</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8784</th>\n",
       "      <td>8784</td>\n",
       "      <td>201668251</td>\n",
       "      <td>In general the loss l is chosen as a surrogate of the evaluation metric whose purpose is to measure the similarity between the predictions and the true labels.</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38659</th>\n",
       "      <td>38659</td>\n",
       "      <td>219309265</td>\n",
       "      <td>not true').</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23301</th>\n",
       "      <td>23301</td>\n",
       "      <td>38708803</td>\n",
       "      <td>However, each such sourcetarget word translation is assigned a probability score indicating how likely it can be treated as true translation.</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30042</th>\n",
       "      <td>30042</td>\n",
       "      <td>202788853</td>\n",
       "      <td>But doing so requires knowledge of the true author of an episode, something which is not generally available.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20789</th>\n",
       "      <td>20789</td>\n",
       "      <td>39590706</td>\n",
       "      <td>LDC conducts limited quality control on the translations, using methods that vary based on the translation type, but which are primarily automated rather than manual and which serve primarily to exclude egregiously bad data rather than improve the quality to a true \"gold standard\".</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28209</th>\n",
       "      <td>28209</td>\n",
       "      <td>874565</td>\n",
       "      <td>In detail, when contrasting the confusion matrices of the best configurations accomplished by ME-combined (80.72%), ME-KB (80.33%) and ME-N-KB (78.99%), one can find that MEcombined correctly identified 88% of the answers (true positives), while ME-KB 89.37% and ME-N-KB 93.38% (see Table 3 ).</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>219303045</td>\n",
       "      <td>This is particularly true for headlines, which are typically very short.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17823</th>\n",
       "      <td>17823</td>\n",
       "      <td>198183589</td>\n",
       "      <td>I t i s true t h a t there are the traditional terms \" semel factive\" and \"iterative\" referring, respectively, to one and more than one instantiation of an event.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13164</th>\n",
       "      <td>13164</td>\n",
       "      <td>211818155</td>\n",
       "      <td>Formally, if we denote the correct entity of each mention m as ê, the gold candidate recall r is defined as: r = N i=1 δ(ê i ∈ e i ) N where δ(•) is the indicator function, which is 1 if true else 0, and N is the total number of mentions among all documents.</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33890</th>\n",
       "      <td>33890</td>\n",
       "      <td>13569843</td>\n",
       "      <td>For instance, if q i was true only once in the training data, then, depending on the value for y that time, we would assign a probability of 1 or 0.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23276</th>\n",
       "      <td>23276</td>\n",
       "      <td>26276428</td>\n",
       "      <td>For w i , we can expect that this will be true for more than one category.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>9900</td>\n",
       "      <td>233443843</td>\n",
       "      <td>The famous source-coding theorem of Shannon (1948) gives us a theoretical limit on coding cost: H(M ) ≤ cost(C ) &lt; H(M ) + 1 (5) where we define C to be the most efficient code, and where H(M ) is the entropy of distribution p: H(M ) = m∈M p(m) log |Σ| 1 p(m) (6) According to the source-coding theorem, if we know the true distribution p over lexical meanings, then we know how to optimally code them.</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35985</th>\n",
       "      <td>35985</td>\n",
       "      <td>5361885</td>\n",
       "      <td>This is true whether one uses EM or not--a method that yields the \"wrong\" estimates on complete data does not improve when EM is used to extend the method to incomplete data.</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12804</th>\n",
       "      <td>12804</td>\n",
       "      <td>218763425</td>\n",
       "      <td>In fact, Stahlberg and Byrne (2019) show that oftentimes the true mode is the empty sequence.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27080</th>\n",
       "      <td>27080</td>\n",
       "      <td>32482544</td>\n",
       "      <td>Cosine similarity was computed as follows, cosine(G, P ) = n i=1 G i * P i n i=1 G 2 i * n i=1 P 2 i where, G represents the vector of true sentiment polarity values and P represents the vector of predicted sentiment polarity values by the system.</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17139</th>\n",
       "      <td>17139</td>\n",
       "      <td>394655</td>\n",
       "      <td>Otherwise we add an edge from m i to m j for every positive relation R + such that R + (m i , m j ) is true.</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33586</th>\n",
       "      <td>33586</td>\n",
       "      <td>6373755</td>\n",
       "      <td>If the hypothesis is true, we can proofread among the auto-tagged results only those words with low confidence values.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19376</th>\n",
       "      <td>19376</td>\n",
       "      <td>9970174</td>\n",
       "      <td>Our SS system finds fewer than the true number of boundaries (14.52 on average), while the combined system SS+C finds almost precisely the correct number (19.98 on average).</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30635</th>\n",
       "      <td>30635</td>\n",
       "      <td>232021614</td>\n",
       "      <td>3CosAvg tests the first goal, the second is always true in analogy completion tasks, and LRCos tests the third.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18347</th>\n",
       "      <td>18347</td>\n",
       "      <td>241583385</td>\n",
       "      <td>This is particularly true for the control trends of H(S|C), whose slope, too, is determined by H(S).</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>6461</td>\n",
       "      <td>1028231</td>\n",
       "      <td>While it is certainly true that carers speak to small children in sentences of simple structure (Motherese), this is not true for all of the data that the child has access to, nor is it universally valid.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20612</th>\n",
       "      <td>20612</td>\n",
       "      <td>10490228</td>\n",
       "      <td>But in the two years that followed, he delivered a true recovery economic growth and job creation were three times higher than in the Obama Economy.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16088</th>\n",
       "      <td>16088</td>\n",
       "      <td>3141477</td>\n",
       "      <td>We tried over-sampling by giving a weight of 1000 to all true positive instances; this neither improved nor damaged the results.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17953</th>\n",
       "      <td>17953</td>\n",
       "      <td>3896503</td>\n",
       "      <td>These inferences are part of a heater's general knowledge and true of the worleJ. They are part of the knowledge in the association network.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31002</th>\n",
       "      <td>31002</td>\n",
       "      <td>8563533</td>\n",
       "      <td>In this subtask, we discriminate between true and false candidates.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39170</th>\n",
       "      <td>39170</td>\n",
       "      <td>226283491</td>\n",
       "      <td>We hypothesise that there is a true underlying \"EAAT2/C1-4 were found to be equally expressed in ALS patients and controls.\" \"</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31753</th>\n",
       "      <td>31753</td>\n",
       "      <td>18991996</td>\n",
       "      <td>Permanent' links are conditions that must be true for a certain action or state-of-affairs to bold.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38243</th>\n",
       "      <td>38243</td>\n",
       "      <td>13966561</td>\n",
       "      <td>9 ) and (10) cannot he true at the same time.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24163</th>\n",
       "      <td>24163</td>\n",
       "      <td>18208705</td>\n",
       "      <td>While it is true then that the use of CAT tools such as TM relies to a certain extent on translators extending their traditional skills without having to rethink their traditional values, this does not apply to the use of MT by translators.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>9485</td>\n",
       "      <td>933054</td>\n",
       "      <td>The final stage integrates all the analysis results by applying a classification method based on SVM to classify the candidate sentence pairs as true or false cases of non-uniform language.</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20491</th>\n",
       "      <td>20491</td>\n",
       "      <td>2276802</td>\n",
       "      <td>We ask 5 independent annotators on Amazon Mechanical Turk to read each p and then determine whether h is true, false, or unclear given p. 7 We take the majority answer as the true label.</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7752</th>\n",
       "      <td>7752</td>\n",
       "      <td>227230870</td>\n",
       "      <td>Possessive Extension Phrase Addition This attack modifies the previous sentence by appending phrases such as \"…but he wasn't sure\" and also prepending phrases such as \"it is true:...\".</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35670</th>\n",
       "      <td>35670</td>\n",
       "      <td>62673750</td>\n",
       "      <td>Similarly, \"For each X in the list (A B C), do P(X)\" is not the same as \"For all X, make P(X) true\"; once again, the scripting language defines an or: der, but not the logical language 1. •</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37577</th>\n",
       "      <td>37577</td>\n",
       "      <td>14857477</td>\n",
       "      <td>A bridging mention m i from the gold chain C G is a true positive (tp) if m i and its immediate predecessor from C * G (m i ) are members of the same system entity, and a false negative (fn) otherwise.</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37635</th>\n",
       "      <td>37635</td>\n",
       "      <td>3092326</td>\n",
       "      <td>Here, we study if this is also true for Chinese.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15351</th>\n",
       "      <td>15351</td>\n",
       "      <td>17785402</td>\n",
       "      <td>What we want to make is a data set containing many chat messages, for each of which we need its true language and user id. An important question to answer at this stage is whether we could rely on the keyboard language to find the true language for a message.</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>2822</td>\n",
       "      <td>779551</td>\n",
       "      <td>have sentential complements which do not represent true propositions.</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31786</th>\n",
       "      <td>31786</td>\n",
       "      <td>360138</td>\n",
       "      <td>this point, tile user system should instruct tile B-SUItE system to presume the chooses assumption associated with tile chosen action being executed, which will change its truth value from \"possibly believed true\" to \"delinitely believed true\".</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15780</th>\n",
       "      <td>15780</td>\n",
       "      <td>248779990</td>\n",
       "      <td>Word level evaluation: Given a list of ads A = {A 1 , A 2 , ..., A n }, for an ad A i , let ŶA i represent the predicted set of person names and Y A i represent 3 Details of parameter tuning is provided in Appendix D the set of true person names.</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21425</th>\n",
       "      <td>21425</td>\n",
       "      <td>174800484</td>\n",
       "      <td>2012) , which theoretically guarantee the recovery of the true parameters by overcoming the problem of local optima.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35031</th>\n",
       "      <td>35031</td>\n",
       "      <td>10451941</td>\n",
       "      <td>The minicomputer-based facilities and the fancy graphic di,play systems may be used in conjunction with the extended Boolean processing, since the two types of developments are somewhat independent of each other, The same is true of the systems that provide common interfaces to mulriple data bases.</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25873</th>\n",
       "      <td>25873</td>\n",
       "      <td>7419876</td>\n",
       "      <td>However, the true tree must include many names that fall outside our small observed corpora, so our model would be a more appropriate fit for a far larger corpus.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10942</th>\n",
       "      <td>10942</td>\n",
       "      <td>248178120</td>\n",
       "      <td>While this procedure reduced the size of the training set, we ensured that predictions on the true/false dimension would need to use the dialogue representations.</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>11496</td>\n",
       "      <td>8096508</td>\n",
       "      <td>Denote the number of true positive, false positive, true negative and false negative snippets for all the test queries are TP,F P , TN, FN respectively.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229</th>\n",
       "      <td>8229</td>\n",
       "      <td>2432242</td>\n",
       "      <td>As the table shows, this pattern also held true for our eval test.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16288</th>\n",
       "      <td>16288</td>\n",
       "      <td>207760723</td>\n",
       "      <td>Comparison of judgments of true but underinformative simple declaratives (i.e. There is an X) to judgments of true but underinformative disjunctions (i.e. There is an X or a Y) on two-animal card conditions revealed some amount of scalar diversity.</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>5017</td>\n",
       "      <td>327870</td>\n",
       "      <td>Also, we did not divide a noun phrase to multiple mentions if the relation between the mentions is not always true (cf. \"</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28448</th>\n",
       "      <td>28448</td>\n",
       "      <td>248810772</td>\n",
       "      <td>Instead, we consider each true system response in the evaluation dataset in isolation and generate a response for each, given the conversation history up until that point.</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23448</th>\n",
       "      <td>23448</td>\n",
       "      <td>17947686</td>\n",
       "      <td>In order to further validate the true positives, we did a second round of annotation by randomly dividing the 427 true positives into three lots, and had two annotators to again check each true positive instance.</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21927</th>\n",
       "      <td>21927</td>\n",
       "      <td>182953258</td>\n",
       "      <td>If true, this result implies that CNN-SC prefers not only in-domain data but also a representative sample of paragraphs from all class labels.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33276</th>\n",
       "      <td>33276</td>\n",
       "      <td>224707518</td>\n",
       "      <td>R(s, a) = L Sim(v, v) a is Stop, 0 otherwise, where v is the selected best attribute value and v is the true attribute value.</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9438</th>\n",
       "      <td>9438</td>\n",
       "      <td>8742160</td>\n",
       "      <td>The new binary feature exploits the fact that the possible translation lists are typically different for different senses of the same verb: given a verb token and an aligned token from the other language, the feature is set to \"true\" for those candidate senses that have the aligned token's lemma on the list of their possible translations.</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>8391</td>\n",
       "      <td>16042317</td>\n",
       "      <td>Wikipedia-feature is assigned a true value for keyphrase aspirants for which there exists a Wikipedia article with the same title.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4644</th>\n",
       "      <td>4644</td>\n",
       "      <td>3067452</td>\n",
       "      <td>Relative to the top level annotation lung cancer, the scores are summed to yield 1, meaning that we get a true positive.</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20460</th>\n",
       "      <td>20460</td>\n",
       "      <td>17856283</td>\n",
       "      <td>s ∼ G, (x, c) ∈ X s,q Let s be the stack of s , q = s, q • (x, c) 1: function MAIN( s, q , (x, c), ΦG) 2: if x is SHIFT then 3: if c ≡ c lex 0 then c not gold lexical category 4: return false 5: else if c ≡ c lex 0 and |s| = 0 then the initial item 6: return true 7: else if c ≡ c lex 0 and |s| = 0 then 8: compute R(c s 1 , c s 0 ) 9: return R(c s 1 , c s 0 ) = ∅ 10: if x is REDUCE then s is non-frontier 11: if c ∈ R(cs 1 , cs 0 ) then 12: compute R(c s 1 , c s 0 ) 13: return true 14: else return false 15: if x is UNARY then 16: if |s| = 1 then s is frontier 17: return c ∈ ΦG 18: if |s| = 1 and c ∈ ΦG then s is non-frontier 19: compute R(c s 1 , c s 0 ) 20: return R(c s 1 , c s 0 ) = ∅ A key to defining the dependency oracle function is the notion of a shared ancestor set.</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23363</th>\n",
       "      <td>23363</td>\n",
       "      <td>2856630</td>\n",
       "      <td>The Symbolic Approach Tweet emotion detection For this task, we determined a baseline against which to gauge the performance of our classifiers by calculating precision, recall and F-score for each emotion in the ETCC corpus according to the simple presence or absence of the appropriate emotion hashtag in the tweet text (e.g. \"anger\" in the ANGER tweets were considered true positives, \"anger\" absent from an ANGER tweet was a false negative, and so on).</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>8045</td>\n",
       "      <td>8264993</td>\n",
       "      <td>The reverse can be true as well.</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14901</th>\n",
       "      <td>14901</td>\n",
       "      <td>231986109</td>\n",
       "      <td>We calculate the absolute difference between the estimation and the true average reward.</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37982</th>\n",
       "      <td>37982</td>\n",
       "      <td>18409855</td>\n",
       "      <td>Thus, given a text-hypothesis pair, we recognize the relation between the meanings of the text and the hypothesis in the pair as a true entailment if the meaning of the hypothesis is entailed from the meaning of the text.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35360</th>\n",
       "      <td>35360</td>\n",
       "      <td>18823236</td>\n",
       "      <td>PP-head If is-PP is true, this is the head of the prepositional phrase; otherwise it is zero.</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13361</th>\n",
       "      <td>13361</td>\n",
       "      <td>58857344</td>\n",
       "      <td>Austin's idea was that propositions are not objects that are true or false simpliciter but are true or false with respect to the part of the world that is being described.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30101</th>\n",
       "      <td>30101</td>\n",
       "      <td>218517141</td>\n",
       "      <td>It is also true that all directions in the range (φ + ω, φ − ω) will not satisfy Eq.</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22555</th>\n",
       "      <td>22555</td>\n",
       "      <td>219573632</td>\n",
       "      <td>µ 0 and µ 1 represent the prior number of false/true fact the pattern extract, and κ 0 and κ 1 determine the prior sum of false/true fact count: λ p ( * ) 0 ∼ Gamma(µ 0 , κ 0 ); (3) 1 ) if l fe = 1.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24704</th>\n",
       "      <td>24704</td>\n",
       "      <td>2602353</td>\n",
       "      <td>The best analysis of the corpus is taken to be the true analysis, the frequencies are re-estimated, and the algorithm is repeated until it converges.</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35451</th>\n",
       "      <td>35451</td>\n",
       "      <td>5638681</td>\n",
       "      <td>With an appropriate canon, many undesirable graphs are ruled out as noncanonical, but the canonical graphs are not necessari!y true.</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13467</th>\n",
       "      <td>13467</td>\n",
       "      <td>15518970</td>\n",
       "      <td>Third, they propose to measure performance only on frame elements using the \"Exact match condition\", i.e. both the label and the span of the projected role have to match the gold standard annotation for the target language to count as a true positive.</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13700</th>\n",
       "      <td>13700</td>\n",
       "      <td>235358498</td>\n",
       "      <td>This means that more precise knowledge can be acquired when learning the true underlying ambiguity of questions instead of the sometimes misleading gold-label.</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20942</th>\n",
       "      <td>20942</td>\n",
       "      <td>212725651</td>\n",
       "      <td>For example, Logit Normalization Technique MRR@10 (1) None (\"true\" logit only) 0.026 (2) Softmax on all logits 0.379 (3) Softmax on \"true\"/\"false\" logits only 0.381 we could rerank documents according to the logit of the \"true\" token only or using logits of all tokens to compute the softmax.</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>20401</td>\n",
       "      <td>1860878</td>\n",
       "      <td>Note that sentence-level scores are always at least as high as token-level scores, since it is possible to select a sentence correctly but none of its true relation tokens while the opposite is not possible.</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  corpus_id  \\\n",
       "33556       33556  235097435   \n",
       "26575       26575  208139384   \n",
       "30718       30718    3126524   \n",
       "5298         5298   44109570   \n",
       "21466       21466    6677927   \n",
       "3178         3178  247594019   \n",
       "4440         4440     427084   \n",
       "30968       30968    9228771   \n",
       "3541         3541  199000861   \n",
       "11627       11627   16223112   \n",
       "17691       17691   18712337   \n",
       "37056       37056  202235043   \n",
       "15600       15600   18111831   \n",
       "39324       39324  199424813   \n",
       "7969         7969  247595094   \n",
       "4716         4716    9623634   \n",
       "38947       38947  227231142   \n",
       "39750       39750   48374376   \n",
       "18986       18986  237513923   \n",
       "26673       26673     558258   \n",
       "14518       14518    6342059   \n",
       "21620       21620   71148539   \n",
       "32547       32547  199379857   \n",
       "33362       33362  243865621   \n",
       "36992       36992    1526921   \n",
       "15624       15624    2551840   \n",
       "10155       10155   11551180   \n",
       "13583       13583   28126691   \n",
       "9220         9220  241583486   \n",
       "31064       31064    7596434   \n",
       "27848       27848     104744   \n",
       "31940       31940  250390598   \n",
       "40209       40209  227209515   \n",
       "4271         4271  204885369   \n",
       "33400       33400  222091022   \n",
       "19666       19666  221187043   \n",
       "32216       32216    7177714   \n",
       "35627       35627  248084905   \n",
       "5245         5245  174799458   \n",
       "14764       14764   16763028   \n",
       "2378         2378  236478233   \n",
       "9291         9291   13908311   \n",
       "33663       33663    6323862   \n",
       "40565       40565  233365334   \n",
       "34209       34209   28148522   \n",
       "8051         8051  202544040   \n",
       "633           633    5187134   \n",
       "32499       32499   53082197   \n",
       "19643       19643    1076380   \n",
       "326           326  131773759   \n",
       "4210         4210     521137   \n",
       "30040       30040  222290454   \n",
       "29746       29746  225041060   \n",
       "9745         9745  250390627   \n",
       "32448       32448  202774805   \n",
       "25582       25582   25940328   \n",
       "16186       16186  233209971   \n",
       "37622       37622  235658689   \n",
       "29526       29526    5816453   \n",
       "26417       26417  248085885   \n",
       "18692       18692  237485621   \n",
       "19991       19991    6489978   \n",
       "37233       37233  213719646   \n",
       "12666       12666   13051685   \n",
       "3298         3298   16470003   \n",
       "18414       18414   14222290   \n",
       "38949       38949  227231142   \n",
       "32877       32877  237364106   \n",
       "40428       40428  226283839   \n",
       "7093         7093    2613012   \n",
       "15333       15333  226262218   \n",
       "5721         5721    9665780   \n",
       "39792       39792    8211364   \n",
       "14917       14917   13936472   \n",
       "35187       35187    9922498   \n",
       "9548         9548      86111   \n",
       "7724         7724    5410772   \n",
       "22835       22835  233296446   \n",
       "4133         4133     712473   \n",
       "14277       14277  248780123   \n",
       "30204       30204  233405184   \n",
       "4222         4222   17487884   \n",
       "30018       30018   51890955   \n",
       "10078       10078   18458434   \n",
       "11092       11092   31006069   \n",
       "11118       11118  226283642   \n",
       "32581       32581   53080215   \n",
       "4018         4018    6745820   \n",
       "15195       15195  248780356   \n",
       "29023       29023    1211840   \n",
       "3957         3957    2687019   \n",
       "35388       35388   18679018   \n",
       "12348       12348    1681159   \n",
       "14598       14598   12665845   \n",
       "20209       20209   53577360   \n",
       "21130       21130  119069467   \n",
       "17930       17930   12505676   \n",
       "37828       37828   11987101   \n",
       "154           154  203591833   \n",
       "19906       19906    9016539   \n",
       "34510       34510     600719   \n",
       "17143       17143   10230907   \n",
       "14344       14344  245218415   \n",
       "18714       18714   15548934   \n",
       "38485       38485   52142083   \n",
       "32740       32740  202763196   \n",
       "9236         9236   16456504   \n",
       "35568       35568   11996398   \n",
       "16054       16054  204874503   \n",
       "1295         1295  107331975   \n",
       "26301       26301   12585424   \n",
       "36925       36925  219302968   \n",
       "32441       32441  202789710   \n",
       "40140       40140  235097679   \n",
       "557           557   52808826   \n",
       "30132       30132  247447100   \n",
       "8555         8555   51874206   \n",
       "1787         1787    1039864   \n",
       "11426       11426   13174124   \n",
       "35418       35418   30167514   \n",
       "5228         5228  218581979   \n",
       "7695         7695     789848   \n",
       "31495       31495  244051004   \n",
       "15042       15042    1876856   \n",
       "39653       39653   10616494   \n",
       "8472         8472    9975083   \n",
       "7177         7177    1034340   \n",
       "24305       24305  233209981   \n",
       "6330         6330   14474596   \n",
       "21820       21820  174800717   \n",
       "37280       37280  245433917   \n",
       "31868       31868   15726857   \n",
       "33752       33752    7898970   \n",
       "31484       31484   18070886   \n",
       "10189       10189  218974040   \n",
       "19682       19682   59599691   \n",
       "17036       17036   15956331   \n",
       "26272       26272   36965648   \n",
       "13296       13296   17506596   \n",
       "26514       26514  231592352   \n",
       "4683         4683  235127261   \n",
       "13831       13831   13614607   \n",
       "18821       18821    7904050   \n",
       "28902       28902    2638760   \n",
       "38520       38520   52141013   \n",
       "16467       16467   11058419   \n",
       "23473       23473   13391714   \n",
       "29181       29181     382187   \n",
       "18126       18126   17493348   \n",
       "2867         2867   21731209   \n",
       "22186       22186   14792663   \n",
       "34521       34521     600719   \n",
       "8196         8196    7708706   \n",
       "31813       31813   15134057   \n",
       "31457       31457   10505260   \n",
       "18180       18180  214802016   \n",
       "30373       30373    7523960   \n",
       "18609       18609  222379592   \n",
       "13287       13287    5220041   \n",
       "39441       39441    6574418   \n",
       "12665       12665  247939929   \n",
       "32767       32767   18932500   \n",
       "2746         2746    6386563   \n",
       "40262       40262   10350260   \n",
       "33325       33325  237581611   \n",
       "2643         2643   16531053   \n",
       "859           859    7207849   \n",
       "5002         5002  227230600   \n",
       "30805       30805  231643046   \n",
       "32853       32853   62853828   \n",
       "18206       18206    6819967   \n",
       "33495       33495        543   \n",
       "478           478   16923208   \n",
       "30084       30084  220045140   \n",
       "4167         4167  232222259   \n",
       "15653       15653   16097412   \n",
       "14957       14957    3888499   \n",
       "28349       28349  231602963   \n",
       "24433       24433  233189596   \n",
       "21896       21896  221818956   \n",
       "29319       29319   13163488   \n",
       "8963         8963  237055475   \n",
       "637           637    5187134   \n",
       "38585       38585  221097958   \n",
       "1514         1514  226284017   \n",
       "39075       39075  201740458   \n",
       "9097         9097  248780508   \n",
       "5903         5903    9013266   \n",
       "22922       22922  218487098   \n",
       "31007       31007    6161073   \n",
       "22750       22750  233189603   \n",
       "29711       29711  201666088   \n",
       "36111       36111   18860723   \n",
       "30261       30261  239017038   \n",
       "7575         7575    8333909   \n",
       "32322       32322   18733074   \n",
       "25957       25957  237213618   \n",
       "13426       13426    9707387   \n",
       "32839       32839  220046708   \n",
       "32346       32346    5753846   \n",
       "21295       21295  201657818   \n",
       "2701         2701    1200082   \n",
       "30556       30556    6795973   \n",
       "12184       12184   16075189   \n",
       "8271         8271   21701770   \n",
       "38855       38855   15030503   \n",
       "12388       12388  202784449   \n",
       "1157         1157    9080688   \n",
       "22789       22789   18340881   \n",
       "15115       15115  234345309   \n",
       "7773         7773   28572853   \n",
       "19849       19849  235097421   \n",
       "25255       25255   10539461   \n",
       "2357         2357     426998   \n",
       "27167       27167   18289778   \n",
       "21921       21921  226226713   \n",
       "18017       18017    1583135   \n",
       "3416         3416   16210778   \n",
       "18920       18920     746333   \n",
       "35735       35735    2262192   \n",
       "17088       17088  248157591   \n",
       "3897         3897  222140820   \n",
       "22313       22313    2845210   \n",
       "4530         4530  237503252   \n",
       "19061       19061   14647620   \n",
       "15551       15551    6630458   \n",
       "2072         2072  226262339   \n",
       "12855       12855  227231118   \n",
       "31114       31114    2401184   \n",
       "32749       32749  201103945   \n",
       "21501       21501  229924289   \n",
       "29995       29995    5846516   \n",
       "13051       13051   10464407   \n",
       "36031       36031    3856149   \n",
       "28313       28313  233189520   \n",
       "29997       29997    5846516   \n",
       "40162       40162    1840980   \n",
       "30231       30231    6694415   \n",
       "37921       37921  184483092   \n",
       "2057         2057   15227710   \n",
       "25384       25384   14095018   \n",
       "35607       35607   15637201   \n",
       "19809       19809   16617195   \n",
       "37650       37650   13579675   \n",
       "24246       24246  250390646   \n",
       "35458       35458    5304321   \n",
       "2877         2877     765547   \n",
       "25320       25320     774866   \n",
       "2212         2212    5715019   \n",
       "2163         2163    9203411   \n",
       "35920       35920   14621757   \n",
       "19890       19890     344550   \n",
       "6022         6022    2731424   \n",
       "15706       15706   14446047   \n",
       "20600       20600    7206421   \n",
       "7122         7122  244119739   \n",
       "14950       14950   14974322   \n",
       "25726       25726     729163   \n",
       "32709       32709  249625490   \n",
       "36387       36387    6048999   \n",
       "12304       12304  195750836   \n",
       "17952       17952    3896503   \n",
       "6297         6297   17161699   \n",
       "33023       33023  243865381   \n",
       "16053       16053  248962366   \n",
       "4963         4963   14552960   \n",
       "1901         1901   16377016   \n",
       "2016         2016   10714273   \n",
       "27012       27012    6980436   \n",
       "34447       34447    9163485   \n",
       "6892         6892  220057351   \n",
       "9935         9935  248118589   \n",
       "14899       14899  231986109   \n",
       "18502       18502   11574815   \n",
       "8374         8374  202782321   \n",
       "10023       10023  237451171   \n",
       "37110       37110    2468783   \n",
       "4927         4927   11131833   \n",
       "3090         3090   44113199   \n",
       "12729       12729  218973702   \n",
       "30081       30081  220045140   \n",
       "30387       30387    5371028   \n",
       "22469       22469  235303672   \n",
       "27148       27148    1130969   \n",
       "1790         1790    7628635   \n",
       "27679       27679    5369521   \n",
       "28042       28042  219302427   \n",
       "33610       33610   12928004   \n",
       "39240       39240  199022725   \n",
       "20556       20556   19226723   \n",
       "32559       32559   52971170   \n",
       "917           917    6019603   \n",
       "3347         3347    1193152   \n",
       "27371       27371   33743229   \n",
       "3639         3639   13341920   \n",
       "13796       13796   15047929   \n",
       "18975       18975   51918720   \n",
       "28571       28571    4408231   \n",
       "37606       37606   17387910   \n",
       "21598       21598  202538985   \n",
       "13202       13202  215800828   \n",
       "31310       31310   18718806   \n",
       "32506       32506    3201076   \n",
       "28918       28918  243865273   \n",
       "1084         1084   16936514   \n",
       "9357         9357   31080548   \n",
       "17749       17749   11825156   \n",
       "36741       36741     134248   \n",
       "13634       13634    5620421   \n",
       "33517       33517  235422654   \n",
       "16522       16522  248118588   \n",
       "38148       38148    1270797   \n",
       "18803       18803    2333978   \n",
       "20831       20831  236460013   \n",
       "15174       15174   44084674   \n",
       "3003         3003    2922398   \n",
       "12036       12036  210044174   \n",
       "6046         6046      58302   \n",
       "19548       19548   44063972   \n",
       "32687       32687  202776155   \n",
       "2071         2071  226262339   \n",
       "7119         7119    3223514   \n",
       "5110         5110  202540591   \n",
       "19475       19475    2315102   \n",
       "34649       34649   67239762   \n",
       "1236         1236   53235202   \n",
       "22519       22519  250390926   \n",
       "34763       34763   11878680   \n",
       "14741       14741    3876179   \n",
       "22029       22029  102350590   \n",
       "30644       30644   15619421   \n",
       "33543       33543       1437   \n",
       "12435       12435  227230832   \n",
       "15912       15912  227231594   \n",
       "26554       26554    1455285   \n",
       "23902       23902  234763107   \n",
       "19993       19993    6489978   \n",
       "15065       15065      99196   \n",
       "13757       13757    3892641   \n",
       "22462       22462  248780478   \n",
       "9002         9002   10551763   \n",
       "20173       20173   40503511   \n",
       "39439       39439    6574418   \n",
       "30227       30227    6694415   \n",
       "6194         6194    1881596   \n",
       "27807       27807    2380594   \n",
       "2559         2559   10570679   \n",
       "22453       22453  247233685   \n",
       "24308       24308  218974041   \n",
       "3978         3978    1290272   \n",
       "29225       29225  219182005   \n",
       "2096         2096  174797774   \n",
       "11362       11362     815755   \n",
       "21662       21662    8965491   \n",
       "3637         3637   14922772   \n",
       "39946       39946    7009464   \n",
       "26340       26340  234482939   \n",
       "27408       27408   51940055   \n",
       "16498       16498  220512955   \n",
       "31189       31189    2772094   \n",
       "36029       36029     912349   \n",
       "9603         9603   10969391   \n",
       "14147       14147   10707097   \n",
       "22908       22908  226222033   \n",
       "31478       31478   18070886   \n",
       "5960         5960  218974002   \n",
       "30685       30685  204867474   \n",
       "24146       24146    1494188   \n",
       "3190         3190    5679981   \n",
       "39616       39616   96442562   \n",
       "10657       10657    6190877   \n",
       "34303       34303   14692027   \n",
       "7490         7490  201710452   \n",
       "8617         8617    8558112   \n",
       "26893       26893  237256842   \n",
       "6831         6831   18877507   \n",
       "29646       29646  247762111   \n",
       "12853       12853  235795697   \n",
       "16805       16805    8066686   \n",
       "40086       40086    2211971   \n",
       "24877       24877    2408543   \n",
       "14077       14077    1692763   \n",
       "11540       11540    8015669   \n",
       "6535         6535    1140080   \n",
       "30131       30131  247447100   \n",
       "40076       40076  235097296   \n",
       "5271         5271   14917259   \n",
       "14778       14778  225067907   \n",
       "19165       19165   17100741   \n",
       "2011         2011    2265838   \n",
       "25237       25237    3899390   \n",
       "15881       15881  204762959   \n",
       "37927       37927  214612871   \n",
       "26123       26123     648382   \n",
       "8522         8522   46932607   \n",
       "25099       25099  201683127   \n",
       "28215       28215    2133607   \n",
       "37208       37208   15852664   \n",
       "15             15  236881122   \n",
       "32837       32837  220046708   \n",
       "22546       22546  219573632   \n",
       "24176       24176  218973843   \n",
       "31971       31971  245838383   \n",
       "7901         7901    6741119   \n",
       "11587       11587  250390781   \n",
       "27852       27852    7255624   \n",
       "3774         3774  235097447   \n",
       "12090       12090   52011877   \n",
       "32618       32618    1451416   \n",
       "33305       33305  218517046   \n",
       "20978       20978  209091351   \n",
       "31639       31639  149449424   \n",
       "31488       31488  244064508   \n",
       "31627       31627   27757235   \n",
       "23228       23228   34211552   \n",
       "40225       40225   17964067   \n",
       "10867       10867  218486900   \n",
       "29334       29334   14195143   \n",
       "22500       22500  233033554   \n",
       "21862       21862  106402715   \n",
       "22826       22826  235358901   \n",
       "38716       38716  236486083   \n",
       "37714       37714   29904330   \n",
       "12747       12747  237277900   \n",
       "21129       21129  119069467   \n",
       "39756       39756   15822567   \n",
       "26045       26045  245118159   \n",
       "5050         5050  243865344   \n",
       "2652         2652   10048734   \n",
       "9478         9478     748227   \n",
       "11576       11576    5881871   \n",
       "8784         8784  201668251   \n",
       "38659       38659  219309265   \n",
       "23301       23301   38708803   \n",
       "30042       30042  202788853   \n",
       "20789       20789   39590706   \n",
       "28209       28209     874565   \n",
       "186           186  219303045   \n",
       "17823       17823  198183589   \n",
       "13164       13164  211818155   \n",
       "33890       33890   13569843   \n",
       "23276       23276   26276428   \n",
       "9900         9900  233443843   \n",
       "35985       35985    5361885   \n",
       "12804       12804  218763425   \n",
       "27080       27080   32482544   \n",
       "17139       17139     394655   \n",
       "33586       33586    6373755   \n",
       "19376       19376    9970174   \n",
       "30635       30635  232021614   \n",
       "18347       18347  241583385   \n",
       "6461         6461    1028231   \n",
       "20612       20612   10490228   \n",
       "16088       16088    3141477   \n",
       "17953       17953    3896503   \n",
       "31002       31002    8563533   \n",
       "39170       39170  226283491   \n",
       "31753       31753   18991996   \n",
       "38243       38243   13966561   \n",
       "24163       24163   18208705   \n",
       "9485         9485     933054   \n",
       "20491       20491    2276802   \n",
       "7752         7752  227230870   \n",
       "35670       35670   62673750   \n",
       "37577       37577   14857477   \n",
       "37635       37635    3092326   \n",
       "15351       15351   17785402   \n",
       "2822         2822     779551   \n",
       "31786       31786     360138   \n",
       "15780       15780  248779990   \n",
       "21425       21425  174800484   \n",
       "35031       35031   10451941   \n",
       "25873       25873    7419876   \n",
       "10942       10942  248178120   \n",
       "11496       11496    8096508   \n",
       "8229         8229    2432242   \n",
       "16288       16288  207760723   \n",
       "5017         5017     327870   \n",
       "28448       28448  248810772   \n",
       "23448       23448   17947686   \n",
       "21927       21927  182953258   \n",
       "33276       33276  224707518   \n",
       "9438         9438    8742160   \n",
       "8391         8391   16042317   \n",
       "4644         4644    3067452   \n",
       "20460       20460   17856283   \n",
       "23363       23363    2856630   \n",
       "8045         8045    8264993   \n",
       "14901       14901  231986109   \n",
       "37982       37982   18409855   \n",
       "35360       35360   18823236   \n",
       "13361       13361   58857344   \n",
       "30101       30101  218517141   \n",
       "22555       22555  219573632   \n",
       "24704       24704    2602353   \n",
       "35451       35451    5638681   \n",
       "13467       13467   15518970   \n",
       "13700       13700  235358498   \n",
       "20942       20942  212725651   \n",
       "20401       20401    1860878   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    sentence  \\\n",
       "33556                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Nevertheless, the two tasks differ in one key aspect: whether the combination 2 of the segmented morpheme sequence stays true to the initial orthography of the word.   \n",
       "26575                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           2018) use: (1) mean absolute error (MAE); and (2) mean absolute percentage error (MAPE), calculated as 100 n n i=1 ŷi −y i y i , where n is the number of examples and ŷi (y i ) the predicted (true) value.   \n",
       "30718                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         We use the simple approach of having a single binary feature per sense (e.g., role) that is set true whenever any of the associated collocation words for that sense are encountered (i.e., per-class-binary).   \n",
       "5298                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Although these word embeddings do not distinguish one semantic relation from another, we expect that true hypernyms will constitute a significant proportion of the predicted candidate hypernyms.   \n",
       "21466                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Also, some facts are only true for a certain time period, like being the president of a country.   \n",
       "3178                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        We can also define the outcome Y of a test example x i as the predicted probability of (pseudo) true label given by the trained model f (⋅): Y i (0) ∶= P f (L ′ = l ′ i | X = x i ) ∈ (0, 1). (   \n",
       "4440                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               In sum, the dialog system never knows the true state of the product nor the user's true actions, yet must still instruct the user to successfully restore the product to a working state.   \n",
       "30968                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Results We were interested in whether our working definition of cognation (translations and LCSR ≥ 0.58) reflects true etymological relatedness.   \n",
       "3541                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           In the open-world setting, it's quite possible that the answer entity t true (for a tail query) or h true (for a head query) does not exist in the KB (in E).   \n",
       "11627                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Note that, as discussed in Section 1, the list will contain true and false cognates.   \n",
       "17691                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   It is also unclear whether human examinees guess the text characters according to the true probability distribution.   \n",
       "37056                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The γ • Y (k) term is in effect a class-specific bias offset given the matched document, and the γ • y k variation directly balances the signal from the true token-level label and the prediction.   \n",
       "15600                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Therefore we label model bill sentences in M * that match a bill sentence with a score greater than 0.85 as true matches (S * ) 2 .   \n",
       "39324                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Hamming loss was the chosen metric for evaluation (Zhang and Zhou, 2014) , which computes the distance between predicted and true values.   \n",
       "7969                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     While training, this distribution is penalised for being different from the 'true' distribution (i.e. a probability of 1 for the true next token, 0 for all other tokens) using cross entropy loss.   \n",
       "4716                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          After the conversion, w1 will depend on w2 with a DEP label, and the same is true for w4 and w5; w2 will depend on w5 with label rel and w5 on a dummy word with label ROOT; w3 is ignored since it is not part of any entity.   \n",
       "38947                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          This could not be more true for endangered language archives.   \n",
       "39750                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Checking whether R ω a (x) is true requires global evaluation of the string to see if any position is labeled b. This is due to the existential quantifier ∃, which makes (17) strictly FO.   \n",
       "18986                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        We then have one of the authors and an additional expert annotator manually label all of the errors as true or false positives.   \n",
       "26673                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 They characterized three regimes: one where EM was successful in recovering the true clusters (given lots of data), another where EM failed but the global optimum was successful, and the last where both failed (without much data).   \n",
       "14518                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Because LDA needs to know the number of topics a priori, we set the number of topics to be equal to the true number of factoids.   \n",
       "21620                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     In order to create meaningful edges using training data as the only resource, we utilize the type co-occurrence matrix: if two type t 1 and t 2 both appear to be the true types of a particular entity mention, we will add an edge between them.   \n",
       "32547                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    This is true for many diseases in the i2b2 dataset.   \n",
       "33362                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Mean reciprocal rank is the average of the inverse of the mean rank assigned to the true triple over all candidate triples.   \n",
       "36992                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    However, by separating predicates from entities, we can have two different entities which chase is true of, where one co-occurs with a dog-entity ARG1 and catentity ARG2, while the other co-occurs with a catentity ARG1 and a mouse-entity ARG2.   \n",
       "15624                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     We exclude the years of the true examples from the dataset's year range, and then randomly choose years for the negative examples.   \n",
       "10155                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Thus, we tend to overestimate true word order freedom.   \n",
       "13583                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        If the ability is greater than the difficulty, the student is likely to succeed, or if the inverse is true, the student is more likely to fail.   \n",
       "9220                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         However, this is not true of all hypernyms: it is possible that BERT's use of generic hypernyms like \"thing\" stems from a memorization of frequent constructions like \"my favorite thing\" in the training data.   \n",
       "31064                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 If we take sufficient number of random words as nearby words, the sense distribution comes close to the true distribution, and then we expect the statistically true sense distribution should find out the true sense of the target word, according to the distributional hypotheses (Harris, 1954) .   \n",
       "27848                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The prosodic pseudo-punctuation symbol would replace the true preceding sibling's category in the model, thus possibly resulting in poorer overall performance (note however that the parser also includes a higher-order backoff distribution in which the next category is predicted using the preceding two sibling's categories, so the true sibling's category would still have some predictive value).   \n",
       "31940                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  When the other two distance scores correctly reflect the ground true similarity, like in the second example in Table 4 , the one with no overlap could be large, which spoils the overall prediction.   \n",
       "40209                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         As the true label in the AL setting is unknown, Zhang et al. (   \n",
       "4271                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      While it is of course true that were the AVG or GNN method able to perfectly capture the word order of the UD corpora, the rate of projectivity and Spearman's ρ would match exactly, but it is intriguing that short of perfection, Spearman's ρ and projectivity are not necessarily correlated.   \n",
       "33400                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               We apply Pareto to select maximum input sequences of 64 tokens for true/false questions and 180 for text and diagram MC.   \n",
       "19666                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     In consequence, the negation F1 is zero for the left sentence with the distorted facts and maximum for the sentence that sticks true to the facts.   \n",
       "32216                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Firstly, variations of the same token share the key words and present in similar patterns, for instance, it's true, this is true and true are all considered as variations of that's true, since they contain the same key word true with similar patterns.   \n",
       "35627                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Both the Hoeffding and Bernstein bounds are very loose, overestimating the true error in 100% of samples, by margins that are about an order of magnitude greater than the average error in Figure 4 .   \n",
       "5245                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Ultimately, we consolidated the above finegrained labels into the following coarse-grained labels, which we used for subtask B: * FACTUAL -TRUE: Contains answers with proven true, non-contradictory statements.   \n",
       "14764                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      DCU [baseline] Depending on the drink, some images of galaxias galaxies become true works of art.   \n",
       "2378                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             We can calculate how often this is true for the DeepHit model by calculating the concordance index of the predicted event times and the inverse of the censoring indicator.   \n",
       "9291                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   They introduce three data sets of true and lying texts containing 100 true and 100 false statements for each dataset.   \n",
       "33663                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       of them were (true) paraphrases.   \n",
       "40565                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             If this is true, then we should find similar results in languages that are typologically related to Hindi.   \n",
       "34209                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            salad, the semantic approaches allow us to say that it was a mass or count semantic representation of apple only after inspecting the kind of thing that apple is true of in the sentences.   \n",
       "8051                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                We treat such basic projections in trivalent semantics, where natural language sentences are represented using propositions that denote 1 (true), 0 (false) or (presupposition failure).   \n",
       "633                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ○(T alm ): When the text is true, the hypothesis is almost true. •   \n",
       "32499                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        For example, (Bill Clinton, presi-dentOf, USA) was true only from 1993 to 2001.   \n",
       "19643                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Finally, a Boolean feature (e.g., cues id ea ) is set to true if any word from the list is in the citing context.   \n",
       "326                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2019 ) and compute the true positive rate (TPR) race gap and the TPR gender gap-i.e., the differences in the TPRs between races and between genders, respectively-for each occupation.   \n",
       "4210                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This is especially true in the case of presentational relations.   \n",
       "30040                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       We treat each integer as a bucket and use the normalized counts in each bucket as the true distribution for that scalar attribute of the object.   \n",
       "29746                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       We predict the probability for every text fragment in a page and count the number of fragments whose true superior counterparts appears in the top k candidates.   \n",
       "9745                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Note that when the author has baseline information, it is the author's choice to decide whether or not to disclose the true information to the public.   \n",
       "32448                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     As discussed in Section 4.2, the true posterior we can obtain is in the form of the unordered set.   \n",
       "25582                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               2011) , who use a neural network to predict whether an n-gram is a true n-gram or a \"corrupted\" version.   \n",
       "16186                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Intra-rater agreement For quality control, annotation files contained a total of 69 randomly sampled duplicate pairs, in addition to the 1,360 true pairs.   \n",
       "37622                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Then we compute, in a similar fashion as a normal F1, the precision and recall using the soft definitions of the true positive, false positive, and false negative.   \n",
       "29526                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Future work must therefore gather a large corpus of true narratives, like fairy tales and children's stories, whose simple plot structures should provide better learning material, both for models predicting script events, and for related tasks like automatic storytelling (McIntyre and Lapata, 2009) .   \n",
       "26417                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            in a tweet tuesday night, trump said he \" would love to send ambassador [ sundland ], a really good man and great american, to testify, but unfortunately he would be testifying before a totally compromised kangaroo court, where republican ' s rights have been taken away, and true facts are not allowed out for the public to see. \"   \n",
       "18692                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -Consistency: highly consistent • (\"relax\", HASSUBEVENT, \"vegetable\") -Grammar: incorrect -Truthfulness: never true -Consistency: not consistent at all • (\"drink coffee\", HASSUBEVENT, \"water may get into your nose\") -Grammar: correct -Truthfulness: never true -Consistency: a little consistent (Our interpretation: Drinking coffee doesn't cause water to get into your nose, but coffee and water are both drinkable liquids, so we think this statement is a little consistent.)   \n",
       "19991                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The correct answer is true, so it shows the method works well for the decision.   \n",
       "37233                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 The second way of modifying surprisal theory would be to posit that the relevant probability distribution of words given contexts does not take into account full information from the context, or is distorted in some way relative to the true distribution of words given contexts.   \n",
       "12666                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        In order to understand better the true precision and recall of the automatic classification as compared to the handannotated data-set it would, of course, be highly beneficial to have a larger sample of hand-annotated data.   \n",
       "3298                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     In this case, given the imbalance between positive and negative pairs, we maximize weighted accuracy (that is, we count each true negative as (|pos| + |neg|)/2|neg|, and each true positive as (|pos| + |neg|)/2|pos|, where |class| is the cardinality of the relevant class in the tuning data).   \n",
       "18414                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            That is, (true pos + inv pos) divided by (true pos + inv pos + f alse pos).   \n",
       "38949                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Anthropologists interested in material culture now have a very simple entry point into the data; the same is true for ethnozoologist/ornithologists and their kin.   \n",
       "32877                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      For EL, we use (i) mention-level F1 score (EL m ), and (ii) cluster-level hard F1 score (EL h ) that counts a true positive only if both the coreference cluster (in terms of all its mention spans) and the entity link are correctly predicted.   \n",
       "40428                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   We can formalize it as: T P C j = I y i =C j * I C j =y i (4) where: I X = 1 if X is true 0 if X is false We propose a continuous generalization as the confidence true positive: cT P C j = M (x i , C j ) * I C j =y i (5) As shown in Equation 5 , we're simply replacing the binary I y i =C j from Equation 4 by the continuous M (x i , C j ).   \n",
       "7093                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Computing the true translation probability would require the same operation to be repeated in every cell during decoding, which is very time consuming.   \n",
       "15333                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        In contrast, our model reduces the difference in scores for a human entity's true sensitive attributes and the alternatives (shown in Table 5 ) significantly for FB15K and FB3M. For Wikidata, we still see a notable gap between these scores (for example of 0.49 for gender), suggesting some information about these attributes remains in the embeddings.   \n",
       "5721                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       When margin = 2 the ratio true positive/true negative is maximal.   \n",
       "39792                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Recall, as defined in (8), is the number of true positives divided by the number of true positives plus false negatives.   \n",
       "14917                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The same is true for the implementation described in Eisner (1997a) , although a proposal is given there for a method that might improve the situation.   \n",
       "35187                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             To see that this is true, execute the following algorithm.   \n",
       "9548                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Because we train both our model and the standard phrase table on the same dataset, we use leaving-one-out in the classifier training to avoid Feature Type Configurations Czech German Polish, Romanian Source Indicator f, l, l+t, t f, l, l+t, t l, t Source Internal f, f+a, f+p, l, l+t, t, a+p f, f+a, f+p, l, l+t, t, a+p l, l+a, l+p, t, a+p Source Context f (-3,3), l (-3,3), t (-5,5) f (-3,3), l (-3,3), t (-5,5) l (-3,3), t (-5,5) For target-side context features, we simply use the true (gold) target context.   \n",
       "7724                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              For FTC, it will be the probability of observing the difference (referred to as the evidence, E) between the offender's and the suspect's samples if they had come from the same author (H p ) (i.e. if the prosecution hypothesis is true) relative to the probability of observing the same evidence (E) if they had been produced by different authors (H d ) (i.e. if the defence hypothesis is true).   \n",
       "22835                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Following such schema, models were instead required to produce a continuous score representing how likely the premise is true given the hypothesis.   \n",
       "4133                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         QA and IR It is true that, intrinsically, IR engines and QA systems differ in design, objectives and processes.   \n",
       "14277                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          B.2 Zero-shot TPE Classification We build the previous premise-hypothesis construction in § 4.4 based on the assumption of availability of TPE, which is frequently not true.   \n",
       "30204                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         operator: RUN </s> generated answer:true, NAF.   \n",
       "4222                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                R's answer circumvents this problem, by conveying the extent to which the questioned proposition (on the strict interpretation) is true.   \n",
       "30018                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         We contrast using random negatives with carefully selected hard negatives that challenge the model to distinguish between true translation pairs versus non-translation pairs that exhibit some degree of semantic similarity.   \n",
       "10078                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   For example, 'sharp' and 'clear' are conceptually related to camera picture qualities, but they are not true synonyms from a linguistic perspective.   \n",
       "11092                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    This is especially true in overcoming language barriers of today's global communication besides supporting underresourced language.   \n",
       "11118                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Then, the model with attention focuses mainly on the repeated part and marks the misleading statement as \"true\".   \n",
       "32581                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          As in most cases of multiview learning, these three properties are only approximately true for our problem. (   \n",
       "4018                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Next, we show the predicted and true distributions over attachment direction and distance.   \n",
       "15195                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         If true, the experiments' performance is printed on the shell.   \n",
       "29023                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         To describe our algorithm, we exploit an abstract data structure called a lazy list (aka generator, stream, pipe, or iterator), which supports three oper-ations: next(list): pops the front item from a list peek(list): returns the score of the front item empty(list): returns true if the list is empty A cube is a lazy list (of edges).   \n",
       "3957                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      However, as we do not have access to negative facts, the model would simply learn to predict all facts to be true.   \n",
       "35388                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The only difference is that we need to use words from previous sentences while we don't have true previous sentences but their best lists.   \n",
       "12348                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 This shows the true potential of the machine learning approach and the features chosen for the classification (see relatedness measures, Section 5.4).   \n",
       "14598                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Therefore, at training time, we replace the label y ji for the i-th segment of the j-th document (system output) by y ji − Q (true) j , where Q (true) j is the true overall quality of the j-th document.   \n",
       "20209                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              To this end, the model can use the presence of \"exit\" to classify true-belief from non-true-belief tasks.   \n",
       "21130                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 To create a negative sentence given a gold response, we pick a random phrase in the true response and replace it with a random phrase in another random true response.   \n",
       "17930                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      In our example, the premise to goal argument is the shortest, as it threads a path through the 6 nodes in the Argument Graph; the exclusive reasoning by cases argument is the longest, requiring 9 nodes (3 for the case where node 4 is false, 5 for the case where node 4 is true, and 1 for stating the conclusion); the non-exclusive reasoning by cases argument requires 8 nodes (3 for each case, 1 for node 6, which introduces the cases, and 1 for the conclusion); and the reductio ad absurdum argument requires 7 nodes (the 6 nodes in the Argument Graph plus 1 node for stating the conclusion).   \n",
       "37828                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     However, this is not exactly true.   \n",
       "154                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Model training We use negative log likelihood of the true labels as a loss function.   \n",
       "19906                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A true positive is a DNI which has been linked to the correct entity as given by the gold data.   \n",
       "34510                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          On the other hand, if we know both readings are true, then we can safely assert the ambiguous expression (2).   \n",
       "17143                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Assertion (9) states that the signal \"AWID\" is true at the point of evaluation, and must remain true for next clock cycle before the single \"AWVALID\" will be true, while assertion (10) states that the signal \"AWID\" is true, and may remain true for up to 3 further clock cycles, directly after which the single \"AWVALID\" will be true.   \n",
       "14344                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Although current systems achieve near-human F1 scores on this static evaluation, it is questionable whether this can faithfully reflect models' true performance in real-world applications.   \n",
       "18714                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         A preliminary manual analysis of the resulting list of relevant terms (true positives) revealed that a clear majority of the resulting terms were related to substance abuse -only one term was obviously problematic (years).   \n",
       "38485                                                                                                                                                                                                                                                                Following the tenets of the TPACK Framework (Koehler & Mishra, 2009) , which urges the researchers to consider the complex interplay of the three primary forms of knowledge: Content (C), Pedagogy (P), and Technology (T) and their intersections in the language classroom context, the researchers drew implications from these intersections: PCK or Pedagogical Content Knowledge, which refers to the knowledge of pedagogy that is applicable to the teaching of specific content that a teacher intends to teach; TCK or Technological Content Knowledge, which refers to the knowledge of the relationship between technology and content; TPK or Technological Pedagogical Knowledge, which refers to the components and capabilities of various technologies as they used in teaching and learning; and finally the TPACK or Technological Pedagogical Content Knowledge, which is the intersection of the three components characteristic of true technology integration in the classroom.   \n",
       "32740                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   It ranks all the entities in the graph for their likelihood to be the missing entity and the rank assigned to the true missing entity is considered.   \n",
       "9236                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The true class for datum x i is denoted with xi .   \n",
       "35568                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   is true, then only the full scopings are returned. (   \n",
       "16054                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The baseline model already corrects most typos, and while there are examples of phrases where the baseline model generates an incorrect word or inflection and the error-augmented model a correct one, the converse is true in other cases.   \n",
       "1295                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         We listed payment in an attempt to see if Frey and Goette's theory would hold true (see above).   \n",
       "26301                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           In particular, we vary the ratio of positive (true relations) and negative (the class Other) examples in the ACE 2005 dataset and see how the system performance responds to this variation.   \n",
       "36925                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Operands are set-of-support phrases which have a true interpretation in the model.   \n",
       "32441                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Each item has at least 8 annotations indicating the extent to which the speaker of the sentences are committed to the truth of the embedded clause (+3/speaker is certain that it is true, 0/speaker is not certain about its truth, −3/speaker is certain that it is false).   \n",
       "40140                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            However, since the algorithm developed in this study is a binary classier, scores 1 and 2 were considered true (task preformed) and 0 was considered false.   \n",
       "557                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          However, training on true case texts proved beneficial when translating from English to French, even when scoring in a case insensitive manner.   \n",
       "30132                                                                                        WMT'17 Edinburgh en-cs.l2r(1-4) ≤ 2 0 en-cs.r2l(1-4) ≤ 1 0 cs-en.l2r(1-4) ≤ 2 0 cs-en.r2l(1-4) 0 0 en-de.l2r(1-4) index c t , W ∈ R |C|×d , b ∈ R |C| Result: Whether c t is unargmaxable 1 unargmaxable = true 2 patience = 2500 3 x = w ⊤ c t 4 while patience do 5 c i = argmax(Wx + b) 6 if c i = c t then 7 unargmaxable = false 8 break 9 else 10 w = (w ct − w c i ) ⊤ 11 b = b ct − b c i 12 w ′ = w ∥w∥ 2 13 d = w ′ ⊤ x 14 x = x − 2(d + b ∥w∥ 2 )w ′ 15 patience = patience -1 16 end 17 end ≤ 1 0 en-de.r2l(1-4) ≤ 2 0 de-en.l2r(1-4) ≤ 2 0 de-en.r2l(1-4) 0 0 en-ru.l2r(1-4) 0 0 ru-en.l2r(1-4) 0 0 ru-en.r2l(1-4) 0 0 en-tr.l2r(1-4) ≤ 5 0 en-tr.r2l(1-4) ≤ 4 0 lv-en.l2r(1-4) 0 0 lv-en.r2l(1-4) ≤ 1 0 tr-en.l2r(1) 2 0 tr-en.l2r(2) 8 0 tr-en.l2r(3) 6 0 tr-en.l2r(4) 2 0 tr-en.r2l(1) 4 0 tr-en.r2l(2) 0 0 tr-en.r2l(3) 6 0 tr-en.r2l(4) 4 0 en-zh.l2r(1) 3 0 en-zh.l2r(2) 3 0 en-zh.l2r(3) 14 0 en-zh.l2r(4) 1 0 en-zh.r2l(1) 2 0 en-zh.r2l(2) 0 0 en-zh.r2l(3) 7 0 en-zh.r2l(4) 7 0 zh-en.l2r(1) 8 0 zh-en.l2r(2) 3 0 zh-en.l2r(3) 366 0 zh-en.r2l(1-3) ≤ 3 0 Table 8 : Unargmaxable token search results for Edinburgh WMT'17 submission (ensemble) models.   \n",
       "8555                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       It is true that movie dialogs promote stereotypes that may affect characters' expression of code-choice, however accommodative effects can still be expected to play out largely independent of such stereotypes.   \n",
       "1787                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Let y denote a possible world, the p(y) is defined as follows (Richardson and Domingos, 2006) : p(y) = 1 Z exp   ∑ (ϕ i ,w i )∈M w i ∑ c∈C n ϕ i f ϕ i c (y)   , where each c is a binding of free variable in ϕ i to constraints; f ϕ i c (y) is a binary feature function that returns 1 if the true value is obtained in the ground formula we get by replacing the free variables in ϕ i with the constants in c under the given possible world y, and 0 otherwise; C n ϕ i is all possible bindings of variables to constants, and Z is a normalization constant.   \n",
       "11426                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The symbols h a , l a , and d a are used to denote the head node, label, and dependent node, respectively, of an arc a (that is, a = (h a , l a , d a )); IN-SPAN(i) is true if i is contained in a span in S C ; END-SPAN(i) is true if i is the last word in a span in S C ; s(i) denotes the span containing i (with a dummy span for all words that are not contained in any span); r(s) denotes the designated root of span s (if any); #CC records the number of connected components in the current span up to and including the last word that was pushed onto the stack; NONE and ROOT are true if we allow no outgoing arcs from spans and if we allow outgoing arcs only from the span root, respectively.   \n",
       "35418                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Accordingly, Einstein's formula М(х-x 0 ) 2 = 2....(1) was applicable as well as the Einstein-Fokker-Plank equation, which holds true for Markov's processes.   \n",
       "5228                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  In the process of search, we optimized for macro-average F 1 score, i.e., averaging over the classes, since our dataset is not balanced, which is true for both tasks.   \n",
       "7695                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               One issue with our evaluation is that it assumes all tokens are true instances of the multiword unit in question; we carried out a manual inspection of multiword tokens identified by string match in our development sets (5000 sentences set aside from each of the abstract and blog corpora), and excluded from the evaluation a small set of idiomatic expressions (e.g. on it, do in) whose literal, non-MWE usage is too common for the expression to be used reliably for evaluation; otherwise, we were satisfied that the vast majority of multiword tokens were true matches.   \n",
       "31495                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2002) and a number of examples presenting true and false MWEs.   \n",
       "15042                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The Chernoff bound says that for any δ > 0, for the sum of n bernouilli variables with prob p and Now we bound each group separately, using the binomial Chernoff bound where n = mµ > mp (which is true since p < µ ) This bound decreases with p, so we can replace this for all strings in S k with the upper bound for the probability, and we can replace m with m 0 .   \n",
       "39653                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Conflict and Cooperation The machines response and the true category is best seen as a set of multinomial probabilities (with a unit vector with the value 1 at the index of the system's extracted category or the true category respectively.   \n",
       "8472                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2013) and defines 11 groups of features to capture how likely each candidate answer is the true answer for the question from different aspects, which includes answer type coercion, candidate answer occurrence count, name count, average overlapping token count, stopword count, overlapping concept count, token and concept proximity, etc.   \n",
       "7177                                                                                                                                                                                                                                                                                           If there exists a mapping from RMRS-D into RMRS-B such that: • for each index i, each anchor a, each label l and each relation r such that l:a:r(i) is in RMRS-D then for the corresponding label l', anchor a' and index i' it is true that l':a':r(i') is in RMRS-B; • for each anchor a, each index i and argument ARG such that a:ARG(i) is in RMRS-D then for the corresponding anchor a' and index i' it is true that a':ARG(i') is in RMRS-B; • for each handle h and each label l such that h =q l is in RMRS-D then for the corresponding handle h' and label l' it is true that h' =q l' is in RMRS-B; and • if l':a':i' is the hook of RMRS-B and for at least one of its elements there is a mapping from a corresponding element in RMRS-D, then there are mappings for all elements and original triple l:a:i is the hook of RMRS-D. then we say that RMRS-D is substructure of RMRS-B. The last condition is very strong and is subject to further refinement.   \n",
       "24305                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Among our results, there are many examples where the model detected spans in not annotated posts, for example: • \"uhhh Hillary Clinton is a serial killer and thief\": [] (true annotation), [26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 44, 45, 46, 47, 48] (our annotation, \"uhhh Hillary Clinton is a serial killer and thief\"); • \"This goes way beyond just being an asshole skipper, dude must have some serious mental issues\": [] (true annotation), [35, 36, 37, 38, 39, 40, 41] (our annotation, \"This goes way beyond just being an asshole skipper, dude must have some serious mental issues\").   \n",
       "6330                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Second, we argue that the true domain of lexical rules is not, in fact, the lexical item, but rather the referent of the lexical item.   \n",
       "21820                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         This was in general true, although we observed a different pattern to the previous experiment.   \n",
       "37280                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The same is true for the scenario of merging MCI and mAD patients (i.e., the 2-class identification task).   \n",
       "31868                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The future experiments will continue with new thesauri parsing: Russian, Spanish, Italian, but the true challenge shall be oriented towards Chinese / Japanese thesauri, aiming to establish a thorough lexical-semantics comparison and a language-independent, portable DEP technology based on SCD configurations.   \n",
       "33752                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  A manual sampling of VPEs in the Brown Corpus showed this to be true.   \n",
       "31484                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The path in the decision tree where both Locative and Deictic are true may be accounting for utterances in which an identity expression is used, rather than a true deictic.   \n",
       "10189                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   We generate all the paths by the following: for each category c, each true candidate x and each connector o we gen- So basically, if the connector is not used by category c or if x is not a true instance of c, then the combinations of x and connector c can be followed by any arbitrary words.   \n",
       "19682                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 An outcome which holds true for both data sets and two different ensemble model configurations (MarkerE and MarkerEB).   \n",
       "17036                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Since we noticed that the number of \"false\" pairs is much larger than the number of \"true\" ones in the training data of every iteration, we defined another parameter (currently 6) that limits the factor of \"false\" pairs allowed in the training data with respect to the \"true\" pairs.   \n",
       "26272                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           In a similar manner, the converse is true for the weights into the target unit representing the example (2).   \n",
       "13296                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The converse is true for the remainder of the lexicon: the words will all the same frequency as in the smaller samples, but their ranks will have increased in proportion to their distance above the Figure 12 .   \n",
       "26514                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Comparison with model that explicitly uses the true hierarchy We compare performance of our joint approach HIDDEN jnt against a state-of-the-art hierarchical multi-label classifier, HiLAP (Mao et al.,   \n",
       "4683                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Building on continued Moses development of Moses in the academic community and combined with other open source projects, Moses for Localization can serve as a crucial building block in a true end-to-end open source machine translation solution for the localization industry.   \n",
       "13831                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                For sentences it will return the probability that the sentence is true.   \n",
       "18821                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2  Slang: As with profanity, it is intuitively true that true news articles tend to avoid slang.   \n",
       "28902                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         However, the true probability cannot be known ahead of time and certainly not in a new domain.   \n",
       "38520                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         First, belief propositions of the form B w x ϕ are defined by doxastic accessibility: 8 (6) a. B w x ϕ → ∀w .wR dox x w : w ∈ W ϕ b. ¬B w x ϕ → ∃w .wR dox x w : w ∈ W ϕ c. B w x ¬ϕ → ∀w .wR dox x w : w ∈ W ϕ Thus, \"x believes ϕ to be true at w\" (B w x ϕ) means that at all worlds compatible with x's beliefs at w, ϕ is true ; \"x does not believe ϕ to be true at w\" (¬B w x ϕ) means that at least at one world compatible with x's beliefs at w, ϕ is false, and \"x believes ϕ to be false at w\" (B w x ¬ϕ) means that at no worlds compatible with x's beliefs at w at which ϕ is true (ϕ is false at all worlds compatible with x's beliefs at w).   \n",
       "16467                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The best results are obtained when combining all models, which remains true when considering mean results up to at least 8 rephrasings.   \n",
       "23473                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       We use SVN repository version 2444, giving the options --modal true --nn true --roles verbnet to Boxer and making some minor modifications to its code to better match our annotation scheme for adjectives, adverbs, semantic roles and modals.   \n",
       "29181                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Precision is defined as the number of true instances divided by number of true positives and false negatives.   \n",
       "18126                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       This is especially true since gestures usually take an extra effort from a user.   \n",
       "2867                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Qualitative analysis shows that L2W's continuation is often a straightforward continuation of the original text while the true continuation is more surprising and contains complex references to earlier parts of the book.   \n",
       "22186                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      We then use cosine similarity over these vector space models as features: Title Features: LIEL also contains a number of features that make use of the Wikipedia title of the entity links in t (remember t = entity mention tuples and not a Wikipedia title) : • NIL FREQUENCY: Computes the frequency of entities that link to N IL • EXACT MATCH FREQUENCY: returns 1 if the surface form of m is a redirect for e; • MATCH ALL: returns true if m matches exactly the title of e; • MATCH ACRONYM: returns true if m is an acronym for a redirect of e; • LINK PRIOR: the prior link probability P (e|m), computed from anchor-title pairs in KB (described in Section 2.3).   \n",
       "34521                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             However, if only one of R1 and R2 is true, then there is a model where Q is false, namely where R1 is true and C1 is false, and C2 is true but R2 is false, or vice versa.   \n",
       "8196                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Given a word w and two opposing styles (topics) p and n, we place w on the PN dimension according to the β of our trained model as follows: PN w = β pw − β nw β pw + β nw The normalization is important because otherwise more-common words would tend to have higher PN's, when in fact the opposite is true (rare words tend to be more stylistically prominent).   \n",
       "31813                                                                                                    ° b) another approach however consists in regarding the data base as a set of fomaulas and the process of answering a query as a deduction° A query wil] be said to be true with respect to the ~ita ]mse if and only if it can I~ <]educed frc~n ]to (Naturally as in the case of the first approach, this meth(x] app].ies (~qual]y well to closed sentences ( i°e yes-no questions) as well as to open sentences ( i.e W[I-questions)° ],'or an application of this im~thod as wo].l as for disc:ussion of its advantages (cf [PASERO~ 73])° ].'o~. reasons which w~ sha]l not spell out here we have chosen the ~ode] the(met]ca] approach (].e the first approach ) in OPERA° Needless to say it: is not Loo difficult and in fact, sclnetimes necessary~ as we shall see below, to c<mlpl6]nent the pure se~nantic evaluation with deductivo capacities.. 2-Sh:MANTICS VIA TRANS~TION IN'IY) LOGIC Even if it is clear in nmst respects how to obtain predicate logic: translaticms for a large w~riety of natura] language sentences, cf [WAR[~FM & PEREIRA, 82] we repeat here :[or the sake of clarity the essentials of the translation process in OPERA.   \n",
       "31457                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       It lower bounds the true distances of original data (Lin et al.,   \n",
       "18180                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   These results show that, though setting a threshold is a common heuristic to balance true and false acceptance rates (Larson et al.,   \n",
       "30373                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             As long as an upward path takes at least one step, making it to a scheme containing two or more alternating suffixes, our search strategy accepts the terminal scheme of the path as likely modeling a portion of a true inflection class.   \n",
       "18609                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            However, these sequences are unlikely to have any semantic correlation with the true label.   \n",
       "13287                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The fundamental assumption, in our \"unsupervised\" technique for WSD in this paper, is that the similarity of contextual features of the target with the pre-defined features of its sense in the lexical knowledge base provides a quantitative cue for identifying the true sense of the target.   \n",
       "39441                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    This allows the phrase to be selected or adjoined to again by anything that selects or adjoins to X. This model accounts for optionality and true transparency: the modified element remains the head ( Since this grammar is designed to model unordered modifiers, illicit orders are also derivable (Figure 6 ).   \n",
       "12665                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Misclassifications occur when the inferred label y i of an input x i does not correspond to the actual true label ŷi and thus ŷi = y i holds.   \n",
       "32767                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This is especially true of phonotactics: reduplication and metathesis, which have higher complexity, are not phonotactic patterns as they involve alternations.   \n",
       "2746                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Moreover, let the boolean function L(a i , u i ) to be true if the anchor text a i points to url u i .   \n",
       "40262                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This conjecture seems to be true for natural languages (the contrary would mean the possibility of unlimited extraction from extracted groups).   \n",
       "33325                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Questions we ask to search engines are often done in the comfort of our own homes, making them likely to reflect true stereotypes that are out there in the real world (Stephens-Davidowitz, 2018 • 'Why is [TGT] so [ATTR] ?' • '   \n",
       "2643                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          This is true of automatic summarization systems too, which consider the position of a sentence in a document and how it relates to its surrounding sentences (Kupiec, Pedersen, and Chen 1995; Barzilay and Elhadad 1997; Marcu 2000; Teufel and Moens 2002) .   \n",
       "859                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 In part this is true: most words translate to a word which is identical in its form and they happen to appear largely in the same order.   \n",
       "5002                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        However, this kind of pattern is not always true and an opposite case is shown in Figure 2 (b) .   \n",
       "30805                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Though it is true that the improvement was relatively small (between 1 % and 3 %), we must remember that in these cases the method was applied to a percentage of the synsets in Word-Net.   \n",
       "32853                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            But the same is not true for grammatical relations, and we get both OBJ(eat,banana, ) and OBJ(eat,apple, ).   \n",
       "18206                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        In future work, it would be useful to build a ternary classifier which labels Agree/Disagree/Neutral, thus reflecting the true distribution of these dialogue acts in the data.   \n",
       "33495                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      In general a probabilistic algorithm will make an estimate, 15, of this probability: 15(A= llV=v, Nl=nl, P=p, N2=n2) For brevity this estimate will be referred to from here on as: p(l[v, nl,p, n2) The decision can then be made using the test: ~(llv, nl,p, n2 ) >= 0.5 If this is true the attachment is made to the noun, !   \n",
       "478                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 The stability of evaluation results Question A can be rephrased in the following way: How much does the observed precision value for an acceptance region A differ from the true average precision π A ?   \n",
       "30084                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            While the work presented here targets possession relations, we believe that a similar approach could be used to to determine for how long any semantic relation holds true.   \n",
       "4167                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              This certainly rings true for NLP as well.   \n",
       "15653                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 In addition, we will produce a corpus of annotated (true and false) instances that can later be used as training data.   \n",
       "14957                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           We aim to predict a quality class ĉ for each article, such that ĉ is as close as possible to the true latent quality class c of the article.   \n",
       "28349                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             While the classification accuracy is important, it is more important that given a sample is misclassified, the predicted label is close to the true label.   \n",
       "24433                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               First, while encountering a scientific claim, we need to identify the true fact related to the claim from the knowledge base (in most cases the source journal article).   \n",
       "21896                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        To further capture causal and temporal dependencies between sentences in a reasonable story, they employ multi-task learning which combines a discriminative objective to distinguish true and fake stories during fine-tuning.   \n",
       "29319                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The value being true means that the model has estimated Shift actions to all the target nodes (from i = 1 to i = |T |) in the parsing process, then the parser stops the analysis and outputs the subtrees in T, because no further action is possible.   \n",
       "8963                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  This SMT model is of very high quality thanks to the amount of training data (especially true for English-French: with more than 8 Million parallel translation units as released in COPPA corpus 3 ).   \n",
       "637                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The input text and the hypothesis were considered as a problem of binary classification ('true' or 'false').   \n",
       "38585                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   If no ps exist, the conclusion is vacuously true; otherwise, we may choose some q to which every p is related, and the conclusion is certainly true.   \n",
       "1514                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     The imbalanced dataset results in an excessive number of true negatives rather than true positives.   \n",
       "39075                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The ambiguity of source morphology is the true ambiguity rate of the language (according to the morphological analyser), i.e. how many potential interpretation each word has.   \n",
       "9097                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Although it is true that creating a language repository alone cannot revert language endangerment or decay, there are several ways in which documentation data can be integrated into revitalisation projects.   \n",
       "5903                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     For instance, the sentence \"Ana y Juan hablan espafiol y franc6s\" (Ann and John speak Spanish and French), which translates roughly into speak({Ann,John], {Spanish,French]), introduces a distributive plural and must therefore evaluate to true (false) if the following formulas are all true (false): speak(Ann,Spanish) speak(John,Spanish) speak(Ann,French) speak(John,French) On the other hand, the sentence \"A y B son paralelas\" (A and B are parallel), which translates into parallel({A,B]), introduces a collective plural and must evaluate to either true or false as a result of testing the whole set {A,B} for the property of being parallel.   \n",
       "22922                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             We analyze wrongly predicted spans by their true category.   \n",
       "31007                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Levin takes a useful approach in reducing the size of true state space by simply tracking when a particular state variable has a value rather than including the specific value in the state.   \n",
       "22750                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           We conclude that if we do not see alignment improvement on the QC-HQ setting (as is true of ATOMIC-PIQA), then extraction does not indicate the best knowledge gap coverage.   \n",
       "29711                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The partial annotation of coreference data for mention detection means that not labeled spans may be true mentions of entities.   \n",
       "36111                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Second, the reported improvement cover corrections of vocabulary deficiencies, not only true transcription mistakes due to weaknesses of the language model.   \n",
       "30261                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 We straightforwardly use pairs of contexts and their true re-sponses from DOMAINREDDIT as positive training instances.   \n",
       "7575                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Under some circumstances, such an error-correction capability might induce comprehenders to adopt grammatical analyses that are inconsistent with the true input.   \n",
       "32322                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       On CDCP, where the number of true links is 272, the linear baseline with strict inference predicts 796 links with a precision of only 16%, while the strict structured RNN only predicts 52 links, with 33% precision; the example in Figure 5 illustrates this.   \n",
       "25957                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         For example, the fact (Liu Cang, sibling, Liu Yan) is true, but is not included by KG, resulting in the inferred answer being judged as wrong.   \n",
       "13426                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   The text describes some situation or setting, and the query in the simplest case asks whether a particular statement is true of the situation described in the text.   \n",
       "32839                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The ELBO on the marginal likelihood of the finance documents is as follows: where q φ (z|D) is an approximation to the true posterior p θ (z|D).   \n",
       "32346                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The true error rate is almost invariably higher than the apparent error rate.   \n",
       "21295                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         One reason is that STRESS decreases word overlap rate and injects negation words by appending distractor phrases, i.e. \"true is true\" and \"false is not true\".   \n",
       "2701                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 However, such skip normally reflects the true searching intent because novel relevant feedbacks always have more attractions after all.   \n",
       "30556                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Since the task, which involved identifying, on average, 3.33 true positives among 2596 candidates, was more challenging, the recall values are lower than in Figure 1 .   \n",
       "12184                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2014 ) report κ = 0.4), so discarding candidates without a clear majority decision can be seen as discarding those for which the true label is not well defined.   \n",
       "8271                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Human-judged Synonyms: The prediction is judged as true by the expert (but is not present in the glossary). *   \n",
       "38855                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The lower fee paid to external translators is based on the premise that postediting saves them some typing and part of the time they need to consult dictionaries and reference works, which is generally true.   \n",
       "12388                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 de i,j and d e i,j denote the true distribution and predicted distribution of entity categorical labels, respectively.   \n",
       "1157                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     We can then see from Table 3 that b-LID outperforms every other system by a large margin: 7 it is excellent at distinguishing between true entailments, and while it misses some good identity replacements, is not handicapped in this respect relative to the other systems, which are also unable to model them.   \n",
       "22789                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Although the fact stay-in(Snowden, Hong Kong) is true, it is harmful to include \"Snowden will stay in Hong Kong\" in the training for travel-to(person, location).   \n",
       "15115                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  But, this statement is not true in the case of the children with ASD.   \n",
       "7773                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The same is true for another type of relational annotation, discourse analysis, and a future version of the corpus should therefore include a running text section from a source, where this is not a copyright problem.   \n",
       "19849                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Unsupervised Baseline: Text Classification as Natural Language Inference Natural language inference (NLI) is the task of determining if a hypothesis is true (entailment), false (contradiction), or undetermined (neutral) given a premise 8 (Table 3 ).   \n",
       "25255                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   In the logic formalisms, \"negation is the only significant monadic functor,\" whose behavior is described by the Law of Contradiction that asserts that no proposition can be both true and not true.   \n",
       "2357                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Our experimentation also shows that the CRF model is much complementary to the ME model in trigger identification with a high precision of 83.7 units and a low recall of 43.3 units, and the new constraint helps bring back 1.9% of true trigger mentions.   \n",
       "27167                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Compatibility and Backward Dependency Match As mentioned in Section 2, the independency assumption of phrase tokenization is not always true.   \n",
       "21921                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               One limitation of any analysis of social bias on TVTROPES is that the website may not be representative of the true distribution of tropes within media.   \n",
       "18017                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             By varying the relative size of an animal and the number of cells in the matrix (or number of digits) imaged next to it, it was demonstrated that size and number of parts had independent effects on time to verify properties of the image (see Kosslyn, in press; 1974) property appropriate for, the image, the subject was to respond \"true\" as quickly as possible (after consulting an image), otherwise he was to respond \"false.\"   \n",
       "3416                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  They do not receive any formal training and do not have access to true annotations except a few examples if provided by the requester.   \n",
       "18920                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Furthermore, it is unable to cope with noisy dimensions (this is especially true in the case of the text data) and highly non-ellipsoid clusters. (   \n",
       "35735                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Suggested fixes to the representations Of the 74 true positives, the judges felt that 17 of the bad representations should be fixed by splitting the predicate into multiple senses.   \n",
       "17088                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  This logical relationship can either be Entailment (premise is true implies the hypothesis is absolutely true), Contradiction (premise is true implies the hypothesis is absolutely false), and Neutral (one cannot determine if the hypothesis is true or false based on the premise) (Dagan et al.,   \n",
       "3897                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           This also holds true for Rotowire tableto-text generation, where our models surpass previously reported metrics for content selection, planning and ordering, highlighting the strength of stepwise modeling.   \n",
       "22313                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Special thanks go to Prof. Jianmin Yao at Soochow University and Suzhou Scientific Service Center of China for his advices and suggestions that help this paper finally come true.   \n",
       "4530                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             In this way, empirical evaluations can test more accurately the true linguistic capabilities of the models.   \n",
       "19061                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                We also observe that although the top-ranked output of the CRF model is not always correct, the true abbreviation very often appears in the top few outputs of the CRF.   \n",
       "15551                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A constraint is true if when all the propositions in the right hand side of the constraint are true, the left han(l prop(.   \n",
       "2072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Crowdsourced Evaluators Crowdworkers on Mechanical Turk are presented with the 500 test set claims and instructed to use a search bar to decide if the claim is true, false, or in the middle.   \n",
       "12855                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           By definition, precision is the number of true positives divided by the number of all non-null results retrieved by the system, recall is the number of true positive samples divided by the total number of positives, and F1 is the harmonic mean of precision and recall.   \n",
       "31114                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Conversely, the falsity of any of them is sufficient to make (1) true: (1) would be true if nobody got anything, we didn't get, an offer wasn't gotten or the offer wasn't for more than $40.   \n",
       "32749                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   This is especially true if we consider languages other than English, ever since the influ-ential CoNLL shared tasks on dependency parsing in 2006 (Buchholz and Marsi, 2006) and 2007 (Nivre et al.,   \n",
       "21501                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The overall model, shown in Figure 3 , takes a corrupted event sequence x = {e i } as input, and outputs the true event sequence y = {e j }.   \n",
       "29995                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       For our context model, we address this problem using distant supervision: we treat all contexts of an entity that can have type t as contexts of type t even though this assumption will in general be only true for a subset of these contexts.   \n",
       "13051                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Oenerally speaking, the converse of this is also true,and only a Poisson process would produce exponential decay.   \n",
       "36031                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  This view may turn out to be true but it is impossible to discuss it.   \n",
       "28313                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Calculating the upper bound essentially comes down to associating each word in the dataset to the largest possible number N given m: N = i m i (5) To demonstrate that, no matter what the vectors were the compression would work, we show the upper bounds compared to the size of the original dataset of 50-dimensional GloVe embeddings and the true CRT-compressed dataset of those embeddings on Table 4 .   \n",
       "29997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Assumptions that result in errors: The performance of all models suffers from a number of assumptions we made in our training / evaluation setup that are only approximately true.   \n",
       "40162                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Evaluation Evaluation was to be carried out according to the following F-scores:  Strict F-score: a predicted mention is considered a true positive if: 1.   \n",
       "30231                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              We introduce a unary predicate called holds over string constants to capture the probability of a string constant being true given the setup is true (∀x ∈ setup, holds(x) = true) and the KB rules hold.   \n",
       "37921                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The absence of true labels for both the dev and the test set prevents us from conducting an error analysis.   \n",
       "2057                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            For each relation type, P is the ratio of the true relation instances in all the relation instances being identified, R is the ratio of the true relation instances being identified in all the true relation instances in the corpus, and F1 is the harmonic mean of P and R. The overall performance P/R/F1 is then calculated using the micro-average measure over all major class types.   \n",
       "25384                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   During training the class that corresponds to the column with the greatest sum is compared to the true class and if it is correct no change is made.   \n",
       "35607                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The maximum likelihood estimate for τ is x n , however for small values of x this estimate has a high variance and can significantly overestimate the true value.   \n",
       "19809                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               For example, 62% of the true responses are produced only by 1 or 2 of the 18 SF systems.   \n",
       "37650                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The expected value is determined using the unconditional distribution, on the assumption that if the null hypothesis is true then this distribution will correlate with the conditional distribution.   \n",
       "24246                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     We tested EFEX on the EFCAMDAT test set and we obtained significant results when comparing the true labels with the predicted ones in terms of PCC (see Table 8 ).   \n",
       "35458                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      This holds true for all estimation methods tried.   \n",
       "2877                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        If we knew which derivation in each forest was the \"true\" derivation, then we could straightforwardly collect rule counts off those derivations.   \n",
       "25320                                                                                                                                           moll 'wet', morat 'purple', mutu 'mutual', notori 'notorious', ocult 'hidden', opac 'opaque', paradoxal 'paradoxical', peculiar 'peculiar', perillós 'dangerous', pertinent 'pertinent', pessimista 'pessimistic', plàcid 'placid', precoç 'precocious', predilecte 'favorite', primari 'primary', primitiu 'primitive', propens 'prone', pròsper 'prosperous', prudent 'prudent', punxegut 'sharp-pointed', quadrat 'square', reaccionari 'reactionary', recent 'recent', recíproc 'reciprocal', remarcable 'remarkable', responsable 'responsible', rígid 'rigid', roent 'burning', sant 'saint', semicircular 'semicircular', seriós 'serious', significatiu 'significant', silenciós 'silent', similar 'similar', simplista 'simplistic', subaltern 'subordinate', sublim 'sublime', subsidiari 'subsidiary', subterrani 'underground', superflu 'superfluous', tenaç 'tenacious', terrible 'terrible', típic 'typical', titular 'titular, official', tort 'bent', total 'total', tou 'soft', triangular 'triangular', vague 'vague', ver 'true', viciós 'vicious', vigorós 'vigorous', viril 'virile', vulgar 'vulgar'.   \n",
       "2212                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Even with semi-supervised approaches, which use a large unlabeled corpus, manual construction of a small set of seeds known as true instances of the target entity or relation is susceptible to arbitrary human decisions.   \n",
       "2163                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Our variational approximation takes the following form: Q(T, L, Z r , A p , τ , π) = δ r (Z r , L) n k=1 q k (T k ) np i=1 r i (A p i ) δ s (τ )δ d (π) We use a mean field approach to update each of the RHS factors in turn to minimize the KL-divergence between the current variational posterior and the true model posterior.   \n",
       "35920                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  We represent an infon as a term of the form Sit : P, which means that p is true in the situation Sit.   \n",
       "19890                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Trigger type consistency is motivated by one observation: documents in the ACE 2005 Chinese corpus are mostly news articles, each of which describes one theme, and most of the true triggers are compatible with this document theme.   \n",
       "6022                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           This is because our focus is on evaluating pairwise approach versus the graph partitioning approach and also comparing them to some state-of-the-art approaches which also use true mentions.   \n",
       "15706                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Condition 2 is true as the Kullback-Leibler Divergence is never smaller than 0 and the same is true for the Euclidean norm.   \n",
       "20600                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         However, formulas with high scores in PRA are not always true.   \n",
       "7122                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             These shortcomings are mainly are a result of commonly used automatic evaluation methods (like BLEU) using only surface-level similarity; they do not strictly measure , Semantic Equivalence (SE), which is the true goal.   \n",
       "14950                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Statistical-based collocation extraction approaches suffer from (1) low precision rate because high co-occurrence bi-grams may be syntactically unrelated and are thus not true collocations; (2) low recall rate because some true collocations with low occurrences cannot be identified successfully by statistical-based models.   \n",
       "25726                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Most importantly, it is not clear what should be the 'true' senses of a word.   \n",
       "32709                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Denoising Techniques Noisy training examples can be thought of as the result of perturbing the true, underlying labels by some source of noise.   \n",
       "36387                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Precision is the percentage of boundaries identified by an algorithm that are indeed true boundaries; recall is the percentage of true boundaries that are identified by the algorithm.   \n",
       "12304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  We observe that in most regions of the brain, the predicted and true activity agree on the activity sign, thereby providing evidence that deep learning representations can capture useful information about language processing consistent with the brain recording.   \n",
       "17952                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                As stated, the EBC rule makes a true prediction about u-ambiguous defnps which occur in sentences following the focus: they are c¢)-referential with the focus, and hence disambiguated as non-generic.   \n",
       "6297                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The truth conditions state that a IRS K is true in a model M if there is a proper imbedding from K Into M. Proper embedding is defined as a f~mction f from the set of discourse referents of K in to M s.t. (   \n",
       "33023                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Hierarchical-F1 is a commonly used measure for hierarchical classification tasks that compares the true path from the true parent to the root with the predicted path (Kiritchenko et al.,   \n",
       "16053                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This will ensure that the sentiment state of the generated output by the VA is consistent with the true output.   \n",
       "4963                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Results from each category were compiled in 2 x 2 contingency tables like Table 3 , where tp stands for \"true positive\" and fn for \"false negative\".   \n",
       "1901                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Each node includes three different components: (1) A precondition that must be true before the subtask is executed; (2) A description of the node that includes its label and identifier; and (3) Links to nodes that will be executed at the subsequent turn.   \n",
       "2016                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Cameras had more relevant than not relevant tweets, while the opposite was true for mobile devices and game consoles.   \n",
       "27012                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          a default rule: P is assumed to be true if Q is true or assumed to be true and there is no definite evidence to the contrary.   \n",
       "34447                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       $uch conclusions may be true, and this is why the values in Tab.   \n",
       "6892                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              PRMSE with reference to true scores The simulations in the previous sections demonstrate that the values of metrics usually used to evaluate automated scoring systems are directly dependent on the quality of human ratings used to evaluate the system.   \n",
       "9935                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Jacovi and Goldberg (2020) define faithfulness as \"how accurately [explanations] reflects the true reasoning process of the model.\"   \n",
       "14899                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   When using only 10% data, the error is larger and ENIGMA has lower correlation with the true reward.   \n",
       "18502                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          As we can see, for news stories text order by itself is a poor predictor of chronological order (only 3.71% correlation with the true order).   \n",
       "8374                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            We consider two assumptions in this work as the same has been done in the baseline, -(a) every sarcastic text has at least one sarcasm target as this holds true by the definition of sarcasm, and, (b) the notion of sarcasm target is applicable for sarcastic texts only.   \n",
       "10023                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The L2-Error is the L2-Norm of the difference between the predicted user distribution and the true user goal.   \n",
       "37110                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Therefore, a good measure of relational similarity, sim r , should obey the following equation: sim r (A : B, C : D) = sim r (B : A, D : C) ( 8 ) In steps 5 and 6 of the LRA algorithm (Section 5.5), we ensure that the matrix X is symmetrical, so that equation ( 8 ) is necessarily true for LRA.   \n",
       "4927                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Evaluation by hand identified 232 true collocations in the set A test set.   \n",
       "3090                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                When the condition is true, then the result would apply.   \n",
       "12729                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          We regarded the anchor texts as mentions and the entities that anchor texts referred to were considered as the true entities.   \n",
       "30081                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Possession Duration How long do possession relations hold true for?   \n",
       "30387                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    If we suppose that the number of languages is finite, let us denote it n, counting the number of \"true analogies\" in a set of sentences in a given language, say L 1 , is tantamount to counting the cases described by the following formula (ii).   \n",
       "22469                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          This method relies on the assumption that the two embedding spaces are structurally similar, which does not necessarily hold true in general.   \n",
       "27148                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Given the cover, the overall plural predication holds just in case the basic property denoted by the predicate is true (collectively)of each of the sets (or CELLS) in the cover.   \n",
       "1790                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Most of these candidates are in fact English phrasal verbs that happened to be missing from Wiktionary; some are present in Wiktionary but were removed from the reference sets during filtering, and the remainder are in fact not phrasal verbs (true precision errors).   \n",
       "27679                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               This is true both in resource acquisition, such as automated bilingual lexicon generation (Kolak et al.,   \n",
       "28042                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           For example, definition clause (7) means that, for a pair of the variables X and Y, p(f(X, Y)) is true if the instances satisfy the constraint {r(X), s(Y)}.   \n",
       "33610                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       A definite clause has either the form P:-QI,\"',Qn\" to be read as \"P is true if Q 1 ..... Qn are true\", or the form P. to be read as \"P is true\".   \n",
       "39240                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           This includes complete utterances or phrases (e.g. to je res \"that's true\", no no \"well well\"), sentence elements, such as predicates (boš videl \"you-will see\"), predicate arguments (glava družine \"head of the family\") and adjuncts (pol ure \"half an hour\"), as well as modifiers (bolj ali manj \"more or less\"), multi-word conjunctions (zaradi tega ker \"given the fact that\"), and connectives (tako da \"so that\").   \n",
       "20556                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Our method employs embedding techniques, and also integrates context-aware true label dis- Although Universal Schemas does not adopted the source consistency assumption, but it's conducted in document-level, and is context-agnostic in our sentence-level setting.   \n",
       "32559                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                W t is another set of parameters in addition to W. Objective Function We use the max-margin loss function to learn the parameters of the model: L(θ) = m ∑ i=1 k ∑ j̸ =i max ( 0, γ + d(y i , ŷg i ) − d(y j , ŷg i ) ) , (5) Where y i is the true label; ŷg i is the prediction, which is either ŷlinear i or ŷnn i .   \n",
       "917                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Thus, the distinction between stem and variant can not be done clearly by the algorithm (the same holds true for independant and independent).   \n",
       "3347                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         More formally: α(N i,j ) = P (w 0,i , N i,j , w j,n ) β(N i,j ) = P (w i,j |N ) FOM(N i,j ) = α(N i,j ) β(N i,j ) With bottom-up parsing, the true inside probability is accumulated and β(N i,j ) does not need to be estimated, improving the FOMs ability to represent the true inside/outside distribution.   \n",
       "27371                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The sentence is judged true in scenario Σ 30a -a scenario that makes the transparent NP, opaque VP reading true--but false in scenario Σ 30b -a scenario where the opaque NP, transparent VP reading is true.   \n",
       "3639                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Figure 3 illustrates a simulation demonstrating that the approximation is a close match for small a and n but underestimates the true value for high a To resample a sequence of trigrams we start by removing their counts from the current restaurant configuration (resulting in z − ).   \n",
       "13796                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   The extensional models of logic are recast as \"semantic\" functors from the lexical category to C. We associate to any semantic functor an RDF interpretation and show that a statement is true in the semantic functor if and only if the corresponding RDF graph is true in the RDF interpretation.   \n",
       "18975                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          However, we should be cautious of using backchannels too liberally if they are not a result of true understanding, since they could break down trust between robot and human.   \n",
       "28571                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              For example, assigned relation variable (Z(i, r)) is true if z i = r and false otherwise.   \n",
       "37606                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            7 The length filter eliminated 48.6% of the 9,000,000 possible pairs in the cross-product, keeping 95.7% of the true pairs.   \n",
       "21598                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       We believe the problem comes from the nature of variational family itself and hence we propose our Copula-VAE which makes use of the dependency modeling ability of copula model to guide the variational posterior to match the true posterior.   \n",
       "13202                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            False responses are hypothesized to be less fluent than true responses because fabricating a story takes more mental effort than recalling an actual event.   \n",
       "31310                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         If true, this merely attests to the relative independence of task-based and human-annotated knowledge sources.   \n",
       "32506                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            a(C i,j ) matches the true outside score if the onebest category assignments on the outside words (arg max c k log P tag (c k |x)) can comprise a wellformed tree with C i,j , which is generally not true.   \n",
       "28918                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The message is clear: the ordinal model is always more likely to detect a true effect of any size than the corresponding linear model is (all of the solid lines of a given color are always above their dashed counterpart).   \n",
       "1084                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               However, this assumes that each error indicates a unique level, which is not always true.   \n",
       "9357                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Temporally, the original blank positions are labeled true, and the shifted ones are labeled as false.   \n",
       "17749                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           To allow a \"partial credit\" for these cases, we introduce \"weighted\" version of these measures, where a predicted label is given 0.5 credit if the true label is its direct child or parent, and 0.25 credit if the true label is a sibling.   \n",
       "36741                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Next, the tranformations from L1 will be applied if X is true, since S' is the initial-state label for L1.   \n",
       "13634                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The constants true and false play their usual role, c-struct and f-struct give us 'labels' for our two domains, while the elements of Cat and Atom enable us to talk about syntactic categories and atomic f-structure information respectively.   \n",
       "33517                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Second, normalized κ x approximates the true correlation between two experiments' item-level mean scores.   \n",
       "16522                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Same is true for majority of EQUATE data.   \n",
       "38148                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               However, this generalization holds true only in Mandarin and perhaps in some other varieties of the Chinese language but certainly not in all varieties of the language.   \n",
       "18803                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 We call this threshold the confidence threshold and denote it by ρ, whilst the prefixed true score to identify a good translation is called acceptance threshold and is denoted by τ .   \n",
       "20831                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Markov Logic Network (MLN) (Pearl, 1988) can model such uncertainty by assigning each causal rule a causal strength, which measures the probability that this rule holds true.   \n",
       "15174                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              In our model, we removed the dependency on both the true cast list and the script, which makes it easier to apply our model to other movies and TV shows.   \n",
       "3003   Algorithm 4.1: CALCULATE-T(U, Tj) procedure FAST-UPDATE(n k ) diff ← 0, m(n k ) ← *1, U ← φ for n2 ← 1 to |Tj| do change(n2) ← true n1 ← n k while n1 ̸ = nil do 8 > > > > > > > > > > > > > > > > < > > > > > > > > > > > > > > > > : for n2 ← 1 to |Tj| do // actually iterate only on n2 with l(pa( n1 ) ) = l(n2) nchange(n2) ← false for n2 ← 1 to |Tj| do // actually iterate only on n2 with l(n1) = l(n2) if change(n2) then pre ← C r (n1, n2), U ← U ∪ (n1, n2) update C(n1, n2) and C r (n1, n2) using (A) of Algorithm 3.1 diff + = (C r (n1, n2) − pre) if pa(n2) ̸ = nil then nchange(pa(n2)) ← true n1 ← pa(n1), change ← nchange for (n1, n2) ∈ U do //restore DP cells C(n1, n2) ← C ′ (n1, n2), C r (n1, n2) ← C r ′ (n1, n2) m(n k ) ← no-mark return (diff ) main m(nv) ← * 0, k ← WMOLT-KERNEL(U, Tj) C ′ (n1, n2) ← C(n1, n2), C r ′ (n1, n2) ← C r (n1, n2) for n k ← 1 to |U | do (n k ̸ = nv) diff ← FAST-UPDATE(n k ), t(n k ) ← k + diff Given a sentence represented by tree U and the node for the target predicate n v , the argument recognition requires the calculation of: However, if we exploit the fact that U @{n v = *0, n k = *1} is different from U @{n v = *0} at one node, we can greatly speed up the above calculation.   \n",
       "12036                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Fact checking requires the apt evidence against which sentences can be predicted to be true or false.   \n",
       "6046                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       This is not true in the cooperation of bigrams and trigrams with acquired constraints (BTC), in this case the synergy is not enough to get a better joint result.   \n",
       "19548                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The gradient of L G can be formulated as below: θ D L G = s j ∈B i E s j ∼p G (s j ) r θ G log p G (s j ) = 1 |T | s j ∈T r θ G log p G (s j ) (7) Cleaning Noisy Dataset with Generator After our adversarial learning process, we obtain one generator for one relation type; These generators possess the capability of generating true positive samples for the corresponding relation type.   \n",
       "32687                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  They are used to help to judge whether the answer found by the vanilla model is true.   \n",
       "2071                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             For example, questions such as What evidence is there that [claim] is true?   \n",
       "7119                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Finally, we use a simple 3-gram casing model trained on the true-case workshop distributed language model data, and apply the SRILM disambig tool to restore true-case for our final submissions.   \n",
       "5110                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         As we have manually corrected the label mistakes in the testing set, we are able to report the number of true mistakes among the potential mistakes discovered in the test set.   \n",
       "19475                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Conversely, not Permit P to be true was labeled as Require P to be false.   \n",
       "34649                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 If the author of the domain model has provided this reasonable and perfectly true fact about motherhood, (6) can proceed to yield: (PAT I ENT-WI TH-D I ABET IC-MOTHER X) as in the preceding example.   \n",
       "1236                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       However, if our hypothesis holds true, visible differences in the baseline improvements measured with \"TER/BLEU (pe)\" and \"TER/BLEU (ref)\" should indicate system's ability to model the post-editing style of the training data.   \n",
       "22519                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Rephrase) Evaluation Metrics For these three sub-tasks, standard evaluation metrics including accuracy and F1 score are used to evaluate the participating system, calculated as follows: accuracy = T P + T N T P + F P + T N + F N (1) recall = T P T P + F N (3) F1 = 2 • precision • recall precision + recall (4) where T P, F P, T N, F N represent true positive, false positive, true negative, and false negative, respectively.   \n",
       "34763                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Within $waggart's world view, adulterers rn~t be sinners simply because the bible says so, and whatever the bible says is true.   \n",
       "14741                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            We refer to dimensions by their first descriptor (Section 3); 1 (-1) indicates that the first (second) descriptor is true, and 0 that the value is unknown.   \n",
       "22029                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The country's history has been turbulent and true is true.   \n",
       "30644                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              In that case, it is no longer true that (10) 3m is the only generated sentence, which is a contradiction.   \n",
       "33543                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       We collected only nouns under the assumption that most, if not all, true category members would be nouns3 1 Of course, this may depend on the target categories.   \n",
       "12435                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             PCNN+INTRA+INTER (Ye and Ling, 2019) propose to emphasize true labeled sentences and bags.   \n",
       "15912                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             This does not assume that analytic treatment of linguistic context can resolve any 'true' or 'correct' meaning of a contested concept, but simply that usage reflects meaning as held by the community or ideology that produces the text.   \n",
       "26554                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           2  From the definition of G it directly follows that w ∈ L(G) implies the existence of a truth assignment that satisfies C. A satisfying truth assignment can be read directly off of any derivation tree for w. If T i (respectively, F i ) is a child of S in the derivation tree, then v k is true (respectively, false).   \n",
       "23902                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Beam search is an approximation that is tractable, but it also frequently fails to find the true mode of the distribution (Stahlberg and Byrne, 2019) .   \n",
       "19993                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            They contain 26 and 23 multiple-choice questions each of which has four sentential statements, thus 104 and 92 predicates can be used for true/false validation as development and test data, respectively.   \n",
       "15065                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -the algorithm's task is to return a set of descriptors that encompasses the majority of points with rain=true values.   \n",
       "13757                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Reasonable people can disagree about how best to categorize a situation, as no metaphor is ever objectively right or true, just potentially apt in a particular context.   \n",
       "22462                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    First compute the forward derivative: ∇F(X) = ∂F (X) ∂e(X) = ∂F j (X) ∂e(x i ) i∈1..N,j∈1..T (1) and the saliency of word x i is defined as: S(x i ) = ∂F true (X) ∂e(x i ) (2) where, F j (•) is the output w.r.t.   \n",
       "9002                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The two criteria used would select the most difficult cases for the algorithm, that is, cases whose true alignment is expected to be most informative.   \n",
       "20173                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     While this may typically be true, extending the system to be able to prefer the opposite with certain types of questions would potentially help with these errors.   \n",
       "39439                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This allows the derivation to keep track of both the true head of the phrase and the place in the Cinque hierarchy of the modifier, preventing inverted modifier orders in the absence of Move.   \n",
       "30227                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    We are interested in computing Pr[result() = true].   \n",
       "6194                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Moreover, if one of the premises is tagged by contributors as true but irrelevant, then the inference is blocked.   \n",
       "27807                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         If either case is true, then CFLex reports that the anaphor and candidate might be coreferent.   \n",
       "2559                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            We measure the Top-1 accuracy (i.e., whether the true comparable is the closest in the test set), and the Mean Reciprocal Rank of the true comparable, and report the average performance over the two retrieval directions.   \n",
       "22453                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Following previous work in this direction such as Jacovi and Goldberg (2020), we advocate to carefully consider the explanations obtained from interpretation methods as they may not always reflect the true reasoning process behind model predictions.   \n",
       "24308                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     In particular, this is true for basic problems such as POS-tagging, sentence parsing and entity recognition, as well as for more complex problems such as question answering (QA).   \n",
       "3978                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                In our case, the true negative number is 100 times larger than the true positive number.   \n",
       "29225                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       CDP [does] not suppose cooperation with party [of] mister Sladek and it isn't true, that chairman [of] Christian democrats mister Benda enforced in telephonic discussion with Petr Pithart ing.   \n",
       "2096                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               w m }, annotated with N highlights, we define the weight β n g ∈ [0, 1] for an n-gram g as: β n g = m−(n−1) i=1 i+n−1 j=i NumH(w j ) N n w i:i+n−1 ==g m−(n−1) i=1 [1] w i:i+n−1 ==g where, [x] y is an indicator function which returns x if y is true and 0, otherwise.   \n",
       "11362                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            5 When using a static oracle for training in Algorithm 2, the function o(t; c, T ) returns true if o s (T ) = t 1 , . . . ,   \n",
       "21662                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Regression model evaluation We select 10K English-Chinese sentence pairs with both hand alignment and automatic HMM alignment, and extract 106K phrase pairs with true phrase translation quality scores as computed according to formula 8.   \n",
       "3637                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    We filter out false negatives that were observed true (entity, type) pairs in our complete data set.   \n",
       "39946                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          19 This simple technique has reasonable accuracy (0.752: see Table 5 ) but this is due largely to the high number of true negatives produced.   \n",
       "26340                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Intuitively, the true fraction of decaying instances can be captured by the difference of these left tails, and we formally quantify this below.   \n",
       "27408                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Traditional approach fails to capture the true posterior distribution of z due to its oversimplified assumption when using the mean-field approaches.   \n",
       "16498                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Perceived weakness of must is accounted for on this analysis because must φ -unlike bare φ -allows for the possibility that ¬φ is true in worlds compatible with the known propositions (but incompatible with the assumed ones).   \n",
       "31189                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       12* Factive verb in context {true, false} One/two word(s) around w is a factive (Hooper, 1975) .   \n",
       "36029                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Though inversion transduction grammars remain inadequate as full-fledged translation models, bilingual parsing with simple inversion transduction grammars turns out to be very useful for parallel corpus analysis when the true grammar is not fully known.   \n",
       "9603                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Action schemas (acs1 and acs2) use the reassignment operator R to make loaded true after performing the Load action and to make both loaded and alive false after performing the F ire action, but only if loaded was true when the action was initiated.   \n",
       "14147                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         For instance, the first utterance, u 1 : \"turn right a little\", shows the true user utterance.   \n",
       "22908                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This is especially true for the elaboration and list relations.   \n",
       "31478                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                One possibility is that this is caused by our having defined the Deictic feature as true whenever there is an actual deictic expression (variable D in Table 1 ; e.g. those squares) or an identity expression (variable ID; e.g. the same one we saw).   \n",
       "5960                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     The choice of language clues (i.e., features) that can be used to classify news as true or false vary considerably.   \n",
       "30685                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Phylogenetic methods are designed to recover the \"true\" evolutionary tree as often as possible.   \n",
       "24146                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Our ) UNARY A B u w l B u pg(A → B | A)p lef t (w l | A, eA) B u B B wr p right (wr | A, eA) BINARY A A 1 w l A 1 p lef t (w l | A, eA) A 1 B C 1 B C 1 pg(A → B C | A)pinv(I=false | B, C) A 1 B C 1 C 1 B pg(A → B C | A)pinv(I=true | B, C) C 1 C 2 fm C 2 p mid (fm | A, eA) C 2 C C fr p right (fr | A, eA) DT[3,3] NN[3,4] VP[0,3] VB[2,2] VP[2,3] VBN[2,3] NN[3,3] VP[2,3] MD[1,2] 明天 将 公布 名!   \n",
       "3190                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    By construction, correct edges (i, j), that appear both in the true parse tree y and the predicted parse tree ŷ, are not affecting the update, as the terms in the two sums of Eq. (   \n",
       "39616                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            For every R i 2 S, R i (x 1 , ..., x k ) is an atomic formula in L S , which is interpreted as true in a model M when x 1 , ..., x k are evaluated to d 1 , ..., d k 2 D and (d 1 , ..., d k ) 2 R i in M .   \n",
       "10657                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      This is true even for a language as seemingly dissimilar to English as Japanese .   \n",
       "34303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Since, by the definition of o\" , any predicate indexed by the empty set will be true of the typical element of the empty set, \"arrlve#(~(# ))\" will be true, and the sentence will be satisfied.   \n",
       "7490                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 With the multitoken approach none of the tokens would have the gazetteer feature equal to true, while with the single token approach both salami, pizza, mozzarella and sandwiches would have the presence set to true.   \n",
       "8617                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      If a specific linguistic cue was more often used during deception than in a true story, d becomes a negative sign.   \n",
       "26893                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The analogy is made between computerised information and books; if it is not an infringement of copyright to pick up someone else's book and read it, the same should be true of unauthorised browsing through computer files.   \n",
       "6831                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           A major reason for this problem was that the true attributes did not exist in our dictionary.   \n",
       "29646                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          In other words, the negative samples chosen by the backbone model X for the AF algorithm will be difficult to distinguish from the human-annotated true samples using the same model X. These negative samples, however, could be relatively easier to identify using another model Y. The seq2seq models T5 and Unified QA perform significantly better than RoBERTa and ELECTRA as can be seen in Table 8 .   \n",
       "12853                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              2015) , previous dialogue states are half predicted dialogue states and half true labels.   \n",
       "16805                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               L DGA gives thus a true cut across the Chomsky hierarchy, which we judge to be possibly relevant for formal linguistics.   \n",
       "40086                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Similarly, the feature word hp1 of has the value 1 (true) if the given window contains the head word followed by \"of\"; otherwise, it has the value 0 (false).   \n",
       "24877                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           For example, if we have in the gazetteer the compound name yAsr ErfAt 'Yasser Arafat' and the input text is yAsr BarakAt then PM-GAZ for the token yAsr will be set to true.   \n",
       "14077                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Of the 52 occurrences in the test corpus BIO-ART, the system produces 3 true positives, 8 false positives and 49 false negatives.   \n",
       "11540                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Variable x i is true, and therefore phrase i will be included, if any of its dependents x j ∈ D i are true.   \n",
       "6535                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Each node in the tree is marked with an elementary formula which can be true or false.   \n",
       "30131                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             This is especially true for recommender systems, where adversarial attacks can create fake users such that a target item is removed from a target user's top-k list (Christakopoulou and Banerjee, 2019) .   \n",
       "40076                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          x n , y n ), the (empirical) training loss for a parameter θ is defined as: 1 n n i=1 ( x i , θ ; y i ) and the goal in training (empirical risk minimization) is to minimize this loss over a parameter space Θ. Let θ be a true minimizer of 1 n n i=1 ( x i , θ ; y i ), i.e., θ ∈ argmin θ∈Θ 1 n n i=1 ( x i , θ ; y i ).   \n",
       "5271                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The so-called true tree principle (e.g. Schubert 1987:87-90) makes it impossible for different parts of a constituent C1 to be split apart by another constituent C2 which is not a part of C1.   \n",
       "14778                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Third, they perform multi-class classification (i.e., they assume only one intent to be true for a user query) and have no notion of state (e.g., current webpage).   \n",
       "19165                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Let us assume that we have a rule ¢, R2 = ¢ ^ X ~ \"~¢. When ¢ and X are both true ¢ and ~g, are both true.   \n",
       "2011                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Instances are known tuples of entities that make a relation or category true, such as film(Titanic) or directed by(Titanic, James Cameron).   \n",
       "25237                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  This type of model constraint allows the model to find solutions which correspond to true syntactic parts of speech (which follow such a sparse, Zipfian distribution), unlike the uniformly-sized clusters found by standard maximum likelihood estimation using EM.   \n",
       "15881                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Usage Implications The consequences of declaring a claim to be true or false can be serious.   \n",
       "37927                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 In reality, this is true only if we are very sure about the right sense used in a particular sentence.   \n",
       "26123                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Writer Perspective The writer perspective tells the reader what the writer wants him to believe (to be true) and explicates what this implies for the status of the targets involved, i.e. whether they are benefactors etc.   \n",
       "8522                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Length Mismatch: For this adversarial set, we append the tautology \"and true is true\" five times to the end of the premise sentence for every example in the MultiNLI development set.   \n",
       "25099                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            This is particularly true with informal forms of 'everyday' language, which proliferate in most online spaces (Eisenstein, O'Connor, Smith, & Xing, 2014) .   \n",
       "28215                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               In our implementation, the function returns true if M −1 m=0 max h∈ Ω:|h|=l−m α(h,X)−max h ∈ Ω α(h , X) < D end =M, (18) where D end and M are predetermined thresholds.   \n",
       "37208                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Second, the system is to learn the language well enough to determine whether or not a new sentence is true of the accompanying picture.   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The three metrics are defined as follows: P @k = 1 k k l∈r k (ŷ) y l (3) R@k = 1 n k l∈r k (ŷ) y l (4) F 1@k = 2 • P @k • R@k P @k + R@k (5) where k is the number of labels to be used for comparison, n is the number of true labels of the respective document, y ∈ {0, 1} L is the vector of the true labels, ŷ ∈ R L is the vector of predicted labels and r k (ŷ) is a function that selects the index of the kth largest value in the prediction labels.   \n",
       "32837                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                More specifically, we assume a latent variable z for generating the representation of finance document, whose true posterior distribution p(z|D) is usually too complicated to have an analytical form.   \n",
       "22546                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   For the book seller's example, we assume that one book can have only one true author list; so if we knew one list was true, then any different list of the same book would be false.   \n",
       "24176                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     It is valuable to note the algorithm also selects word pairs which can technically be considered true cognates (long/luengo -meaning long), but are not used as such in current speech: largo is more frequently used than luengo.   \n",
       "31971                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   8 The same is true for a sentence with many clauses.   \n",
       "7901                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           By the same token, \"the interpretation of a question is the minimal explanation of why the question would be true\" based on a set of lexical knowledge bases.   \n",
       "11587                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             In addition, an advantage of the template-based framework is that it can generate T/F questions while determining whether their answers are true or false.   \n",
       "27852                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Because answer typing is only intended to be a component of a full QA system, we rely on other components to help establish the true correctness of a candidate answer.   \n",
       "3774                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2019) uses an unrealistic candidate generation setting where the true positive candidate is within the candidate set and/or entities are limited to those in the dataset rather than those in the knowledge-base.   \n",
       "12090                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Results on the Test Set Figure 2 depicts the average number of CS (i.e., true positives) retrieved per the top K = 10, 20, 50 predictions.   \n",
       "32618                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Active(N) is true iff a node or an element of a node gets an A-Marker.   \n",
       "33305                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The more likely r is to be true, the more likely it is to be generated.   \n",
       "20978                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 This means that for any given recognized entity, it is only counted as a true positive if both the span and the label match exactly with the gold standard annotation.   \n",
       "31639                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Morphological analyzers provide multiple analyses of a word, only one of which is true in context.   \n",
       "31488                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              6  Annotators were provided detailed guidelines, which included an operational definition of MWEs (as presented in 3.1) and several examples showing true and false MWEs.   \n",
       "31627                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                First, what one writes in a comment is more important than simply how much one writes; this is true across both subjective and objective outcomes, though length had virtually no predictive ability for improving forecaster accuracy.   \n",
       "23228                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  2003 ) created a labeled corpus of elicited narratives marked as lie or true, then applied machine learning techniques (logistic regression) to rank the contribution of these linguistic categories.   \n",
       "40225                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     If an instance is classified as true by more than one classifier, we consider only the classification with the highest confidence.   \n",
       "10867                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    If the number of slots is huge, each individual inflection is rare, and it is hard for any unsupervised paradigm completion system to distinguish true inflections (e.g., rise → rises) from false candidates (e.g., rise → arise).   \n",
       "29334                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            When ~ is close to 1, there will be few ~rds in common between two meanings, on the average~ and hence the distance between them will be close to I. When c~ is close to zero, on the other hand, the reverse is true, and distances will tend toward zero.   \n",
       "22500                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2018) , typically represent the head entity, relation, and tail entity in each triplet in the knowledge graph as vectors and aim to rank true triplets higher than corresponding corrupted triplets.   \n",
       "21862                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             the true distance or norm.   \n",
       "22826                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   i go with my parents are more relevant and coherent than the response generated by baselines, and it also similar with the true response 1 (oh, that sounds great!),   \n",
       "38716                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       See Table 1 for a summary of the criterion for each type of fragment to be true.   \n",
       "37714                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               And this is true not only for individual wordsenses, but also for larger units such as topics: the product of LDA and similar topic characterization engines is similar.   \n",
       "12747                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  2011) based on mutual information, even with the expectation these may only somewhat correlate with true human judgments (Lau et al.,   \n",
       "21129                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 To create a negative sentence given a gold response, we pick a random phrase in the true response and replace it with a random phrase in another random true response.   \n",
       "39756                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Note that by simply checking if rheme is contained in the alternatives set is not sufficient; this would return true or false as an answer to a question that expects a person.   \n",
       "26045                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               In his opinion the principles of natural science, such as those of causality and the law of conservation of energy, are unconditionally true because the mind thinks in Newtonian terms.   \n",
       "5050                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        It makes a true-false determination for each of the inferred aspect terms based on the corresponding contextual.   \n",
       "2652                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             When the relation classifier is trained using the true entity labels, the performance is much worse than using the predicted entity labels.   \n",
       "9478                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              2012) , we evaluate the imputed sentence completions by examining their distinguishability from the true sentence endings.   \n",
       "11576                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  We select the maximum likelihood frame as the system's hypothesized meaning for the test utterance, and examine both how often the maximum likelihood estimate exactly matches the true frame (frame accuracy), and how many of the role fillers within the estimated frame match the role fillers of the true frame (role accuracy).   \n",
       "8784                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         In general the loss l is chosen as a surrogate of the evaluation metric whose purpose is to measure the similarity between the predictions and the true labels.   \n",
       "38659                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            not true').   \n",
       "23301                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          However, each such sourcetarget word translation is assigned a probability score indicating how likely it can be treated as true translation.   \n",
       "30042                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          But doing so requires knowledge of the true author of an episode, something which is not generally available.   \n",
       "20789                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             LDC conducts limited quality control on the translations, using methods that vary based on the translation type, but which are primarily automated rather than manual and which serve primarily to exclude egregiously bad data rather than improve the quality to a true \"gold standard\".   \n",
       "28209                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  In detail, when contrasting the confusion matrices of the best configurations accomplished by ME-combined (80.72%), ME-KB (80.33%) and ME-N-KB (78.99%), one can find that MEcombined correctly identified 88% of the answers (true positives), while ME-KB 89.37% and ME-N-KB 93.38% (see Table 3 ).   \n",
       "186                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 This is particularly true for headlines, which are typically very short.   \n",
       "17823                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I t i s true t h a t there are the traditional terms \" semel factive\" and \"iterative\" referring, respectively, to one and more than one instantiation of an event.   \n",
       "13164                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Formally, if we denote the correct entity of each mention m as ê, the gold candidate recall r is defined as: r = N i=1 δ(ê i ∈ e i ) N where δ(•) is the indicator function, which is 1 if true else 0, and N is the total number of mentions among all documents.   \n",
       "33890                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   For instance, if q i was true only once in the training data, then, depending on the value for y that time, we would assign a probability of 1 or 0.   \n",
       "23276                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             For w i , we can expect that this will be true for more than one category.   \n",
       "9900                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The famous source-coding theorem of Shannon (1948) gives us a theoretical limit on coding cost: H(M ) ≤ cost(C ) < H(M ) + 1 (5) where we define C to be the most efficient code, and where H(M ) is the entropy of distribution p: H(M ) = m∈M p(m) log |Σ| 1 p(m) (6) According to the source-coding theorem, if we know the true distribution p over lexical meanings, then we know how to optimally code them.   \n",
       "35985                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         This is true whether one uses EM or not--a method that yields the \"wrong\" estimates on complete data does not improve when EM is used to extend the method to incomplete data.   \n",
       "12804                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          In fact, Stahlberg and Byrne (2019) show that oftentimes the true mode is the empty sequence.   \n",
       "27080                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Cosine similarity was computed as follows, cosine(G, P ) = n i=1 G i * P i n i=1 G 2 i * n i=1 P 2 i where, G represents the vector of true sentiment polarity values and P represents the vector of predicted sentiment polarity values by the system.   \n",
       "17139                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Otherwise we add an edge from m i to m j for every positive relation R + such that R + (m i , m j ) is true.   \n",
       "33586                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 If the hypothesis is true, we can proofread among the auto-tagged results only those words with low confidence values.   \n",
       "19376                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Our SS system finds fewer than the true number of boundaries (14.52 on average), while the combined system SS+C finds almost precisely the correct number (19.98 on average).   \n",
       "30635                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        3CosAvg tests the first goal, the second is always true in analogy completion tasks, and LRCos tests the third.   \n",
       "18347                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   This is particularly true for the control trends of H(S|C), whose slope, too, is determined by H(S).   \n",
       "6461                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            While it is certainly true that carers speak to small children in sentences of simple structure (Motherese), this is not true for all of the data that the child has access to, nor is it universally valid.   \n",
       "20612                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   But in the two years that followed, he delivered a true recovery economic growth and job creation were three times higher than in the Obama Economy.   \n",
       "16088                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       We tried over-sampling by giving a weight of 1000 to all true positive instances; this neither improved nor damaged the results.   \n",
       "17953                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           These inferences are part of a heater's general knowledge and true of the worleJ. They are part of the knowledge in the association network.   \n",
       "31002                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    In this subtask, we discriminate between true and false candidates.   \n",
       "39170                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         We hypothesise that there is a true underlying \"EAAT2/C1-4 were found to be equally expressed in ALS patients and controls.\" \"   \n",
       "31753                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Permanent' links are conditions that must be true for a certain action or state-of-affairs to bold.   \n",
       "38243                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          9 ) and (10) cannot he true at the same time.   \n",
       "24163                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       While it is true then that the use of CAT tools such as TM relies to a certain extent on translators extending their traditional skills without having to rethink their traditional values, this does not apply to the use of MT by translators.   \n",
       "9485                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The final stage integrates all the analysis results by applying a classification method based on SVM to classify the candidate sentence pairs as true or false cases of non-uniform language.   \n",
       "20491                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             We ask 5 independent annotators on Amazon Mechanical Turk to read each p and then determine whether h is true, false, or unclear given p. 7 We take the majority answer as the true label.   \n",
       "7752                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Possessive Extension Phrase Addition This attack modifies the previous sentence by appending phrases such as \"…but he wasn't sure\" and also prepending phrases such as \"it is true:...\".   \n",
       "35670                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Similarly, \"For each X in the list (A B C), do P(X)\" is not the same as \"For all X, make P(X) true\"; once again, the scripting language defines an or: der, but not the logical language 1. •   \n",
       "37577                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              A bridging mention m i from the gold chain C G is a true positive (tp) if m i and its immediate predecessor from C * G (m i ) are members of the same system entity, and a false negative (fn) otherwise.   \n",
       "37635                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Here, we study if this is also true for Chinese.   \n",
       "15351                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    What we want to make is a data set containing many chat messages, for each of which we need its true language and user id. An important question to answer at this stage is whether we could rely on the keyboard language to find the true language for a message.   \n",
       "2822                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   have sentential complements which do not represent true propositions.   \n",
       "31786                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   this point, tile user system should instruct tile B-SUItE system to presume the chooses assumption associated with tile chosen action being executed, which will change its truth value from \"possibly believed true\" to \"delinitely believed true\".   \n",
       "15780                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Word level evaluation: Given a list of ads A = {A 1 , A 2 , ..., A n }, for an ad A i , let ŶA i represent the predicted set of person names and Y A i represent 3 Details of parameter tuning is provided in Appendix D the set of true person names.   \n",
       "21425                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2012) , which theoretically guarantee the recovery of the true parameters by overcoming the problem of local optima.   \n",
       "35031                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The minicomputer-based facilities and the fancy graphic di,play systems may be used in conjunction with the extended Boolean processing, since the two types of developments are somewhat independent of each other, The same is true of the systems that provide common interfaces to mulriple data bases.   \n",
       "25873                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     However, the true tree must include many names that fall outside our small observed corpora, so our model would be a more appropriate fit for a far larger corpus.   \n",
       "10942                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     While this procedure reduced the size of the training set, we ensured that predictions on the true/false dimension would need to use the dialogue representations.   \n",
       "11496                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Denote the number of true positive, false positive, true negative and false negative snippets for all the test queries are TP,F P , TN, FN respectively.   \n",
       "8229                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      As the table shows, this pattern also held true for our eval test.   \n",
       "16288                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Comparison of judgments of true but underinformative simple declaratives (i.e. There is an X) to judgments of true but underinformative disjunctions (i.e. There is an X or a Y) on two-animal card conditions revealed some amount of scalar diversity.   \n",
       "5017                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Also, we did not divide a noun phrase to multiple mentions if the relation between the mentions is not always true (cf. \"   \n",
       "28448                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Instead, we consider each true system response in the evaluation dataset in isolation and generate a response for each, given the conversation history up until that point.   \n",
       "23448                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   In order to further validate the true positives, we did a second round of annotation by randomly dividing the 427 true positives into three lots, and had two annotators to again check each true positive instance.   \n",
       "21927                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         If true, this result implies that CNN-SC prefers not only in-domain data but also a representative sample of paragraphs from all class labels.   \n",
       "33276                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          R(s, a) = L Sim(v, v) a is Stop, 0 otherwise, where v is the selected best attribute value and v is the true attribute value.   \n",
       "9438                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The new binary feature exploits the fact that the possible translation lists are typically different for different senses of the same verb: given a verb token and an aligned token from the other language, the feature is set to \"true\" for those candidate senses that have the aligned token's lemma on the list of their possible translations.   \n",
       "8391                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Wikipedia-feature is assigned a true value for keyphrase aspirants for which there exists a Wikipedia article with the same title.   \n",
       "4644                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Relative to the top level annotation lung cancer, the scores are summed to yield 1, meaning that we get a true positive.   \n",
       "20460                                                                                                                                                                                                                                                                                                                                                                                                                                                         s ∼ G, (x, c) ∈ X s,q Let s be the stack of s , q = s, q • (x, c) 1: function MAIN( s, q , (x, c), ΦG) 2: if x is SHIFT then 3: if c ≡ c lex 0 then c not gold lexical category 4: return false 5: else if c ≡ c lex 0 and |s| = 0 then the initial item 6: return true 7: else if c ≡ c lex 0 and |s| = 0 then 8: compute R(c s 1 , c s 0 ) 9: return R(c s 1 , c s 0 ) = ∅ 10: if x is REDUCE then s is non-frontier 11: if c ∈ R(cs 1 , cs 0 ) then 12: compute R(c s 1 , c s 0 ) 13: return true 14: else return false 15: if x is UNARY then 16: if |s| = 1 then s is frontier 17: return c ∈ ΦG 18: if |s| = 1 and c ∈ ΦG then s is non-frontier 19: compute R(c s 1 , c s 0 ) 20: return R(c s 1 , c s 0 ) = ∅ A key to defining the dependency oracle function is the notion of a shared ancestor set.   \n",
       "23363                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The Symbolic Approach Tweet emotion detection For this task, we determined a baseline against which to gauge the performance of our classifiers by calculating precision, recall and F-score for each emotion in the ETCC corpus according to the simple presence or absence of the appropriate emotion hashtag in the tweet text (e.g. \"anger\" in the ANGER tweets were considered true positives, \"anger\" absent from an ANGER tweet was a false negative, and so on).   \n",
       "8045                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The reverse can be true as well.   \n",
       "14901                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               We calculate the absolute difference between the estimation and the true average reward.   \n",
       "37982                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Thus, given a text-hypothesis pair, we recognize the relation between the meanings of the text and the hypothesis in the pair as a true entailment if the meaning of the hypothesis is entailed from the meaning of the text.   \n",
       "35360                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          PP-head If is-PP is true, this is the head of the prepositional phrase; otherwise it is zero.   \n",
       "13361                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Austin's idea was that propositions are not objects that are true or false simpliciter but are true or false with respect to the part of the world that is being described.   \n",
       "30101                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   It is also true that all directions in the range (φ + ω, φ − ω) will not satisfy Eq.   \n",
       "22555                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 µ 0 and µ 1 represent the prior number of false/true fact the pattern extract, and κ 0 and κ 1 determine the prior sum of false/true fact count: λ p ( * ) 0 ∼ Gamma(µ 0 , κ 0 ); (3) 1 ) if l fe = 1.   \n",
       "24704                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The best analysis of the corpus is taken to be the true analysis, the frequencies are re-estimated, and the algorithm is repeated until it converges.   \n",
       "35451                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   With an appropriate canon, many undesirable graphs are ruled out as noncanonical, but the canonical graphs are not necessari!y true.   \n",
       "13467                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Third, they propose to measure performance only on frame elements using the \"Exact match condition\", i.e. both the label and the span of the projected role have to match the gold standard annotation for the target language to count as a true positive.   \n",
       "13700                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This means that more precise knowledge can be acquired when learning the true underlying ambiguity of questions instead of the sometimes misleading gold-label.   \n",
       "20942                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   For example, Logit Normalization Technique MRR@10 (1) None (\"true\" logit only) 0.026 (2) Softmax on all logits 0.379 (3) Softmax on \"true\"/\"false\" logits only 0.381 we could rerank documents according to the logit of the \"true\" token only or using logits of all tokens to compute the softmax.   \n",
       "20401                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Note that sentence-level scores are always at least as high as token-level scores, since it is possible to select a sentence correctly but none of its true relation tokens while the opposite is not possible.   \n",
       "\n",
       "       start_idx  end_idx  \n",
       "33556         21       22  \n",
       "26575         54       55  \n",
       "30718         21       22  \n",
       "5298          16       17  \n",
       "21466          6        7  \n",
       "3178          21       22  \n",
       "4440          18       19  \n",
       "30968         19       20  \n",
       "3541          25       26  \n",
       "11627         13       14  \n",
       "17691         14       15  \n",
       "37056         35       36  \n",
       "15600         21       22  \n",
       "39324         23       24  \n",
       "7969          24       25  \n",
       "4716          18       19  \n",
       "38947          5        6  \n",
       "39750          9       10  \n",
       "18986         19       20  \n",
       "26673         13       14  \n",
       "14518         23       24  \n",
       "21620         36       37  \n",
       "32547          2        3  \n",
       "33362         16       17  \n",
       "36992         17       18  \n",
       "15624          6        7  \n",
       "10155          6        7  \n",
       "13583         21       22  \n",
       "9220           5        6  \n",
       "31064         35       36  \n",
       "27848         56       57  \n",
       "31940         10       11  \n",
       "40209          2        3  \n",
       "4271           5        6  \n",
       "33400         12       13  \n",
       "19666         23       24  \n",
       "32216         46       47  \n",
       "35627         12       13  \n",
       "5245          31       32  \n",
       "14764         15       16  \n",
       "2378           7        8  \n",
       "9291          12       13  \n",
       "33663          4        5  \n",
       "40565          3        4  \n",
       "34209         30       31  \n",
       "8051          21       22  \n",
       "633           15       16  \n",
       "32499         14       15  \n",
       "19643         16       17  \n",
       "326            5        6  \n",
       "4210           3        4  \n",
       "30040         17       18  \n",
       "29746         18       19  \n",
       "9745          23       24  \n",
       "32448          7        8  \n",
       "25582         17       18  \n",
       "16186         25       26  \n",
       "37622         23       24  \n",
       "29526          9       10  \n",
       "26417         54       55  \n",
       "18692         22       23  \n",
       "19991          4        5  \n",
       "37233         40       41  \n",
       "12666          6        7  \n",
       "3298          34       35  \n",
       "18414         13       14  \n",
       "38949         19       20  \n",
       "32877         35       36  \n",
       "40428         36       37  \n",
       "7093           2        3  \n",
       "15333         15       16  \n",
       "5721           9       10  \n",
       "39792         19       20  \n",
       "14917          3        4  \n",
       "35187          5        6  \n",
       "9548         143      144  \n",
       "7724          82       83  \n",
       "22835         19       20  \n",
       "4133           5        6  \n",
       "14277         30       31  \n",
       "30204          9       10  \n",
       "4222          23       24  \n",
       "30018         17       18  \n",
       "10078         22       23  \n",
       "11092          3        4  \n",
       "11118         19       20  \n",
       "32581         14       15  \n",
       "4018           7        8  \n",
       "15195          1        2  \n",
       "29023         55       56  \n",
       "3957          23       24  \n",
       "35388         18       19  \n",
       "12348          3        4  \n",
       "14598         46       47  \n",
       "20209         16       17  \n",
       "21130         29       30  \n",
       "17930         59       60  \n",
       "37828          6        7  \n",
       "154            9       10  \n",
       "19906          1        2  \n",
       "34510         11       12  \n",
       "17143         22       23  \n",
       "14344         24       25  \n",
       "18714         12       13  \n",
       "38485        156      157  \n",
       "32740         22       23  \n",
       "9236           1        2  \n",
       "35568          1        2  \n",
       "16054         38       39  \n",
       "1295          16       17  \n",
       "26301         10       11  \n",
       "36925         11       12  \n",
       "32441         35       36  \n",
       "40140         20       21  \n",
       "557            4        5  \n",
       "30132         67       68  \n",
       "8555           2        3  \n",
       "1787          88       89  \n",
       "11426         71       72  \n",
       "35418         31       32  \n",
       "5228          32       33  \n",
       "7695         105      106  \n",
       "31495          8        9  \n",
       "15042         43       44  \n",
       "39653          8        9  \n",
       "8472          17       18  \n",
       "7177         154      155  \n",
       "24305        117      118  \n",
       "6330           6        7  \n",
       "21820          4        5  \n",
       "37280          3        4  \n",
       "31868         18       19  \n",
       "33752         13       14  \n",
       "31484         29       30  \n",
       "10189         15       16  \n",
       "19682          4        5  \n",
       "17036         19       20  \n",
       "26272          8        9  \n",
       "13296          3        4  \n",
       "26514          7        8  \n",
       "4683          31       32  \n",
       "13831         11       12  \n",
       "18821         11       12  \n",
       "28902          3        4  \n",
       "38520         77       78  \n",
       "16467         12       13  \n",
       "23473         11       12  \n",
       "29181          7        8  \n",
       "18126          3        4  \n",
       "2867          18       19  \n",
       "22186        103      104  \n",
       "34521         10       11  \n",
       "8196          70       71  \n",
       "31813         36       37  \n",
       "31457          4        5  \n",
       "18180         15       16  \n",
       "30373         41       42  \n",
       "18609         13       14  \n",
       "13287         47       48  \n",
       "39441         25       26  \n",
       "12665         19       20  \n",
       "32767          3        4  \n",
       "2746          14       15  \n",
       "40262          5        6  \n",
       "33325         22       23  \n",
       "2643           2        3  \n",
       "859            4        5  \n",
       "5002           9       10  \n",
       "30805          3        4  \n",
       "32853          5        6  \n",
       "18206         24       25  \n",
       "33495         78       79  \n",
       "478           30       31  \n",
       "30084         28       29  \n",
       "4167           3        4  \n",
       "15653         11       12  \n",
       "14957         22       23  \n",
       "28349         25       26  \n",
       "24433         13       14  \n",
       "21896         27       28  \n",
       "29319          3        4  \n",
       "8963          17       18  \n",
       "637           16       17  \n",
       "38585         30       31  \n",
       "1514           9       10  \n",
       "39075          7        8  \n",
       "9097           3        4  \n",
       "5903          59       60  \n",
       "22922          7        8  \n",
       "31007         10       11  \n",
       "22750         19       20  \n",
       "29711         16       17  \n",
       "36111         13       14  \n",
       "30261          8        9  \n",
       "7575          22       23  \n",
       "32322          7        8  \n",
       "25957         15       16  \n",
       "13426         21       22  \n",
       "32839         25       26  \n",
       "32346          1        2  \n",
       "21295         20       21  \n",
       "2701           7        8  \n",
       "30556         12       13  \n",
       "12184         25       26  \n",
       "8271          10       11  \n",
       "38855         35       36  \n",
       "12388         12       13  \n",
       "1157          27       28  \n",
       "22789         11       12  \n",
       "15115          6        7  \n",
       "7773           3        4  \n",
       "19849         24       25  \n",
       "25255         35       36  \n",
       "2357          43       44  \n",
       "27167         20       21  \n",
       "21921         20       21  \n",
       "18017         69       70  \n",
       "3416          13       14  \n",
       "18920         14       15  \n",
       "35735          8        9  \n",
       "17088         10       11  \n",
       "3897           3        4  \n",
       "22313         28       29  \n",
       "4530          11       12  \n",
       "19061         20       21  \n",
       "15551          3        4  \n",
       "2072          27       28  \n",
       "12855          8        9  \n",
       "31114         15       16  \n",
       "32749          3        4  \n",
       "21501         26       27  \n",
       "29995         39       40  \n",
       "13051          9       10  \n",
       "36031          7        8  \n",
       "28313         67       68  \n",
       "29997         29       30  \n",
       "40162         27       28  \n",
       "30231         33       34  \n",
       "37921          3        4  \n",
       "2057          36       37  \n",
       "25384         17       18  \n",
       "35607         27       28  \n",
       "19809          7        8  \n",
       "37650         19       20  \n",
       "24246         16       17  \n",
       "35458          2        3  \n",
       "2877          11       12  \n",
       "25320        251      252  \n",
       "2212          24       25  \n",
       "2163          86       87  \n",
       "35920         19       20  \n",
       "19890         32       33  \n",
       "6022          32       33  \n",
       "15706         19       20  \n",
       "20600         11       12  \n",
       "7122          39       40  \n",
       "14950         41       42  \n",
       "25726         12       13  \n",
       "32709         15       16  \n",
       "36387         13       14  \n",
       "12304         13       14  \n",
       "17952          8        9  \n",
       "6297           9       10  \n",
       "33023         19       20  \n",
       "16053         18       19  \n",
       "4963          21       22  \n",
       "1901          15       16  \n",
       "2016          13       14  \n",
       "27012         13       14  \n",
       "34447          5        6  \n",
       "6892           4        5  \n",
       "9935          17       18  \n",
       "14899         18       19  \n",
       "18502         27       28  \n",
       "8374          31       32  \n",
       "10023         19       20  \n",
       "37110         75       76  \n",
       "4927           5        6  \n",
       "3090           4        5  \n",
       "12729         19       20  \n",
       "30081          8        9  \n",
       "30387         22       23  \n",
       "22469         20       21  \n",
       "27148         20       21  \n",
       "1790          43       44  \n",
       "27679          2        3  \n",
       "28042         27       28  \n",
       "33610         23       24  \n",
       "39240         14       15  \n",
       "20556         12       13  \n",
       "32559         69       70  \n",
       "917           20       21  \n",
       "3347          61       62  \n",
       "27371          4        5  \n",
       "3639          21       22  \n",
       "13796         33       34  \n",
       "18975         18       19  \n",
       "28571         13       14  \n",
       "37606         23       24  \n",
       "21598         39       40  \n",
       "13202          9       10  \n",
       "31310          1        2  \n",
       "32506         48       49  \n",
       "28918         15       16  \n",
       "1084          16       17  \n",
       "9357           8        9  \n",
       "17749         31       32  \n",
       "36741         12       13  \n",
       "13634          2        3  \n",
       "33517          7        8  \n",
       "16522          2        3  \n",
       "38148          5        6  \n",
       "18803         16       17  \n",
       "20831         32       33  \n",
       "15174         11       12  \n",
       "3003          39       40  \n",
       "12036         14       15  \n",
       "6046           3        4  \n",
       "19548         86       87  \n",
       "32687         16       17  \n",
       "2071          15       16  \n",
       "7119          31       32  \n",
       "5110          21       22  \n",
       "19475          7        8  \n",
       "34649         13       14  \n",
       "1236           6        7  \n",
       "22519         96       97  \n",
       "34763         26       27  \n",
       "14741         26       27  \n",
       "22029         10       11  \n",
       "30644          8        9  \n",
       "33543         14       15  \n",
       "12435         11       12  \n",
       "15912         14       15  \n",
       "26554         63       64  \n",
       "23902         17       18  \n",
       "19993         26       27  \n",
       "15065         20       21  \n",
       "13757         20       21  \n",
       "22462         50       51  \n",
       "9002          19       20  \n",
       "20173          5        6  \n",
       "39439         10       11  \n",
       "30227          9       10  \n",
       "6194          12       13  \n",
       "27807          4        5  \n",
       "2559          28       29  \n",
       "22453         33       34  \n",
       "24308          5        6  \n",
       "3978           5        6  \n",
       "29225         18       19  \n",
       "2096          82       83  \n",
       "11362         21       22  \n",
       "21662         28       29  \n",
       "3637           8        9  \n",
       "39946         24       25  \n",
       "26340          3        4  \n",
       "27408          6        7  \n",
       "16498         23       24  \n",
       "31189          7        8  \n",
       "36029         32       33  \n",
       "9603          15       16  \n",
       "14147         19       20  \n",
       "22908          3        4  \n",
       "31478         15       16  \n",
       "5960          18       19  \n",
       "30685          8        9  \n",
       "24146         94       95  \n",
       "3190          16       17  \n",
       "39616         30       31  \n",
       "10657          2        3  \n",
       "34303         37       38  \n",
       "7490          37       38  \n",
       "8617          14       15  \n",
       "26893         33       34  \n",
       "6831           9       10  \n",
       "29646         27       28  \n",
       "12853         13       14  \n",
       "16805          5        6  \n",
       "40086         12       13  \n",
       "24877         37       38  \n",
       "14077         16       17  \n",
       "11540         25       26  \n",
       "6535          14       15  \n",
       "30131          3        4  \n",
       "40076         58       59  \n",
       "5271           4        5  \n",
       "14778         18       19  \n",
       "19165         24       25  \n",
       "2011          12       13  \n",
       "25237         14       15  \n",
       "15881         10       11  \n",
       "37927          5        6  \n",
       "26123         18       19  \n",
       "8522          14       15  \n",
       "25099          3        4  \n",
       "28215          7        8  \n",
       "37208         20       21  \n",
       "15            93       94  \n",
       "32837         18       19  \n",
       "22546         16       17  \n",
       "24176         16       17  \n",
       "31971          4        5  \n",
       "7901          21       22  \n",
       "11587         26       27  \n",
       "27852         25       26  \n",
       "3774          10       11  \n",
       "12090         16       17  \n",
       "32618          3        4  \n",
       "33305          7        8  \n",
       "20978         15       16  \n",
       "31639         14       15  \n",
       "31488         25       26  \n",
       "31627         20       21  \n",
       "23228         13       14  \n",
       "40225          6        7  \n",
       "10867         26       27  \n",
       "29334         47       48  \n",
       "22500         27       28  \n",
       "21862          1        2  \n",
       "22826         23       24  \n",
       "38716         16       17  \n",
       "37714          3        4  \n",
       "12747         17       18  \n",
       "21129         17       18  \n",
       "39756         20       21  \n",
       "26045         24       25  \n",
       "5050           3        4  \n",
       "2652           8        9  \n",
       "9478          15       16  \n",
       "11576         53       54  \n",
       "8784          26       27  \n",
       "38659          1        2  \n",
       "23301         20       21  \n",
       "30042          7        8  \n",
       "20789         43       44  \n",
       "28209         53       54  \n",
       "186            3        4  \n",
       "17823          4        5  \n",
       "13164         47       48  \n",
       "33890          7        8  \n",
       "23276         11       12  \n",
       "9900          81       82  \n",
       "35985          2        3  \n",
       "12804         13       14  \n",
       "27080         37       38  \n",
       "17139         29       30  \n",
       "33586          4        5  \n",
       "19376          7        8  \n",
       "30635         10       11  \n",
       "18347          3        4  \n",
       "6461          23       24  \n",
       "20612         11       12  \n",
       "16088         13       14  \n",
       "17953         11       12  \n",
       "31002          7        8  \n",
       "39170          6        7  \n",
       "31753          8        9  \n",
       "38243          9       10  \n",
       "24163          3        4  \n",
       "9485          23       24  \n",
       "20491         35       36  \n",
       "7752          32       33  \n",
       "35670         32       33  \n",
       "37577         13       14  \n",
       "37635          8        9  \n",
       "15351         21       22  \n",
       "2822           7        8  \n",
       "31786         42       43  \n",
       "15780         58       59  \n",
       "21425         10       11  \n",
       "35031         40       41  \n",
       "25873          3        4  \n",
       "10942         17       18  \n",
       "11496          4        5  \n",
       "8229           9       10  \n",
       "16288         19       20  \n",
       "5017          21       22  \n",
       "28448          5        6  \n",
       "23448         35       36  \n",
       "21927          1        2  \n",
       "33276         29       30  \n",
       "9438          42       43  \n",
       "8391           6        7  \n",
       "4644          22       23  \n",
       "20460         95       96  \n",
       "23363         66       67  \n",
       "8045           4        5  \n",
       "14901         10       11  \n",
       "37982         27       28  \n",
       "35360          8        9  \n",
       "13361         11       12  \n",
       "30101          3        4  \n",
       "22555         12       13  \n",
       "24704         11       12  \n",
       "35451         21       22  \n",
       "13467         45       46  \n",
       "13700         12       13  \n",
       "20942         49       50  \n",
       "20401         31       32  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d3eec-9c80-4407-bb14-5bd9a3b0fe59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
